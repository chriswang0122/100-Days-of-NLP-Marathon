{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 更加了解word2vec高速化\n",
    "本次作業主要是幫同學更熟悉與了解各項技巧來加速word2vec的原理，同學可以參考章節講義來回答下列問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 - 請問word2vec原本的設計有何問題以及可以怎麼對相對應的問題做改善?\n",
    "\n",
    "Answer:\n",
    "- **Problem**:\n",
    "    - For each training sample, **only the weights corresponding to the target word might get a significant update**. While training a neural network model, in each back-propagation pass we try to update all the weights in the hidden layer. The weight corresponding to non-target words would receive a marginal or no change at all, i.e. in each pass we only make very sparse updates.\n",
    "    - For every training sample, **the calculation of the final probabilities using the softmax is quite an expensive operation** as it involves a summation of scores over all the words in our vocabulary for normalizing.\n",
    "- **Solution**:\n",
    "    - Hierarchical Softmax\n",
    "    - Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 - 請問在Negative Sampling中的次方係數，會如何影響字詞的抽取?\n",
    "Hint: 如何影響高頻詞與低頻詞的抽取機率\n",
    "\n",
    "Answer:<br>\n",
    "The 3/4 power makes **less frequent words be sampled more often**, without it probability of sampling frequent words such as “the”, “is” etc would be much higher than words like “zebra”, “elephant” etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55555556 0.37037037 0.07407407]\n",
      "[0.51061101 0.37672265 0.11266635]\n",
      "[0.45836973 0.37425731 0.16737296]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "freq = [15, 10, 2]\n",
    "factors = [1.0, 0.75, 0.5]\n",
    "for factor in factors:\n",
    "    numerator = np.power(freq, factor)\n",
    "    denominator = np.sum(numerator)\n",
    "    print(numerator / denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "- [Word2Vec Tutorial Part 2 - Negative Sampling](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/)\n",
    "- [NLP 102: Negative Sampling and GloVe](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
