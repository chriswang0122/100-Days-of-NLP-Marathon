{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"作業_Seq2Seq_translator_en_de.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SrWWUhFlUprI"},"source":["# 作業 : 實作英文-德文翻譯機器人\n","***\n","## [作業目標]\n","用 PyTorch 實作一個英文-德文翻譯機器人\n","\n","## [作業重點]\n","* 語言資料處理\n","* 使用 LSTM 建構 Encoder: EncoderLSTM\n","* 使用 LSTM 建構 Decoder: DecoderLSTM\n","* 搭建 Sequence to Sequence 模型: Seq2Seq\n","* 撰寫訓練函式\n","* 撰寫測試函式\n","\n","## [問題]\n","在 Colab 上實際執行完這個範例後，請改用 BiLSTM 來建構 Encoder"]},{"cell_type":"markdown","metadata":{"id":"qyd4LijE7vGo"},"source":["## 引用需要的模組"]},{"cell_type":"code","metadata":{"id":"RanKHsWTu-rn","executionInfo":{"status":"ok","timestamp":1612242436849,"user_tz":-480,"elapsed":6720,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["import os\n","import spacy\n","import torch\n","import random\n","import pandas as pd\n","from pprint import pprint\n","\n","from torch import nn, optim\n","from torchtext.data import Field, BucketIterator\n","from torchtext.datasets import Multi30k\n","from torchtext.data.metrics import bleu_score\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a9h9rmgr74Sk"},"source":["## 下載 spacy 英文/德文語料"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyskUGjGSr-0","executionInfo":{"status":"ok","timestamp":1612242448388,"user_tz":-480,"elapsed":18251,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"afa23647-8ea4-4fa1-aea1-6f6a47d96815"},"source":["!python -m spacy download en\n","spacy_en = spacy.load('en')\n","!python -m spacy download de\n","spacy_de = spacy.load('de')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.3.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","Collecting de_core_news_sm==2.2.5\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n","\u001b[K     |████████████████████████████████| 14.9MB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.3.3)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n","Building wheels for collected packages: de-core-news-sm\n","  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907057 sha256=38563853eab721191ad9a5599d0a9fca687a728d255b9fa4e16e984724d0be9e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-6x1r_5tq/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n","Successfully built de-core-news-sm\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dK984GbYv8Y-","executionInfo":{"status":"ok","timestamp":1612242458195,"user_tz":-480,"elapsed":28054,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"9e9eb761-cd15-4a13-b93e-298f8df5a428"},"source":["def tokenize_en(text):\n","    return [token.text for token in spacy_en.tokenizer(text)]\n","\n","def tokenize_de(text):\n","    return [token.text for token in spacy_de.tokenizer(text)]\n","\n","# Sample Run\n","sample_text = 'I love machine learning'\n","print(tokenize_en(sample_text))\n","\n","english = Field(tokenize=tokenize_en, lower=True,\n","                init_token='<sos>', eos_token='<eos>')\n","german = Field(tokenize=tokenize_de, lower=True,\n","               init_token='<sos>', eos_token='<eos>')\n","\n","train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.de'), fields=(english, german))\n","english.build_vocab(train_data, max_size=10000, min_freq=2)\n","german.build_vocab(train_data, max_size=10000, min_freq=2)\n","\n","print(f\"Unique tokens in source (english) vocabulary: {len(english.vocab)}\")\n","print(f\"Unique tokens in target (german) vocabulary: {len(german.vocab)}\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['I', 'love', 'machine', 'learning']\n","downloading training.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["training.tar.gz: 100%|██████████| 1.21M/1.21M [00:02<00:00, 560kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading validation.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 174kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading mmt_task1_test2016.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 166kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Unique tokens in source (english) vocabulary: 5893\n","Unique tokens in target (german) vocabulary: 7855\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WunTmSIJzBaC","executionInfo":{"status":"ok","timestamp":1612242458197,"user_tz":-480,"elapsed":28052,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"ba495f12-ab91-45fe-fb9d-d08464dcb1c3"},"source":["print(f\"Number of training examples: {len(train_data.examples)}\")\n","print(f\"Number of validation examples: {len(valid_data.examples)}\")\n","print(f\"Number of testing examples: {len(test_data.examples)}\")\n","\n","print(train_data[5].__dict__.keys())\n","pprint(train_data[5].__dict__.values())"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Number of training examples: 29000\n","Number of validation examples: 1014\n","Number of testing examples: 1000\n","dict_keys(['src', 'trg'])\n","dict_values([['a', 'man', 'in', 'green', 'holds', 'a', 'guitar', 'while', 'the', 'other', 'man', 'observes', 'his', 'shirt', '.'], ['ein', 'mann', 'in', 'grün', 'hält', 'eine', 'gitarre', ',', 'während', 'der', 'andere', 'mann', 'sein', 'hemd', 'ansieht', '.']])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zRGP9EsizRRN","executionInfo":{"status":"ok","timestamp":1612242458197,"user_tz":-480,"elapsed":28050,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["BATCH_SIZE = 32\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size=BATCH_SIZE, \n","    sort_within_batch=True,\n","    sort_key=lambda x: len(x.src),\n","    device=device\n",")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E3nozOT8zdeD","executionInfo":{"status":"ok","timestamp":1612242458198,"user_tz":-480,"elapsed":28047,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"d7f62f62-eec6-4e69-c413-cee4e7fb368f"},"source":["len_eng_examples = []\n","len_ger_examples = []\n","for idx, data in enumerate(train_data):\n","    len_eng_examples.append(len(data.src))\n","    len_ger_examples.append(len(data.trg))\n","    if idx < 10:\n","        print('German - ', *data.src, ' Length - ', len(data.src))\n","        print('English - ', *data.trg, ' Length - ', len(data.trg))\n","        print()\n","\n","print(f\"Maximum Length of English sentence {max(len_eng_examples)} and German sentence {max(len_ger_examples)} in the dataset\")\n","print(f\"Minimum Length of English sentence {min(len_eng_examples)} and German sentence {min(len_ger_examples)} in the dataset\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["German -  two young , white males are outside near many bushes .  Length -  11\n","English -  zwei junge weiße männer sind im freien in der nähe vieler büsche .  Length -  13\n","\n","German -  several men in hard hats are operating a giant pulley system .  Length -  12\n","English -  mehrere männer mit schutzhelmen bedienen ein antriebsradsystem .  Length -  8\n","\n","German -  a little girl climbing into a wooden playhouse .  Length -  9\n","English -  ein kleines mädchen klettert in ein spielhaus aus holz .  Length -  10\n","\n","German -  a man in a blue shirt is standing on a ladder cleaning a window .  Length -  15\n","English -  ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster .  Length -  15\n","\n","German -  two men are at the stove preparing food .  Length -  9\n","English -  zwei männer stehen am herd und bereiten essen zu .  Length -  10\n","\n","German -  a man in green holds a guitar while the other man observes his shirt .  Length -  15\n","English -  ein mann in grün hält eine gitarre , während der andere mann sein hemd ansieht .  Length -  16\n","\n","German -  a man is smiling at a stuffed lion  Length -  8\n","English -  ein mann lächelt einen ausgestopften löwen an .  Length -  8\n","\n","German -  a trendy girl talking on her cellphone while gliding slowly down the street .  Length -  14\n","English -  ein schickes mädchen spricht mit dem handy während sie langsam die straße entlangschwebt .  Length -  14\n","\n","German -  a woman with a large purse is walking by a gate .  Length -  12\n","English -  eine frau mit einer großen geldbörse geht an einem tor vorbei .  Length -  12\n","\n","German -  boys dancing on poles in the middle of the night .  Length -  11\n","English -  jungen tanzen mitten in der nacht auf pfosten .  Length -  9\n","\n","Maximum Length of English sentence 41 and German sentence 44 in the dataset\n","Minimum Length of English sentence 4 and German sentence 1 in the dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pE_S5yMdwRsT","executionInfo":{"status":"ok","timestamp":1612242468703,"user_tz":-480,"elapsed":38547,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"7fb4a52e-57cc-407f-b45c-349560ef4680"},"source":["data = next(iter(train_iterator))\n","temp_eng, temp_ger = data.src, data.trg\n","print('Shapes', data.src.shape, data.trg.shape, '\\n')\n","print('English - ', *data.src, ' Length - ', len(data.src), '\\n')\n","print('German - ', *data.trg, ' Length - ', len(data.trg))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Shapes torch.Size([13, 32]) torch.Size([16, 32]) \n","\n","English -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([  38,   16,    4,   16,    4,   21,    4,    4,    4, 4125,    7,    4,\n","          48,    4,    4,    4,    4,    4,    7,    4,    4,    4,    4,    4,\n","           4,  324,   16,    4,    4,    4,    4,    4], device='cuda:0') tensor([  12,   50,    9,   30,  602,  145,    9,    9,   25,  252, 2296,  903,\n","          30,   64,   35, 1814, 3504,  168,  552,  153,    9,   53,   64,   14,\n","          53,  327,   19,  648,   33,   33,   34,   14], device='cuda:0') tensor([ 168,   78,   10,   17, 1435,    9,    6,   22,   35,    4,   15,  212,\n","          17,   10,   13, 1543,  648,   42,   10,   10,  940,   33,  195,  321,\n","          34,   14,  152,  831,    6,    6,   22,   22], device='cuda:0') tensor([ 42,   6, 119,  78, 540,  32,  25, 561,  10, 606, 145, 171, 252,  78,\n","          4,  15, 972, 433, 635,   6,   4,  10,   4,  82,  10,   6,   6,  60,\n","          4,   4,   4,   4], device='cuda:0') tensor([1320,    4,    8,    8,   18,    8,   89,  525, 1608,   13,    9,    7,\n","           4,    4,  409,   12,    7,    9,    6,    4,   55,   41,  576,   14,\n","          22,   29, 1030,    7,   26,  796, 1355,   29], device='cuda:0') tensor([  30,  295,   27,    4,   82,    4,    6,   10, 1678,  826, 1884,  399,\n","        1318,  198,   15,  251, 2853, 1225,   65, 4365,    8,    4,   18,  102,\n","           4,   23, 1545,  103,   23,  372,   67,   23], device='cuda:0') tensor([ 395,  244,  286,  295,   28,  293,   43, 1812,  798,   11,  734, 2765,\n","          93,   40,  256,   15,    8,    6,   78,   37,    4,   35,  557, 4986,\n","        3676,  107,  171,   28,   37,   56,  137, 2623], device='cuda:0') tensor([5802,   17,    6,   40,    8,   45,   12,    4,    4,  131,    6,    8,\n","           4,    4,    6, 1812,    4,    4,    4,   13,  223,   49,    4,    4,\n","           6,   40,    4,  169,    4,   20,    6,    8], device='cuda:0') tensor([   8,  405,    4,    4,    7,    4,    4,  157,   52,   11,    7,    4,\n","        2615,  170,    4,    4,  369,  765,  289,    4,  238,    7, 2697,  278,\n","           4,   20,  291,    4,  866,    4,    4,    4], device='cuda:0') tensor([  39,   22,  101,  142,  622, 2675, 1220,  861,  223,  599,  243,  302,\n","         276,  438,  318,  142,  184,  187,  335,  565,  363,   47,   25,  204,\n","        2094,  131,  142,  319,  135,  277, 1004,  776], device='cuda:0') tensor([  5, 628,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n","          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n","          5,   5,   5,   5], device='cuda:0') tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')  Length -  13 \n","\n","German -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([ 36,  18,   5,  18,   5,   5,   5,   5,   5,   0,  15,   5,  43,   8,\n","          5, 216,   5,   5,  15,   5,   5,   5,   8,   8,   5,   8,  18,   5,\n","          5,   5,   5,   8], device='cuda:0') tensor([  22,   45,   13,   30, 4875,  272,   13,   13,  150,    7, 3673, 1051,\n","          30,   67,   32, 2212, 1533,   13,  468,  164,   13,   66,   67,   16,\n","          70, 3105,   54,  538,   25,   25,   26,   16], device='cuda:0') tensor([ 242,  137,  339,  137,  183,   13,    7,   11,   32, 3056,  390,   83,\n","        1457,  288,   11,  879,  538,  412,  559,    7,  303,   25,   29, 3316,\n","          26,    7,   74,    0,    7,   20,   11,    7], device='cuda:0') tensor([ 56,   5,  11,  12,  12,  31, 232,  14, 220, 548,  13,  12,  98,  12,\n","         14,   8, 404, 429,  22,   6,   5,  60,  12,  17,  11,   6,   7,  58,\n","          6,   0,   6,  14], device='cuda:0') tensor([  24,  259,   77,    6,   15,    7,   29, 1251,   23,   23,  281,   15,\n","           6,    6,  494,   34,   17, 1965,   14, 7102,   49,   55,   14, 3726,\n","        3431,   46, 3700,   17,   71,  182,    0,   46], device='cuda:0') tensor([2360,    9,  722,  259,   34,    6,   27,  667,  109,  193,   20, 2156,\n","        4254,  195,  350,    4, 1488,    7,   78,   38,   12,   63,  535,   14,\n","           7,   79, 2007,   90,  414,   23,   12,  256], device='cuda:0') tensor([2364,  470,    7,   12,   11,  353,    6,   19,  324,  111,  268,   44,\n","           4,   12,    7,    3,   21,    6,  316,   11,    6,   11,   64,   94,\n","          14,   95,   42,   59,   38,    5,   24,  569], device='cuda:0') tensor([ 321,  163,   15,   14,    6,   10,  588, 3205,   44,   10,    5, 4953,\n","           3,    6,    6,    1,    6, 1197,   20,    6, 5119,    6,    8,   16,\n","        1443,   12,    8,   15,    5,  286,  143,   21], device='cuda:0') tensor([   0, 1826,  152,   34,   94,   37,    4,    4,   82,  445,    4,    4,\n","           1, 7521,  310,    1, 1208,  799,   63,  575,    4,   32, 2031,    7,\n","           4,  111, 2484, 3599,    0,   21,   38,    6], device='cuda:0') tensor([  12,    4,    4,    4,    4,    8,    3,    3, 7331,    4,    3,    3,\n","           1,    4,    4,    1,  200,    4,   21,    4,    3, 1173,  232, 6675,\n","           3,  937,    4,   44,    4,    4,    7,  774], device='cuda:0') tensor([  15,    3,    3,    3,    3, 2470,    1,    1,    7,    3,    1,    1,\n","           1,    3,    3,    1,    4,    3,    4,    3,    1,    4,   28, 2230,\n","           1,    4,    3,    0,    3,    3,   14,    4], device='cuda:0') tensor([  34,    1,    1,    1,    1,    4,    1,    1,   15,    1,    1,    1,\n","           1,    1,    1,    1,    3,    1,    3,    1,    1,    3, 2027,    4,\n","           1,    3,    1,    4,    1,    1, 1148,    3], device='cuda:0') tensor([ 4,  1,  1,  1,  1,  3,  1,  1, 90,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  4,  3,  1,  1,  1,  3,  1,  1,  4,  1],\n","       device='cuda:0') tensor([3, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1,\n","        1, 1, 1, 1, 1, 1, 3, 1], device='cuda:0') tensor([1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')  Length -  16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xSP5RchXyuaz","executionInfo":{"status":"ok","timestamp":1612242468704,"user_tz":-480,"elapsed":38547,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["temp_eng_idx = temp_eng.cpu().detach().numpy()\n","temp_ger_idx = temp_ger.cpu().detach().numpy()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500},"id":"tgAmQS4I6k9v","executionInfo":{"status":"ok","timestamp":1612242468705,"user_tz":-480,"elapsed":38543,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"f469fc3a-62fc-40d3-dbe8-cbeb53a5714f"},"source":["df_eng_idx = pd.DataFrame(data=temp_eng_idx,\n","                          columns=[str('S_') + str(x + 1) for x in range(BATCH_SIZE)])\n","df_eng_idx.index.name = 'Time Steps'\n","df_eng_idx.index = df_eng_idx.index + 1 \n","df_eng_idx"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>S_1</th>\n","      <th>S_2</th>\n","      <th>S_3</th>\n","      <th>S_4</th>\n","      <th>S_5</th>\n","      <th>S_6</th>\n","      <th>S_7</th>\n","      <th>S_8</th>\n","      <th>S_9</th>\n","      <th>S_10</th>\n","      <th>S_11</th>\n","      <th>S_12</th>\n","      <th>S_13</th>\n","      <th>S_14</th>\n","      <th>S_15</th>\n","      <th>S_16</th>\n","      <th>S_17</th>\n","      <th>S_18</th>\n","      <th>S_19</th>\n","      <th>S_20</th>\n","      <th>S_21</th>\n","      <th>S_22</th>\n","      <th>S_23</th>\n","      <th>S_24</th>\n","      <th>S_25</th>\n","      <th>S_26</th>\n","      <th>S_27</th>\n","      <th>S_28</th>\n","      <th>S_29</th>\n","      <th>S_30</th>\n","      <th>S_31</th>\n","      <th>S_32</th>\n","    </tr>\n","    <tr>\n","      <th>Time Steps</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>21</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4125</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>48</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>324</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12</td>\n","      <td>50</td>\n","      <td>9</td>\n","      <td>30</td>\n","      <td>602</td>\n","      <td>145</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>25</td>\n","      <td>252</td>\n","      <td>2296</td>\n","      <td>903</td>\n","      <td>30</td>\n","      <td>64</td>\n","      <td>35</td>\n","      <td>1814</td>\n","      <td>3504</td>\n","      <td>168</td>\n","      <td>552</td>\n","      <td>153</td>\n","      <td>9</td>\n","      <td>53</td>\n","      <td>64</td>\n","      <td>14</td>\n","      <td>53</td>\n","      <td>327</td>\n","      <td>19</td>\n","      <td>648</td>\n","      <td>33</td>\n","      <td>33</td>\n","      <td>34</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>168</td>\n","      <td>78</td>\n","      <td>10</td>\n","      <td>17</td>\n","      <td>1435</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>22</td>\n","      <td>35</td>\n","      <td>4</td>\n","      <td>15</td>\n","      <td>212</td>\n","      <td>17</td>\n","      <td>10</td>\n","      <td>13</td>\n","      <td>1543</td>\n","      <td>648</td>\n","      <td>42</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>940</td>\n","      <td>33</td>\n","      <td>195</td>\n","      <td>321</td>\n","      <td>34</td>\n","      <td>14</td>\n","      <td>152</td>\n","      <td>831</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>22</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>42</td>\n","      <td>6</td>\n","      <td>119</td>\n","      <td>78</td>\n","      <td>540</td>\n","      <td>32</td>\n","      <td>25</td>\n","      <td>561</td>\n","      <td>10</td>\n","      <td>606</td>\n","      <td>145</td>\n","      <td>171</td>\n","      <td>252</td>\n","      <td>78</td>\n","      <td>4</td>\n","      <td>15</td>\n","      <td>972</td>\n","      <td>433</td>\n","      <td>635</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>82</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>60</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1320</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>18</td>\n","      <td>8</td>\n","      <td>89</td>\n","      <td>525</td>\n","      <td>1608</td>\n","      <td>13</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>409</td>\n","      <td>12</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>55</td>\n","      <td>41</td>\n","      <td>576</td>\n","      <td>14</td>\n","      <td>22</td>\n","      <td>29</td>\n","      <td>1030</td>\n","      <td>7</td>\n","      <td>26</td>\n","      <td>796</td>\n","      <td>1355</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>30</td>\n","      <td>295</td>\n","      <td>27</td>\n","      <td>4</td>\n","      <td>82</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>10</td>\n","      <td>1678</td>\n","      <td>826</td>\n","      <td>1884</td>\n","      <td>399</td>\n","      <td>1318</td>\n","      <td>198</td>\n","      <td>15</td>\n","      <td>251</td>\n","      <td>2853</td>\n","      <td>1225</td>\n","      <td>65</td>\n","      <td>4365</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>18</td>\n","      <td>102</td>\n","      <td>4</td>\n","      <td>23</td>\n","      <td>1545</td>\n","      <td>103</td>\n","      <td>23</td>\n","      <td>372</td>\n","      <td>67</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>395</td>\n","      <td>244</td>\n","      <td>286</td>\n","      <td>295</td>\n","      <td>28</td>\n","      <td>293</td>\n","      <td>43</td>\n","      <td>1812</td>\n","      <td>798</td>\n","      <td>11</td>\n","      <td>734</td>\n","      <td>2765</td>\n","      <td>93</td>\n","      <td>40</td>\n","      <td>256</td>\n","      <td>15</td>\n","      <td>8</td>\n","      <td>6</td>\n","      <td>78</td>\n","      <td>37</td>\n","      <td>4</td>\n","      <td>35</td>\n","      <td>557</td>\n","      <td>4986</td>\n","      <td>3676</td>\n","      <td>107</td>\n","      <td>171</td>\n","      <td>28</td>\n","      <td>37</td>\n","      <td>56</td>\n","      <td>137</td>\n","      <td>2623</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5802</td>\n","      <td>17</td>\n","      <td>6</td>\n","      <td>40</td>\n","      <td>8</td>\n","      <td>45</td>\n","      <td>12</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>131</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>1812</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>13</td>\n","      <td>223</td>\n","      <td>49</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>40</td>\n","      <td>4</td>\n","      <td>169</td>\n","      <td>4</td>\n","      <td>20</td>\n","      <td>6</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>8</td>\n","      <td>405</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>157</td>\n","      <td>52</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>2615</td>\n","      <td>170</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>369</td>\n","      <td>765</td>\n","      <td>289</td>\n","      <td>4</td>\n","      <td>238</td>\n","      <td>7</td>\n","      <td>2697</td>\n","      <td>278</td>\n","      <td>4</td>\n","      <td>20</td>\n","      <td>291</td>\n","      <td>4</td>\n","      <td>866</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>39</td>\n","      <td>22</td>\n","      <td>101</td>\n","      <td>142</td>\n","      <td>622</td>\n","      <td>2675</td>\n","      <td>1220</td>\n","      <td>861</td>\n","      <td>223</td>\n","      <td>599</td>\n","      <td>243</td>\n","      <td>302</td>\n","      <td>276</td>\n","      <td>438</td>\n","      <td>318</td>\n","      <td>142</td>\n","      <td>184</td>\n","      <td>187</td>\n","      <td>335</td>\n","      <td>565</td>\n","      <td>363</td>\n","      <td>47</td>\n","      <td>25</td>\n","      <td>204</td>\n","      <td>2094</td>\n","      <td>131</td>\n","      <td>142</td>\n","      <td>319</td>\n","      <td>135</td>\n","      <td>277</td>\n","      <td>1004</td>\n","      <td>776</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>5</td>\n","      <td>628</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             S_1  S_2  S_3  S_4   S_5   S_6  ...  S_27  S_28  S_29  S_30  S_31  S_32\n","Time Steps                                   ...                                    \n","1              2    2    2    2     2     2  ...     2     2     2     2     2     2\n","2             38   16    4   16     4    21  ...    16     4     4     4     4     4\n","3             12   50    9   30   602   145  ...    19   648    33    33    34    14\n","4            168   78   10   17  1435     9  ...   152   831     6     6    22    22\n","5             42    6  119   78   540    32  ...     6    60     4     4     4     4\n","6           1320    4    8    8    18     8  ...  1030     7    26   796  1355    29\n","7             30  295   27    4    82     4  ...  1545   103    23   372    67    23\n","8            395  244  286  295    28   293  ...   171    28    37    56   137  2623\n","9           5802   17    6   40     8    45  ...     4   169     4    20     6     8\n","10             8  405    4    4     7     4  ...   291     4   866     4     4     4\n","11            39   22  101  142   622  2675  ...   142   319   135   277  1004   776\n","12             5  628    5    5     5     5  ...     5     5     5     5     5     5\n","13             3    3    3    3     3     3  ...     3     3     3     3     3     3\n","\n","[13 rows x 32 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"vXy1431M6o02","executionInfo":{"status":"ok","timestamp":1612242469026,"user_tz":-480,"elapsed":38859,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"96000b61-1cc9-4722-c50e-d78ea58c9584"},"source":["idx2word = {idx: word for idx, word in enumerate(english.vocab.itos)}\n","df_eng_word = pd.DataFrame(columns=[str('S_') + str(x + 1) for x in range(BATCH_SIZE)])\n","df_eng_word = df_eng_idx.replace(idx2word)\n","df_eng_word"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>S_1</th>\n","      <th>S_2</th>\n","      <th>S_3</th>\n","      <th>S_4</th>\n","      <th>S_5</th>\n","      <th>S_6</th>\n","      <th>S_7</th>\n","      <th>S_8</th>\n","      <th>S_9</th>\n","      <th>S_10</th>\n","      <th>S_11</th>\n","      <th>S_12</th>\n","      <th>S_13</th>\n","      <th>S_14</th>\n","      <th>S_15</th>\n","      <th>S_16</th>\n","      <th>S_17</th>\n","      <th>S_18</th>\n","      <th>S_19</th>\n","      <th>S_20</th>\n","      <th>S_21</th>\n","      <th>S_22</th>\n","      <th>S_23</th>\n","      <th>S_24</th>\n","      <th>S_25</th>\n","      <th>S_26</th>\n","      <th>S_27</th>\n","      <th>S_28</th>\n","      <th>S_29</th>\n","      <th>S_30</th>\n","      <th>S_31</th>\n","      <th>S_32</th>\n","    </tr>\n","    <tr>\n","      <th>Time Steps</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>group</td>\n","      <td>two</td>\n","      <td>a</td>\n","      <td>two</td>\n","      <td>a</td>\n","      <td>an</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>indians</td>\n","      <td>the</td>\n","      <td>a</td>\n","      <td>three</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>the</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>african</td>\n","      <td>two</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>of</td>\n","      <td>women</td>\n","      <td>man</td>\n","      <td>men</td>\n","      <td>military</td>\n","      <td>old</td>\n","      <td>man</td>\n","      <td>man</td>\n","      <td>white</td>\n","      <td>having</td>\n","      <td>fat</td>\n","      <td>athlete</td>\n","      <td>men</td>\n","      <td>person</td>\n","      <td>dog</td>\n","      <td>rod</td>\n","      <td>lonely</td>\n","      <td>middle</td>\n","      <td>surfer</td>\n","      <td>baby</td>\n","      <td>man</td>\n","      <td>little</td>\n","      <td>person</td>\n","      <td>woman</td>\n","      <td>little</td>\n","      <td>american</td>\n","      <td>people</td>\n","      <td>skier</td>\n","      <td>girl</td>\n","      <td>girl</td>\n","      <td>boy</td>\n","      <td>woman</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>middle</td>\n","      <td>riding</td>\n","      <td>is</td>\n","      <td>are</td>\n","      <td>member</td>\n","      <td>man</td>\n","      <td>in</td>\n","      <td>wearing</td>\n","      <td>dog</td>\n","      <td>a</td>\n","      <td>,</td>\n","      <td>runs</td>\n","      <td>are</td>\n","      <td>is</td>\n","      <td>with</td>\n","      <td>crew</td>\n","      <td>skier</td>\n","      <td>-</td>\n","      <td>is</td>\n","      <td>is</td>\n","      <td>pushes</td>\n","      <td>girl</td>\n","      <td>using</td>\n","      <td>painting</td>\n","      <td>boy</td>\n","      <td>woman</td>\n","      <td>walk</td>\n","      <td>flies</td>\n","      <td>in</td>\n","      <td>in</td>\n","      <td>wearing</td>\n","      <td>wearing</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>-</td>\n","      <td>in</td>\n","      <td>talking</td>\n","      <td>riding</td>\n","      <td>talks</td>\n","      <td>sitting</td>\n","      <td>white</td>\n","      <td>safety</td>\n","      <td>is</td>\n","      <td>gathering</td>\n","      <td>old</td>\n","      <td>across</td>\n","      <td>having</td>\n","      <td>riding</td>\n","      <td>a</td>\n","      <td>,</td>\n","      <td>enjoys</td>\n","      <td>aged</td>\n","      <td>coming</td>\n","      <td>in</td>\n","      <td>a</td>\n","      <td>is</td>\n","      <td>a</td>\n","      <td>another</td>\n","      <td>is</td>\n","      <td>in</td>\n","      <td>in</td>\n","      <td>through</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>eastern</td>\n","      <td>a</td>\n","      <td>on</td>\n","      <td>on</td>\n","      <td>to</td>\n","      <td>on</td>\n","      <td>stands</td>\n","      <td>goggles</td>\n","      <td>airborne</td>\n","      <td>with</td>\n","      <td>man</td>\n","      <td>the</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>frisbee</td>\n","      <td>of</td>\n","      <td>the</td>\n","      <td>man</td>\n","      <td>in</td>\n","      <td>a</td>\n","      <td>child</td>\n","      <td>walking</td>\n","      <td>ladder</td>\n","      <td>woman</td>\n","      <td>wearing</td>\n","      <td>blue</td>\n","      <td>opposite</td>\n","      <td>the</td>\n","      <td>black</td>\n","      <td>cat</td>\n","      <td>birthday</td>\n","      <td>blue</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>men</td>\n","      <td>motorcycle</td>\n","      <td>his</td>\n","      <td>a</td>\n","      <td>another</td>\n","      <td>a</td>\n","      <td>in</td>\n","      <td>is</td>\n","      <td>whilst</td>\n","      <td>coats</td>\n","      <td>falls</td>\n","      <td>racing</td>\n","      <td>discussion</td>\n","      <td>horse</td>\n","      <td>,</td>\n","      <td>five</td>\n","      <td>slopes</td>\n","      <td>crouches</td>\n","      <td>from</td>\n","      <td>sandpit</td>\n","      <td>on</td>\n","      <td>a</td>\n","      <td>to</td>\n","      <td>'s</td>\n","      <td>a</td>\n","      <td>shirt</td>\n","      <td>directions</td>\n","      <td>air</td>\n","      <td>shirt</td>\n","      <td>costume</td>\n","      <td>hat</td>\n","      <td>shirt</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>selling</td>\n","      <td>they</td>\n","      <td>cellphone</td>\n","      <td>motorcycle</td>\n","      <td>while</td>\n","      <td>bus</td>\n","      <td>front</td>\n","      <td>repairing</td>\n","      <td>catching</td>\n","      <td>and</td>\n","      <td>asleep</td>\n","      <td>lanes</td>\n","      <td>behind</td>\n","      <td>down</td>\n","      <td>swimming</td>\n","      <td>,</td>\n","      <td>on</td>\n","      <td>in</td>\n","      <td>riding</td>\n","      <td>playing</td>\n","      <td>a</td>\n","      <td>dog</td>\n","      <td>paint</td>\n","      <td>fingernails</td>\n","      <td>snorkel</td>\n","      <td>looks</td>\n","      <td>across</td>\n","      <td>while</td>\n","      <td>playing</td>\n","      <td>looking</td>\n","      <td>plays</td>\n","      <td>typing</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>trinkets</td>\n","      <td>are</td>\n","      <td>in</td>\n","      <td>down</td>\n","      <td>on</td>\n","      <td>holding</td>\n","      <td>of</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>food</td>\n","      <td>in</td>\n","      <td>on</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>in</td>\n","      <td>repairing</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>with</td>\n","      <td>toy</td>\n","      <td>by</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>in</td>\n","      <td>down</td>\n","      <td>a</td>\n","      <td>doing</td>\n","      <td>a</td>\n","      <td>at</td>\n","      <td>in</td>\n","      <td>on</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>on</td>\n","      <td>both</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>the</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>bicycle</td>\n","      <td>green</td>\n","      <td>and</td>\n","      <td>the</td>\n","      <td>a</td>\n","      <td>tow</td>\n","      <td>dirt</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>beautiful</td>\n","      <td>dirty</td>\n","      <td>big</td>\n","      <td>a</td>\n","      <td>train</td>\n","      <td>the</td>\n","      <td>column</td>\n","      <td>bright</td>\n","      <td>a</td>\n","      <td>at</td>\n","      <td>brick</td>\n","      <td>a</td>\n","      <td>carnival</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>street</td>\n","      <td>wearing</td>\n","      <td>city</td>\n","      <td>road</td>\n","      <td>streets</td>\n","      <td>briefcase</td>\n","      <td>barbecue</td>\n","      <td>tire</td>\n","      <td>toy</td>\n","      <td>drinks</td>\n","      <td>chair</td>\n","      <td>track</td>\n","      <td>truck</td>\n","      <td>trail</td>\n","      <td>lake</td>\n","      <td>road</td>\n","      <td>day</td>\n","      <td>room</td>\n","      <td>wave</td>\n","      <td>bucket</td>\n","      <td>set</td>\n","      <td>water</td>\n","      <td>white</td>\n","      <td>purple</td>\n","      <td>bathtub</td>\n","      <td>food</td>\n","      <td>road</td>\n","      <td>trick</td>\n","      <td>game</td>\n","      <td>book</td>\n","      <td>puddle</td>\n","      <td>laptop</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>.</td>\n","      <td>helmets</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 S_1         S_2        S_3  ...     S_30      S_31     S_32\n","Time Steps                                   ...                            \n","1              <sos>       <sos>      <sos>  ...    <sos>     <sos>    <sos>\n","2              group         two          a  ...        a         a        a\n","3                 of       women        man  ...     girl       boy    woman\n","4             middle      riding         is  ...       in   wearing  wearing\n","5                  -          in    talking  ...        a         a        a\n","6            eastern           a         on  ...      cat  birthday     blue\n","7                men  motorcycle        his  ...  costume       hat    shirt\n","8            selling        they  cellphone  ...  looking     plays   typing\n","9           trinkets         are         in  ...       at        in       on\n","10                on        both          a  ...        a         a        a\n","11            street     wearing       city  ...     book    puddle   laptop\n","12                 .     helmets          .  ...        .         .        .\n","13             <eos>       <eos>      <eos>  ...    <eos>     <eos>    <eos>\n","\n","[13 rows x 32 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"HLV-t-MzVQdg"},"source":["## 用 LSTM 搭建 Encoder 類別: EncoderLSTM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0dZT3Zs17yMQ","executionInfo":{"status":"ok","timestamp":1612242469027,"user_tz":-480,"elapsed":38855,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"202054b5-fd04-4167-b0c9-378eeb5a76d9"},"source":["class EncoderLSTM(nn.Module):\n","    def __init__(self, input_size, embedding_size, hidden_size, num_layers, drop_rate):\n","        super(EncoderLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, \n","                            bidirectional=True, dropout=drop_rate)\n","        self.dropout = nn.Dropout(drop_rate)\n","\n","    def forward(self, x):\n","        embedding = self.dropout(self.embedding(x))\n","        outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n","        hidden_state = hidden_state.view(self.num_layers, -1, self.hidden_size * 2)\n","        cell_state = cell_state.view(self.num_layers, -1, self.hidden_size * 2)\n","\n","        return hidden_state, cell_state\n","\n","input_size_encoder = len(english.vocab)\n","encoder_embedding_size = 300\n","hidden_size = 256\n","num_layers = 2\n","encoder_dropout = 0.5\n","\n","encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n","                           hidden_size, num_layers, encoder_dropout).to(device)\n","print(encoder_lstm)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["EncoderLSTM(\n","  (embedding): Embedding(5893, 300)\n","  (LSTM): LSTM(300, 256, num_layers=2, dropout=0.5, bidirectional=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JTew1tbHVer5"},"source":["## 用 LSTM 搭建 decoder 類別: DecoderLSTM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPGbQiBP72iX","executionInfo":{"status":"ok","timestamp":1612242469027,"user_tz":-480,"elapsed":38851,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"e47b89f4-a734-4996-9138-9c64edda4a54"},"source":["class DecoderLSTM(nn.Module):\n","    def __init__(self, input_size, embedding_size, hidden_size,\n","                 num_layers, output_size, drop_rate):\n","        super(DecoderLSTM, self).__init__()\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.LSTM = nn.LSTM(embedding_size, hidden_size,\n","                            num_layers, dropout=drop_rate)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","        self.dropout = nn.Dropout(drop_rate)\n","\n","    def forward(self, x, hidden_state, cell_state):\n","        x = x.unsqueeze(0)\n","        embedding = self.dropout(self.embedding(x))\n","        outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n","        predictions = self.fc(outputs)\n","        predictions = predictions.squeeze(0)\n","\n","        return predictions, hidden_state, cell_state\n","\n","input_size_decoder = len(german.vocab)\n","decoder_embedding_size = 300\n","hidden_size = 512\n","num_layers = 2\n","decoder_dropout = 0.5\n","output_size = len(german.vocab)\n","\n","decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n","                           hidden_size, num_layers, output_size, decoder_dropout).to(device)\n","print(decoder_lstm)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["DecoderLSTM(\n","  (embedding): Embedding(7855, 300)\n","  (LSTM): LSTM(300, 512, num_layers=2, dropout=0.5)\n","  (fc): Linear(in_features=512, out_features=7855, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xof3dPly753w","executionInfo":{"status":"ok","timestamp":1612242469028,"user_tz":-480,"elapsed":38846,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"3812120d-980c-46b2-d7ef-da51a92222ce"},"source":["batch = next(iter(train_iterator))\n","print(batch.src.shape)\n","print(batch.trg.shape)\n","\n","x = batch.trg[1]\n","print(x)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["torch.Size([12, 32])\n","torch.Size([14, 32])\n","tensor([221,   5,  17,   8, 644,   8,   5,   5,  18,   8,   5,   8,   8,   8,\n","          5,   5,   5,   8,   5,  76,   5,   5,   5,   5,   5,  18,   5,   8,\n","         18,  18,   5,  18], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XGnQbCnGVire"},"source":["## Seq2Seq(Sequence to Sequence)類別"]},{"cell_type":"code","metadata":{"id":"_vzOor_Q782h","executionInfo":{"status":"ok","timestamp":1612242469293,"user_tz":-480,"elapsed":39110,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, Encoder_LSTM, Decoder_LSTM):\n","        super(Seq2Seq, self).__init__()\n","        self.Encoder_LSTM = Encoder_LSTM\n","        self.Decoder_LSTM = Decoder_LSTM\n","\n","    def forward(self, source, target, tfr=0.5):\n","        batch_size = source.shape[1]\n","        target_len = target.shape[0]\n","        target_vocab_size = len(german.vocab)\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n","\n","        hidden_state, cell_state = self.Encoder_LSTM(source)\n","\n","        x = target[0]   # Trigger token <SOS>\n","        for i in range(1, target_len):\n","            output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n","            outputs[i] = output\n","            best_guess = output.argmax(1)   # 0th dimension is batch size, 1st dimension is word embedding size\n","            # Either pass the next word correctly from the dataset or use the earlier predicted word\n","            x = target[i] if random.random() < tfr else best_guess\n","\n","        return outputs"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywW6f9fM8AMa","executionInfo":{"status":"ok","timestamp":1612242470647,"user_tz":-480,"elapsed":40462,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["# Hyperparameters\n","learning_rate = 0.001\n","step = 0\n","writer = SummaryWriter(os.path.join('runs', 'loss_plot'))\n","\n","model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","pad_idx = english.vocab.stoi['<pad>']\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yD0pRilG8CHJ","executionInfo":{"status":"ok","timestamp":1612242470651,"user_tz":-480,"elapsed":40462,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"650bf535-cfb4-4191-8eb3-fb6f4557f8fa"},"source":["model"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (Encoder_LSTM): EncoderLSTM(\n","    (embedding): Embedding(5893, 300)\n","    (LSTM): LSTM(300, 256, num_layers=2, dropout=0.5, bidirectional=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (Decoder_LSTM): DecoderLSTM(\n","    (embedding): Embedding(7855, 300)\n","    (LSTM): LSTM(300, 512, num_layers=2, dropout=0.5)\n","    (fc): Linear(in_features=512, out_features=7855, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"fQyZ_vfq8G6C","executionInfo":{"status":"ok","timestamp":1612242470652,"user_tz":-480,"elapsed":40462,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["def translate(model, sentence, english, german, device, max_length=50):\n","    if type(sentence) == str:\n","        tokens = tokenize_en(sentence)\n","    else:\n","        tokens = [token.lower() for token in sentence]\n","    tokens.insert(0, english.init_token)\n","    tokens.append(english.eos_token)\n","    text_to_indices = [english.vocab.stoi[token] for token in tokens]\n","    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n","\n","    # Build encoder hidden, cell state\n","    with torch.no_grad():\n","        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n","\n","    outputs = [german.vocab.stoi['<sos>']]\n","    for _ in range(max_length):\n","        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n","\n","        with torch.no_grad():\n","            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n","            best_guess = output.argmax(1).item()\n","\n","        outputs.append(best_guess)\n","\n","        # Model predicts it's the end of the sentence\n","        if output.argmax(1).item() == german.vocab.stoi['<eos>']:\n","            break\n","\n","    translated_sentence = [german.vocab.itos[idx] for idx in outputs]\n","    \n","    return translated_sentence[1:]   # ignore <sos> token"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"FM6XX_q15Epw","executionInfo":{"status":"ok","timestamp":1612242470652,"user_tz":-480,"elapsed":40459,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\r\n","    print('saving\\n')\r\n","    state = {'model': model, 'best_loss': best_loss, 'epoch': epoch,\r\n","             'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict()}\r\n","    torch.save(state, 'checkpoint-NMT')\r\n","    torch.save(model.state_dict(), 'checkpoint-NMT-SD')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCb4N52e5Rk7","executionInfo":{"status":"ok","timestamp":1612242470653,"user_tz":-480,"elapsed":40459,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["# 用來評估模型的函式: bleu\r\n","def bleu(data, model, english, german, device):\r\n","    targets, outputs = [], []\r\n","    for example in data:\r\n","        src = vars(example)[\"src\"]\r\n","        trg = vars(example)[\"trg\"]\r\n","\r\n","        prediction = translate(model, src, english, german, device)\r\n","        prediction = prediction[:-1]  # remove <eos> token\r\n","\r\n","        targets.append([trg])\r\n","        outputs.append(prediction)\r\n","\r\n","    return bleu_score(outputs, targets)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ysc4A5HX8Qyg","executionInfo":{"status":"ok","timestamp":1612244063710,"user_tz":-480,"elapsed":1633512,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"9f707a7d-a41d-4e9b-f634-64a0fb0e5917"},"source":["epoch_loss = 0.0\n","num_epochs = 30\n","best_loss = 999999\n","best_epoch = -1\n","sentence = 'a man in a blue shirt is standing on a ladder and cleaning a window'\n","ts = []\n","\n","for epoch in range(num_epochs):\n","    model.eval()\n","    print(f\"Epoch - {epoch + 1} / {num_epochs}\")\n","    translated_sentence = translate(model, sentence, english, german, device, max_length=50)\n","    print(f\"Translated example sentence: \\n {translated_sentence}\")\n","    ts.append(translated_sentence)\n","\n","    model.train()\n","    for batch_idx, batch in enumerate(train_iterator):\n","        input = batch.src.to(device)\n","        target = batch.trg.to(device)\n","\n","        # Pass the input and target for model's forward method\n","        output = model(input, target)\n","        output = output[1:].view(-1, output.shape[2])\n","        target = target[1:].view(-1)\n","\n","        # Calculate the loss value for every epoch\n","        loss = criterion(output, target)\n","        \n","        # Clear the accumulating gradients\n","        optimizer.zero_grad()\n","\n","        # Calculate the gradients for weights & biases using back-propagation\n","        loss.backward()\n","\n","        # Clip the gradient value is it exceeds > 5.0\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n","\n","        # Update the weights values using the gradients we calculated using bp \n","        optimizer.step()\n","        step += 1\n","        epoch_loss += loss.item()\n","        writer.add_scalar('Training loss', loss, global_step=step)\n","\n","    if epoch_loss < best_loss:\n","        best_epoch = epoch\n","        best_loss = epoch_loss\n","        checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss) \n","        if (epoch - best_epoch >= 10):\n","            print('no improvement in 10 epochs, break')\n","            break\n","    print(f\"Epoch_Loss - {loss.item()}\\n\")\n","\n","print(epoch_loss / len(train_iterator))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch - 1 / 30\n","Translated example sentence: \n"," ['verzieht', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd', 'polohemd']\n","saving\n","\n","Epoch_Loss - 4.2687249183654785\n","\n","Epoch - 2 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 4.260138988494873\n","\n","Epoch - 3 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'blauen', 'oberteil', 'und', 'einem', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 4.642498970031738\n","\n","Epoch - 4 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 5.319961071014404\n","\n","Epoch - 5 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.7702765464782715\n","\n","Epoch - 6 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', 'auf', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 4.037022590637207\n","\n","Epoch - 7 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.3415582180023193\n","\n","Epoch - 8 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 4.168022632598877\n","\n","Epoch - 9 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'schwarzen', 'hemd', 'und', 'mit', 'einem', '<unk>', 'auf', 'einem', '.', '.', '<eos>']\n","Epoch_Loss - 3.881467819213867\n","\n","Epoch - 10 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'und', 'mit', 'einem', 'auf', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.855595350265503\n","\n","Epoch - 11 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 4.161566257476807\n","\n","Epoch - 12 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', '<unk>', 'und', 'und', 'mit', 'einem', 'einem', '.', '<eos>']\n","Epoch_Loss - 4.59500789642334\n","\n","Epoch - 13 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.662956714630127\n","\n","Epoch - 14 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'weißen', 'hemd', 'und', 'mit', 'einem', 'in', 'einem', '.', '<eos>']\n","Epoch_Loss - 3.2346928119659424\n","\n","Epoch - 15 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'weißen', 'hemd', 'und', 'mit', 'einem', 'auf', 'einem', '.', '.', '<eos>']\n","Epoch_Loss - 3.0941030979156494\n","\n","Epoch - 16 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 4.649043083190918\n","\n","Epoch - 17 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', 'einem', 'in', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 4.326573848724365\n","\n","Epoch - 18 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 4.307596206665039\n","\n","Epoch - 19 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', 'einem', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.9969351291656494\n","\n","Epoch - 20 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', 'einem', 'einem', '.', '<eos>']\n","Epoch_Loss - 3.947171926498413\n","\n","Epoch - 21 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.751147747039795\n","\n","Epoch - 22 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', 'in', 'einem', '.', '<eos>']\n","Epoch_Loss - 3.442540168762207\n","\n","Epoch - 23 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', 'einem', 'in', 'einem', '.', '.', '<eos>']\n","Epoch_Loss - 3.7050676345825195\n","\n","Epoch - 24 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.524132490158081\n","\n","Epoch - 25 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', '<unk>', 'in', '.', '<eos>']\n","Epoch_Loss - 2.995271921157837\n","\n","Epoch - 26 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', 'in', 'einem', '.', '<eos>']\n","Epoch_Loss - 3.500072956085205\n","\n","Epoch - 27 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.699098587036133\n","\n","Epoch - 28 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'und', 'mit', 'einem', 'in', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.4514122009277344\n","\n","Epoch - 29 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', '<unk>', 'und', 'und', '<unk>', ',', 'einem', '<unk>', '.', '<eos>']\n","Epoch_Loss - 3.9244813919067383\n","\n","Epoch - 30 / 30\n","Translated example sentence: \n"," ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', 'in', 'einem', '.', '<eos>']\n","Epoch_Loss - 3.7133350372314453\n","\n","114.88715209903107\n"],"name":"stdout"}]}]}