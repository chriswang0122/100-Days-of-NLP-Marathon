{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5Pf_RxOIAYv"
   },
   "source": [
    "### 作業目的: 透過實作加速版word2vec Skip-gram模型來更加了解高速版的word2vec\n",
    "\n",
    "本次作業會採用Penn Tree Bank資料集，學員可以在ptb.train.txt中取得訓練文本資料。這次作業可以讓學員練習到以pytorch搭建模型與進行文本資料的前處理\n",
    "\n",
    "PS: 建議學員使用Colab (或可以使用GPU加速的機器)來進行作業，不然訓練會訓練到天荒地老....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKKpFV6GJwhs"
   },
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1317,
     "status": "ok",
     "timestamp": 1610551227733,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "Yjz-fWmbJRPB"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1713,
     "status": "ok",
     "timestamp": 1610551228135,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "i9xrgPu3KBgJ",
    "outputId": "b6a19d9f-52e0-4687-f192-7a4dc237693d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 42068 lines\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料\n",
    "# Penn TreeBank dataset\n",
    "with open(\"ptb.train.txt\", encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "print(f\"Total {len(lines)} lines\")\n",
    "raw_dataset = [line.split() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1707,
     "status": "ok",
     "timestamp": 1610551228136,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "oAcF_5CQKH_J",
    "outputId": "695665cd-9b4e-4396-9919-c046ddfb3d60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aer',\n",
       "  'banknote',\n",
       "  'berlitz',\n",
       "  'calloway',\n",
       "  'centrust',\n",
       "  'cluett',\n",
       "  'fromstein',\n",
       "  'gitano',\n",
       "  'guterman',\n",
       "  'hydro-quebec',\n",
       "  'ipo',\n",
       "  'kia',\n",
       "  'memotec',\n",
       "  'mlx',\n",
       "  'nahb',\n",
       "  'punts',\n",
       "  'rake',\n",
       "  'regatta',\n",
       "  'rubens',\n",
       "  'sim',\n",
       "  'snack-food',\n",
       "  'ssangyong',\n",
       "  'swapo',\n",
       "  'wachter'],\n",
       " ['pierre',\n",
       "  '<unk>',\n",
       "  'N',\n",
       "  'years',\n",
       "  'old',\n",
       "  'will',\n",
       "  'join',\n",
       "  'the',\n",
       "  'board',\n",
       "  'as',\n",
       "  'a',\n",
       "  'nonexecutive',\n",
       "  'director',\n",
       "  'nov.',\n",
       "  'N'],\n",
       " ['mr.',\n",
       "  '<unk>',\n",
       "  'is',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  '<unk>',\n",
       "  'n.v.',\n",
       "  'the',\n",
       "  'dutch',\n",
       "  'publishing',\n",
       "  'group'],\n",
       " ['rudolph',\n",
       "  '<unk>',\n",
       "  'N',\n",
       "  'years',\n",
       "  'old',\n",
       "  'and',\n",
       "  'former',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  'consolidated',\n",
       "  'gold',\n",
       "  'fields',\n",
       "  'plc',\n",
       "  'was',\n",
       "  'named',\n",
       "  'a',\n",
       "  'nonexecutive',\n",
       "  'director',\n",
       "  'of',\n",
       "  'this',\n",
       "  'british',\n",
       "  'industrial',\n",
       "  'conglomerate'],\n",
       " ['a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'asbestos',\n",
       "  'once',\n",
       "  'used',\n",
       "  'to',\n",
       "  'make',\n",
       "  'kent',\n",
       "  'cigarette',\n",
       "  'filters',\n",
       "  'has',\n",
       "  'caused',\n",
       "  'a',\n",
       "  'high',\n",
       "  'percentage',\n",
       "  'of',\n",
       "  'cancer',\n",
       "  'deaths',\n",
       "  'among',\n",
       "  'a',\n",
       "  'group',\n",
       "  'of',\n",
       "  'workers',\n",
       "  'exposed',\n",
       "  'to',\n",
       "  'it',\n",
       "  'more',\n",
       "  'than',\n",
       "  'N',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'researchers',\n",
       "  'reported']]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看前5筆\n",
    "raw_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3107,
     "status": "ok",
     "timestamp": 1610551229541,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "3oki6AxhJyj4",
    "outputId": "ebd8f47e-0349-4ad9-d0e0-2af5891e574b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before subsampling: 885720 words\n",
      "After subsampling: 511580 words\n"
     ]
    }
   ],
   "source": [
    "# 定義資料前處理函式\n",
    "class PreProcessor():\n",
    "    '''Function to do preprocess of input corpus\n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: str\n",
    "        input corpus to be processed\n",
    "    only_word: bool\n",
    "        whether to filter out non-word\n",
    "    min_freq: int\n",
    "        minimum frequency of a word to be kept\n",
    "    do_subsampling: bool\n",
    "        whether to do subsampling\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, only_word: bool=False, min_freq: int=5, do_subsampling: bool=True, t: float=1e-5):\n",
    "        self.only_word = only_word\n",
    "        self.min_freq = min_freq\n",
    "        self.do_subsampling = do_subsampling\n",
    "        self.t = t\n",
    "    \n",
    "    def process(self, corpus: List[List[str]]):\n",
    "        counter = Counter()\n",
    "        processed_sentence = []\n",
    "        \n",
    "        for sentence in corpus:\n",
    "            # hint: 請計算字詞頻率\n",
    "            counter.update(sentence)\n",
    "            processed_sentence.append(sentence)\n",
    "    \n",
    "        # hint: 移除頻率過小的字詞 建立word2idx與idx2word與word_frequency辭典\n",
    "        word_cnt = dict(filter(lambda x: x[1] > self.min_freq, counter.items()))\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(word_cnt.keys())}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        self.word_frequency = word_cnt\n",
    "        \n",
    "        # 將文本轉為ID形式與移除文本中頻率過小的文字\n",
    "        self.processed_corpus = [[self.word2idx[word] for word in line if word in self.word2idx] for line in processed_sentence]\n",
    "        self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
    "        print(f\"Before subsampling: {self.total_num_words} words\")\n",
    "        \n",
    "        # 進行二次採樣(subsampling)\n",
    "        if self.do_subsampling:\n",
    "            self.processed_corpus = [[idx for idx in line if not self.subsampling(idx)] for line in self.processed_corpus]\n",
    "            self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
    "            counter = Counter([self.idx2word[idx] for line in self.processed_corpus for idx in line])\n",
    "            self.word_frequency = dict(counter.items())\n",
    "            print(f\"After subsampling: {self.total_num_words} words\")\n",
    "        \n",
    "        # hint: 移除空字串\n",
    "        self.processed_corpus = [line for line in self.processed_corpus if len(line) != 0]\n",
    "        \n",
    "        return self.processed_corpus, self.word2idx, self.idx2word, self.word_frequency, self.total_num_words\n",
    "    \n",
    "    def subsampling(self, idx):\n",
    "        # hint: 學員可以參考講義的subsampling公式(也可自己定義一個)\n",
    "        # following original paper: https://arxiv.org/abs/1310.4546\n",
    "        p_drop = 1.0 - math.sqrt(self.t / (self.word_frequency[self.idx2word[idx]] / self.total_num_words))\n",
    "        \n",
    "        return random.random() < (1 - p_drop)\n",
    "\n",
    "\n",
    "# 進行資料前處理\n",
    "# 這邊我們subsampling的t取1e-4\n",
    "pre_processor = PreProcessor(True, 5, True, 1e-4)\n",
    "corpus, word2idx, idx2word, word2freq, total_num_words = pre_processor.process(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfDuJuT5Kkvl"
   },
   "source": [
    "### 定義Skip-gram使用的Dataset與collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3103,
     "status": "ok",
     "timestamp": 1610551229542,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "DraniEYMKfWl"
   },
   "outputs": [],
   "source": [
    "# 客製化Dataset\n",
    "class SkipGramGetAllDataset(Dataset):\n",
    "    def __init__(self, corpus, word2freq, word2idx, idx2word, window_size, num_negatives):\n",
    "        self.corpus = corpus\n",
    "        self.word2freq = word2freq\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.window_size = window_size\n",
    "        self.num_negatives = num_negatives\n",
    "        \n",
    "        self.all_targets, self.all_contexts = self._get_all_contexts_targets()\n",
    "        self.all_negatives = self._get_all_negatives()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # hint: 這裡我們會返回 目標字詞，上下文，負採樣樣本\n",
    "        return self.all_targets[idx], self.all_contexts[idx], self.all_negatives[idx]\n",
    "        \n",
    "    def _get_all_contexts_targets(self):\n",
    "        all_targets = []\n",
    "        all_contexts = []\n",
    "        \n",
    "        for line in self.corpus:\n",
    "            if len(line) < 2 * self.window_size + 1:\n",
    "                continue\n",
    "            \n",
    "            # hint: 這邊我們要創建上下文(考慮window_size)\n",
    "            all_contexts += line[self.window_size:-self.window_size]\n",
    "\n",
    "            targets = []\n",
    "            for idx in range(self.window_size, len(line) - self.window_size):\n",
    "                # hint: 創建目標字詞\n",
    "                indices = list(range(idx - self.window_size, idx + self.window_size + 1))\n",
    "                indices.remove(idx)\n",
    "                all_targets.append([line[i] for i in indices])\n",
    "\n",
    "        return all_targets, all_contexts\n",
    "                               \n",
    "    \n",
    "    def _get_all_negatives(self):\n",
    "        # hint: 進行負採樣，若沒頭緒的學員可以參考實作範例\n",
    "        cur_exists_words = list(self.word2freq.keys())\n",
    "        sampling_weights = [self.word2freq[word] ** 0.75 for word in self.word2freq]\n",
    "        population = list(range(len(sampling_weights)))\n",
    "        \n",
    "        all_negatives = []\n",
    "        for targets in self.all_targets:\n",
    "            negatives = []\n",
    "            while len(negatives) < self.num_negatives:\n",
    "                neg_candidate = random.choices(population, sampling_weights)[0]\n",
    "                neg_cnadidate = self.word2idx[cur_exists_words[neg_candidate]]\n",
    "                if neg_candidate not in targets:\n",
    "                    negatives.append(neg_candidate)\n",
    "            all_negatives.append(negatives)\n",
    "        \n",
    "        return all_negatives\n",
    "    \n",
    "# 客製化collate_fn\n",
    "def skipgram_collate(data):\n",
    "    contexts = []\n",
    "    target_negative = []\n",
    "    labels = []\n",
    "    for target, context, negative in data:\n",
    "        # hint: 將目標字詞、上下文與負採樣樣本個別打包\n",
    "        target_negative += [target + negative]\n",
    "        labels += [[1] * len(target) + [0] * len(negative)]\n",
    "        contexts += [context]\n",
    "    \n",
    "    return torch.tensor(contexts), torch.tensor(target_negative), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s94kJ0lKKzG5"
   },
   "source": [
    "### 定義Skip-gram模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3099,
     "status": "ok",
     "timestamp": 1610551229542,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "kyyQyLxcKpv1"
   },
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.in_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.out_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "    def forward(self, contexts, targets):\n",
    "        v = self.in_embedding(contexts)\n",
    "        u = self.out_embedding(targets)\n",
    "        \n",
    "        # do dot product to get output\n",
    "        pred = torch.matmul(v.unsqueeze(1), u.permute(0,2,1))\n",
    "        \n",
    "        return pred.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHZIFz7yK5An"
   },
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 87117,
     "status": "ok",
     "timestamp": 1610551313565,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "Hr4sVBd8K10T"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "use_cuda = torch.cuda.is_available()\n",
    "verbose = True\n",
    "num_epochs = 100\n",
    "batch_size = 512\n",
    "embed_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "model = SkipGram(len(word2idx), embed_size)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)  # 學員可以自行選用optimizer\n",
    "dataset = SkipGramGetAllDataset(corpus, word2freq, word2idx, idx2word, 1, 5)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=skipgram_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 478436,
     "status": "ok",
     "timestamp": 1610551704893,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "sE28LW2_LB0I",
    "outputId": "13323dff-28b7-452a-c54b-d927217effda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Batch: 501/836.9296875 Loss: 0.97601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:03<06:25,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 0.72939\n",
      "Epoch: 2/100, Batch: 501/836.9296875 Loss: 0.28657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:07<06:20,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100, Loss: 0.28172\n",
      "Epoch: 3/100, Batch: 501/836.9296875 Loss: 0.25316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:11<06:22,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100, Loss: 0.25422\n",
      "Epoch: 4/100, Batch: 501/836.9296875 Loss: 0.24335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:15<06:14,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100, Loss: 0.24502\n",
      "Epoch: 5/100, Batch: 501/836.9296875 Loss: 0.23861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:19<06:09,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100, Loss: 0.24056\n",
      "Epoch: 6/100, Batch: 501/836.9296875 Loss: 0.23604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:23<06:11,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100, Loss: 0.23803\n",
      "Epoch: 7/100, Batch: 501/836.9296875 Loss: 0.23475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:27<06:04,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100, Loss: 0.23637\n",
      "Epoch: 8/100, Batch: 501/836.9296875 Loss: 0.23296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:31<05:57,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100, Loss: 0.23520\n",
      "Epoch: 9/100, Batch: 501/836.9296875 Loss: 0.23219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:35<05:58,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100, Loss: 0.23427\n",
      "Epoch: 10/100, Batch: 501/836.9296875 Loss: 0.23195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:39<05:52,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100, Loss: 0.23374\n",
      "Epoch: 11/100, Batch: 501/836.9296875 Loss: 0.23115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:43<05:47,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100, Loss: 0.23304\n",
      "Epoch: 12/100, Batch: 501/836.9296875 Loss: 0.23074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:47<05:47,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100, Loss: 0.23273\n",
      "Epoch: 13/100, Batch: 501/836.9296875 Loss: 0.23061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:50<05:41,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100, Loss: 0.23243\n",
      "Epoch: 14/100, Batch: 501/836.9296875 Loss: 0.23007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:54<05:36,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100, Loss: 0.23208\n",
      "Epoch: 15/100, Batch: 501/836.9296875 Loss: 0.23005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:58<05:36,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100, Loss: 0.23189\n",
      "Epoch: 16/100, Batch: 501/836.9296875 Loss: 0.22954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:02<05:30,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100, Loss: 0.23167\n",
      "Epoch: 17/100, Batch: 501/836.9296875 Loss: 0.22953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:06<05:24,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100, Loss: 0.23145\n",
      "Epoch: 18/100, Batch: 501/836.9296875 Loss: 0.22928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:10<05:23,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100, Loss: 0.23140\n",
      "Epoch: 19/100, Batch: 501/836.9296875 Loss: 0.22935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:14<05:17,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100, Loss: 0.23121\n",
      "Epoch: 20/100, Batch: 501/836.9296875 Loss: 0.22959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:18<05:14,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100, Loss: 0.23114\n",
      "Epoch: 21/100, Batch: 501/836.9296875 Loss: 0.22923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:22<05:13,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100, Loss: 0.23089\n",
      "Epoch: 22/100, Batch: 501/836.9296875 Loss: 0.22891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:26<05:05,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100, Loss: 0.23088\n",
      "Epoch: 23/100, Batch: 501/836.9296875 Loss: 0.22867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:30<04:59,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100, Loss: 0.23085\n",
      "Epoch: 24/100, Batch: 501/836.9296875 Loss: 0.22884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:34<04:59,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100, Loss: 0.23075\n",
      "Epoch: 25/100, Batch: 501/836.9296875 Loss: 0.22846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:38<04:53,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100, Loss: 0.23077\n",
      "Epoch: 26/100, Batch: 501/836.9296875 Loss: 0.22828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:41<04:48,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100, Loss: 0.23064\n",
      "Epoch: 27/100, Batch: 501/836.9296875 Loss: 0.22871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:45<04:47,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100, Loss: 0.23062\n",
      "Epoch: 28/100, Batch: 501/836.9296875 Loss: 0.22855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:49<04:42,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100, Loss: 0.23061\n",
      "Epoch: 29/100, Batch: 501/836.9296875 Loss: 0.22825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:53<04:37,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100, Loss: 0.23052\n",
      "Epoch: 30/100, Batch: 501/836.9296875 Loss: 0.22853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [01:57<04:36,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100, Loss: 0.23049\n",
      "Epoch: 31/100, Batch: 501/836.9296875 Loss: 0.22845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:01<04:31,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100, Loss: 0.23033\n",
      "Epoch: 32/100, Batch: 501/836.9296875 Loss: 0.22875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [02:05<04:25,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100, Loss: 0.23042\n",
      "Epoch: 33/100, Batch: 501/836.9296875 Loss: 0.22855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [02:09<04:24,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100, Loss: 0.23038\n",
      "Epoch: 34/100, Batch: 501/836.9296875 Loss: 0.22848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [02:13<04:19,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100, Loss: 0.23030\n",
      "Epoch: 35/100, Batch: 501/836.9296875 Loss: 0.22851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [02:17<04:13,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100, Loss: 0.23033\n",
      "Epoch: 36/100, Batch: 501/836.9296875 Loss: 0.22817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:21<04:12,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100, Loss: 0.23022\n",
      "Epoch: 37/100, Batch: 501/836.9296875 Loss: 0.22830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [02:25<04:06,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100, Loss: 0.23018\n",
      "Epoch: 38/100, Batch: 501/836.9296875 Loss: 0.22834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [02:28<04:00,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100, Loss: 0.23021\n",
      "Epoch: 39/100, Batch: 501/836.9296875 Loss: 0.22807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [02:33<04:00,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100, Loss: 0.23016\n",
      "Epoch: 40/100, Batch: 501/836.9296875 Loss: 0.22856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [02:36<03:55,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100, Loss: 0.23013\n",
      "Epoch: 41/100, Batch: 501/836.9296875 Loss: 0.22833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [02:40<03:49,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100, Loss: 0.23014\n",
      "Epoch: 42/100, Batch: 501/836.9296875 Loss: 0.22845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [02:44<03:48,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100, Loss: 0.23022\n",
      "Epoch: 43/100, Batch: 501/836.9296875 Loss: 0.22839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [02:48<03:43,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100, Loss: 0.23006\n",
      "Epoch: 44/100, Batch: 501/836.9296875 Loss: 0.22834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [02:52<03:37,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100, Loss: 0.23014\n",
      "Epoch: 45/100, Batch: 501/836.9296875 Loss: 0.22841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [02:56<03:35,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100, Loss: 0.22999\n",
      "Epoch: 46/100, Batch: 501/836.9296875 Loss: 0.22878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [03:00<03:30,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100, Loss: 0.23007\n",
      "Epoch: 47/100, Batch: 501/836.9296875 Loss: 0.22810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [03:04<03:27,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100, Loss: 0.23004\n",
      "Epoch: 48/100, Batch: 501/836.9296875 Loss: 0.22776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [03:08<03:27,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100, Loss: 0.22991\n",
      "Epoch: 49/100, Batch: 501/836.9296875 Loss: 0.22778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [03:12<03:22,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100, Loss: 0.23002\n",
      "Epoch: 50/100, Batch: 501/836.9296875 Loss: 0.22779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [03:16<03:16,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100, Loss: 0.22990\n",
      "Epoch: 51/100, Batch: 501/836.9296875 Loss: 0.22800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [03:20<03:14,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100, Loss: 0.22996\n",
      "Epoch: 52/100, Batch: 501/836.9296875 Loss: 0.22790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [03:24<03:09,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100, Loss: 0.22993\n",
      "Epoch: 53/100, Batch: 501/836.9296875 Loss: 0.22791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [03:27<03:03,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100, Loss: 0.22991\n",
      "Epoch: 54/100, Batch: 501/836.9296875 Loss: 0.22764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [03:32<03:02,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100, Loss: 0.22983\n",
      "Epoch: 55/100, Batch: 501/836.9296875 Loss: 0.22843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [03:35<02:56,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100, Loss: 0.22995\n",
      "Epoch: 56/100, Batch: 501/836.9296875 Loss: 0.22836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [03:39<02:51,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100, Loss: 0.22982\n",
      "Epoch: 57/100, Batch: 501/836.9296875 Loss: 0.22842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [03:43<02:49,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100, Loss: 0.22988\n",
      "Epoch: 58/100, Batch: 501/836.9296875 Loss: 0.22776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [03:47<02:45,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100, Loss: 0.22981\n",
      "Epoch: 59/100, Batch: 501/836.9296875 Loss: 0.22785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [03:51<02:41,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100, Loss: 0.22983\n",
      "Epoch: 60/100, Batch: 501/836.9296875 Loss: 0.22816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [03:55<02:38,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100, Loss: 0.22977\n",
      "Epoch: 61/100, Batch: 501/836.9296875 Loss: 0.22767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [03:59<02:33,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100, Loss: 0.22985\n",
      "Epoch: 62/100, Batch: 501/836.9296875 Loss: 0.22820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [04:03<02:29,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100, Loss: 0.22983\n",
      "Epoch: 63/100, Batch: 501/836.9296875 Loss: 0.22788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [04:07<02:26,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100, Loss: 0.22980\n",
      "Epoch: 64/100, Batch: 501/836.9296875 Loss: 0.22771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [04:11<02:20,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100, Loss: 0.22978\n",
      "Epoch: 65/100, Batch: 501/836.9296875 Loss: 0.22766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [04:15<02:15,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100, Loss: 0.22982\n",
      "Epoch: 66/100, Batch: 501/836.9296875 Loss: 0.22775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [04:19<02:13,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100, Loss: 0.22975\n",
      "Epoch: 67/100, Batch: 501/836.9296875 Loss: 0.22783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [04:22<02:08,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100, Loss: 0.22977\n",
      "Epoch: 68/100, Batch: 501/836.9296875 Loss: 0.22746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [04:27<02:06,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100, Loss: 0.22978\n",
      "Epoch: 69/100, Batch: 501/836.9296875 Loss: 0.22771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [04:30<02:01,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100, Loss: 0.22969\n",
      "Epoch: 70/100, Batch: 501/836.9296875 Loss: 0.22784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [04:34<01:56,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100, Loss: 0.22976\n",
      "Epoch: 71/100, Batch: 501/836.9296875 Loss: 0.22736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [04:38<01:53,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100, Loss: 0.22977\n",
      "Epoch: 72/100, Batch: 501/836.9296875 Loss: 0.22767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [04:42<01:48,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100, Loss: 0.22965\n",
      "Epoch: 73/100, Batch: 501/836.9296875 Loss: 0.22782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [04:46<01:44,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100, Loss: 0.22976\n",
      "Epoch: 74/100, Batch: 501/836.9296875 Loss: 0.22803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [04:50<01:42,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100, Loss: 0.22968\n",
      "Epoch: 75/100, Batch: 501/836.9296875 Loss: 0.22765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [04:54<01:37,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100, Loss: 0.22971\n",
      "Epoch: 76/100, Batch: 501/836.9296875 Loss: 0.22781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [04:57<01:32,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100, Loss: 0.22968\n",
      "Epoch: 77/100, Batch: 501/836.9296875 Loss: 0.22797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [05:02<01:30,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100, Loss: 0.22964\n",
      "Epoch: 78/100, Batch: 501/836.9296875 Loss: 0.22740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [05:05<01:25,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100, Loss: 0.22967\n",
      "Epoch: 79/100, Batch: 501/836.9296875 Loss: 0.22765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [05:09<01:21,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100, Loss: 0.22967\n",
      "Epoch: 80/100, Batch: 501/836.9296875 Loss: 0.22811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [05:13<01:18,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100, Loss: 0.22969\n",
      "Epoch: 81/100, Batch: 501/836.9296875 Loss: 0.22745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [05:17<01:14,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100, Loss: 0.22974\n",
      "Epoch: 82/100, Batch: 501/836.9296875 Loss: 0.22721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [05:21<01:09,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100, Loss: 0.22966\n",
      "Epoch: 83/100, Batch: 501/836.9296875 Loss: 0.22799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [05:25<01:06,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100, Loss: 0.22965\n",
      "Epoch: 84/100, Batch: 501/836.9296875 Loss: 0.22747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [05:29<01:02,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100, Loss: 0.22967\n",
      "Epoch: 85/100, Batch: 501/836.9296875 Loss: 0.22737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [05:33<00:58,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100, Loss: 0.22963\n",
      "Epoch: 86/100, Batch: 501/836.9296875 Loss: 0.22740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [05:36<00:54,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100, Loss: 0.22955\n",
      "Epoch: 87/100, Batch: 501/836.9296875 Loss: 0.22796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [05:40<00:50,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100, Loss: 0.22970\n",
      "Epoch: 88/100, Batch: 501/836.9296875 Loss: 0.22742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [05:44<00:46,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100, Loss: 0.22967\n",
      "Epoch: 89/100, Batch: 501/836.9296875 Loss: 0.22792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [05:48<00:43,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100, Loss: 0.22959\n",
      "Epoch: 90/100, Batch: 501/836.9296875 Loss: 0.22777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [05:52<00:38,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100, Loss: 0.22963\n",
      "Epoch: 91/100, Batch: 501/836.9296875 Loss: 0.22759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [05:56<00:34,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100, Loss: 0.22967\n",
      "Epoch: 92/100, Batch: 501/836.9296875 Loss: 0.22754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [06:00<00:31,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100, Loss: 0.22961\n",
      "Epoch: 93/100, Batch: 501/836.9296875 Loss: 0.22774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [06:04<00:27,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100, Loss: 0.22962\n",
      "Epoch: 94/100, Batch: 501/836.9296875 Loss: 0.22743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [06:07<00:23,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100, Loss: 0.22962\n",
      "Epoch: 95/100, Batch: 501/836.9296875 Loss: 0.22733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [06:11<00:19,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100, Loss: 0.22955\n",
      "Epoch: 96/100, Batch: 501/836.9296875 Loss: 0.22780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [06:15<00:15,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100, Loss: 0.22962\n",
      "Epoch: 97/100, Batch: 501/836.9296875 Loss: 0.22772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [06:19<00:11,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100, Loss: 0.22957\n",
      "Epoch: 98/100, Batch: 501/836.9296875 Loss: 0.22707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [06:23<00:07,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100, Loss: 0.22956\n",
      "Epoch: 99/100, Batch: 501/836.9296875 Loss: 0.22823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [06:27<00:03,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100, Loss: 0.22955\n",
      "Epoch: 100/100, Batch: 501/836.9296875 Loss: 0.22785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:31<00:00,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100, Loss: 0.22959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "lst_loss = []\n",
    "model.train()\n",
    "for ep in tqdm.tqdm(range(num_epochs)):\n",
    "    batch_loss = 0\n",
    "    for i, (contexts, target_negative, labels) in enumerate(loader, 1):\n",
    "        # hint: 開始訓練前要先將optimizer的梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_cuda:\n",
    "            contexts = contexts.cuda()\n",
    "            target_negative = target_negative.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        pred = model(contexts, target_negative)\n",
    "        loss = criterion(pred, labels.float())\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(f\"Epoch: {ep + 1}/{num_epochs}, Batch: {i + 1}/{len(dataset) / batch_size} Loss: {batch_loss / i:.5f}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Epoch: {ep + 1}/{num_epochs}, Loss: {batch_loss / i:.5f}\")\n",
    "\n",
    "    lst_loss.append(batch_loss/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 478431,
     "status": "ok",
     "timestamp": 1610551704894,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "y0rt5W2ELLvP",
    "outputId": "50df8ffc-bd0b-4f29-eb0d-59944c04c30d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(lst_loss, marker='s')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Word2Vec Skip-gram Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 478428,
     "status": "ok",
     "timestamp": 1610551704895,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "43pOYRh-MX_F",
    "outputId": "d3612e8c-eb38-4eb4-da22-9e2b4defc81d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.391: barrel.\n",
      "cosine sim=0.347: fought.\n",
      "cosine sim=0.336: ahmanson.\n",
      "cosine sim=0.332: laundering.\n"
     ]
    }
   ],
   "source": [
    "# 計算字詞相似度\n",
    "def get_similarity(word, top_k, model, word2idx, idx2word):\n",
    "    W = (model.in_embedding.weight.data + model.out_embedding.weight.data) / 2\n",
    "    idx = word2idx.get(word, None)\n",
    "    \n",
    "    if not idx:\n",
    "        # 當出現不在字典中的字詞時，顯示Out of vocabulary error\n",
    "        raise ValueError(\"Out of vocabulary\")\n",
    "    else:\n",
    "        x = W[idx]\n",
    "        # 使用cosine相似計算字詞間的相似程度\n",
    "        cos = torch.matmul(W, x) / (torch.sum(W * W, dim=-1) * torch.sum(x * x) + 1e-9).sqrt()\n",
    "        _, topk = torch.topk(cos, top_k + 1)\n",
    "        \n",
    "        for i in topk[1:]:\n",
    "            print(f\"cosine sim={cos[int(i)]:.3f}: {idx2word[int(i)]}.\")\n",
    "\n",
    "get_similarity('love', 4, model, word2idx, idx2word)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "word2vec高速化_作業.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
