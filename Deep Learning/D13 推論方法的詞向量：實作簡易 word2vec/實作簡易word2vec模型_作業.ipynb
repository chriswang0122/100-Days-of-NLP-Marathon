{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuRqMFQvubkz"
   },
   "source": [
    "### 作業目的: 實作word2vec Skip-gram模型\n",
    "在課程中了解如何搭建CBOW模型，這次的作業目的在於透過搭建Skip-gram模型來了解另外一種word2vec的架構。\n",
    "\n",
    "- Hint_1: 學員可以善用課程中以搭建好的function模組\n",
    "- Hint_2: Skip_gram所需的輸入資料與目標跟CBOW有些許不同，Skip_gram是由中間字詞預測上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1610367914831,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "JqCGzQPVubk7"
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils.utility import preprocess, convert_one_hot, Trainer\n",
    "from utils.layers import Dense, SoftmaxWithCrossEntropy\n",
    "from utils.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1492,
     "status": "ok",
     "timestamp": 1610367915199,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "_Nw5L5_8ubk8",
    "outputId": "2a4c9ec9-a1a4-45cf-cce0-8cc3e8a4d02f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 4, 7, 5, 3, 1]),\n",
       " array([[6, 4],\n",
       "        [2, 7],\n",
       "        [4, 5],\n",
       "        [7, 3],\n",
       "        [5, 1],\n",
       "        [3, 0]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same corpus as in the lecture\n",
    "text = \"I am studying Natural Language Processing now.\"\n",
    "\n",
    "# define create_contexts_target function\n",
    "def create_contexts_target(corpus: List, window_size: int=1):\n",
    "    contexts = corpus[window_size:-window_size]\n",
    "    targets = []\n",
    "    for idx in range(window_size, len(corpus) - window_size):\n",
    "        indices = list(range(idx - window_size, idx + window_size + 1))\n",
    "        indices.remove(idx)\n",
    "        ts = [corpus[i] for i in indices]\n",
    "        targets.append(ts)\n",
    "\n",
    "    return np.array(contexts), np.array(targets)\n",
    "\n",
    "# transform corpus to contexts and targets pair\n",
    "corpus, word2idx, idx2word = preprocess([text])\n",
    "contexts, targets = create_contexts_target(corpus[0], window_size=1)\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1488,
     "status": "ok",
     "timestamp": 1610367915200,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "YcxHObOPubk-",
    "outputId": "131aeb79-f7f2-481a-dfa1-8d095e234160",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0]], dtype=int32),\n",
       " array([[[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1]],\n",
       " \n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0]]], dtype=int32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform contexts and targets to one-hot encoding\n",
    "contexts = convert_one_hot(contexts, len(word2idx))\n",
    "targets = convert_one_hot(targets, len(word2idx))\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1483,
     "status": "ok",
     "timestamp": 1610367915200,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "HnLqi9QXubk-"
   },
   "outputs": [],
   "source": [
    "# define Skip-gram model\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # initialize weights\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # create layers\n",
    "        self.in_layer = Dense(W_in)\n",
    "        self.out_layer = Dense(W_out)\n",
    "        self.loss_layers = [SoftmaxWithCrossEntropy() for i in range(window_size * 2)]\n",
    "\n",
    "        layers = [self.in_layer, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # word vector matrix\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        h = self.in_layer.forward(contexts)\n",
    "        s = self.out_layer.forward(h)\n",
    "        loss = sum([self.loss_layers[i].forward(s, targets[:, i]) for i in range(self.window_size * 2)])\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ds = sum([self.loss_layers[i].backward(dout) for i in range(self.window_size * 2)])\n",
    "        dh = self.out_layer.backward(ds)\n",
    "        self.in_layer.backward(dh)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3135,
     "status": "ok",
     "timestamp": 1610367916856,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "O7H4N4gbubk_",
    "outputId": "7969a4cb-4a59-4956-f583-beafbf303b1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 68/1000 [00:00<00:01, 553.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 1/2, Loss: 4.15902006113147\n",
      "Epoch: 2, Iteration: 1/2, Loss: 4.158985790837521\n",
      "Epoch: 3, Iteration: 1/2, Loss: 4.158864833741857\n",
      "Epoch: 4, Iteration: 1/2, Loss: 4.158934088690577\n",
      "Epoch: 5, Iteration: 1/2, Loss: 4.158790673927234\n",
      "Epoch: 6, Iteration: 1/2, Loss: 4.15870708355577\n",
      "Epoch: 7, Iteration: 1/2, Loss: 4.158745564506209\n",
      "Epoch: 8, Iteration: 1/2, Loss: 4.158600746404954\n",
      "Epoch: 9, Iteration: 1/2, Loss: 4.158537632323334\n",
      "Epoch: 10, Iteration: 1/2, Loss: 4.158520006715241\n",
      "Epoch: 11, Iteration: 1/2, Loss: 4.158596915743298\n",
      "Epoch: 12, Iteration: 1/2, Loss: 4.158333294910063\n",
      "Epoch: 13, Iteration: 1/2, Loss: 4.158284393221344\n",
      "Epoch: 14, Iteration: 1/2, Loss: 4.158270511729063\n",
      "Epoch: 15, Iteration: 1/2, Loss: 4.1582283137778004\n",
      "Epoch: 16, Iteration: 1/2, Loss: 4.158196134676663\n",
      "Epoch: 17, Iteration: 1/2, Loss: 4.157765247477214\n",
      "Epoch: 18, Iteration: 1/2, Loss: 4.1580729121420035\n",
      "Epoch: 19, Iteration: 1/2, Loss: 4.1577046643812405\n",
      "Epoch: 20, Iteration: 1/2, Loss: 4.157726259279956\n",
      "Epoch: 21, Iteration: 1/2, Loss: 4.1575806707807015\n",
      "Epoch: 22, Iteration: 1/2, Loss: 4.157343218180006\n",
      "Epoch: 23, Iteration: 1/2, Loss: 4.157282710389881\n",
      "Epoch: 24, Iteration: 1/2, Loss: 4.157030598472355\n",
      "Epoch: 25, Iteration: 1/2, Loss: 4.156935938248309\n",
      "Epoch: 26, Iteration: 1/2, Loss: 4.156778321831951\n",
      "Epoch: 27, Iteration: 1/2, Loss: 4.156196007131423\n",
      "Epoch: 28, Iteration: 1/2, Loss: 4.156809164171934\n",
      "Epoch: 29, Iteration: 1/2, Loss: 4.155738143768168\n",
      "Epoch: 30, Iteration: 1/2, Loss: 4.155303897096765\n",
      "Epoch: 31, Iteration: 1/2, Loss: 4.155528877562682\n",
      "Epoch: 32, Iteration: 1/2, Loss: 4.1549661169292635\n",
      "Epoch: 33, Iteration: 1/2, Loss: 4.154314628209205\n",
      "Epoch: 34, Iteration: 1/2, Loss: 4.155029980875579\n",
      "Epoch: 35, Iteration: 1/2, Loss: 4.153028143462114\n",
      "Epoch: 36, Iteration: 1/2, Loss: 4.153180275090648\n",
      "Epoch: 37, Iteration: 1/2, Loss: 4.151981215065641\n",
      "Epoch: 38, Iteration: 1/2, Loss: 4.151791841784791\n",
      "Epoch: 39, Iteration: 1/2, Loss: 4.152516413602524\n",
      "Epoch: 40, Iteration: 1/2, Loss: 4.149529463186791\n",
      "Epoch: 41, Iteration: 1/2, Loss: 4.150138129028928\n",
      "Epoch: 42, Iteration: 1/2, Loss: 4.146691957562183\n",
      "Epoch: 43, Iteration: 1/2, Loss: 4.149428274178757\n",
      "Epoch: 44, Iteration: 1/2, Loss: 4.144684439621013\n",
      "Epoch: 45, Iteration: 1/2, Loss: 4.1450338992058136\n",
      "Epoch: 46, Iteration: 1/2, Loss: 4.141322070859047\n",
      "Epoch: 47, Iteration: 1/2, Loss: 4.141412107363933\n",
      "Epoch: 48, Iteration: 1/2, Loss: 4.141852796636258\n",
      "Epoch: 49, Iteration: 1/2, Loss: 4.136491932308667\n",
      "Epoch: 50, Iteration: 1/2, Loss: 4.138050254893922\n",
      "Epoch: 51, Iteration: 1/2, Loss: 4.132043997488972\n",
      "Epoch: 52, Iteration: 1/2, Loss: 4.12830604618302\n",
      "Epoch: 53, Iteration: 1/2, Loss: 4.127273556851316\n",
      "Epoch: 54, Iteration: 1/2, Loss: 4.125199867948936\n",
      "Epoch: 55, Iteration: 1/2, Loss: 4.120247215494125\n",
      "Epoch: 56, Iteration: 1/2, Loss: 4.115116224039067\n",
      "Epoch: 57, Iteration: 1/2, Loss: 4.1114544955211585\n",
      "Epoch: 58, Iteration: 1/2, Loss: 4.102270517696279\n",
      "Epoch: 59, Iteration: 1/2, Loss: 4.101219792397225\n",
      "Epoch: 60, Iteration: 1/2, Loss: 4.089398192815923\n",
      "Epoch: 61, Iteration: 1/2, Loss: 4.088899009385825\n",
      "Epoch: 62, Iteration: 1/2, Loss: 4.085363324180673\n",
      "Epoch: 63, Iteration: 1/2, Loss: 4.053991456271057\n",
      "Epoch: 64, Iteration: 1/2, Loss: 4.071098482747433\n",
      "Epoch: 65, Iteration: 1/2, Loss: 4.060429608665773\n",
      "Epoch: 66, Iteration: 1/2, Loss: 4.032852932462877\n",
      "Epoch: 67, Iteration: 1/2, Loss: 4.024719228758794\n",
      "Epoch: 68, Iteration: 1/2, Loss: 4.013576319966397\n",
      "Epoch: 69, Iteration: 1/2, Loss: 3.9738333507374994\n",
      "Epoch: 70, Iteration: 1/2, Loss: 3.9865142449660276\n",
      "Epoch: 71, Iteration: 1/2, Loss: 3.9550912561417015\n",
      "Epoch: 72, Iteration: 1/2, Loss: 3.939919851363548\n",
      "Epoch: 73, Iteration: 1/2, Loss: 3.904578420347466\n",
      "Epoch: 74, Iteration: 1/2, Loss: 3.9040671762759427\n",
      "Epoch: 75, Iteration: 1/2, Loss: 3.876253425653864\n",
      "Epoch: 76, Iteration: 1/2, Loss: 3.833502333263411\n",
      "Epoch: 77, Iteration: 1/2, Loss: 3.744985933537355\n",
      "Epoch: 78, Iteration: 1/2, Loss: 3.8221010377704965\n",
      "Epoch: 79, Iteration: 1/2, Loss: 3.728085164210259\n",
      "Epoch: 80, Iteration: 1/2, Loss: 3.6165705200050056\n",
      "Epoch: 81, Iteration: 1/2, Loss: 3.6386259568302544\n",
      "Epoch: 82, Iteration: 1/2, Loss: 3.6052892652987127\n",
      "Epoch: 83, Iteration: 1/2, Loss: 3.5950373711217027\n",
      "Epoch: 84, Iteration: 1/2, Loss: 3.4662820812911574\n",
      "Epoch: 85, Iteration: 1/2, Loss: 3.466478434450142\n",
      "Epoch: 86, Iteration: 1/2, Loss: 3.3430063409904087\n",
      "Epoch: 87, Iteration: 1/2, Loss: 3.3445674192330133\n",
      "Epoch: 88, Iteration: 1/2, Loss: 3.242204720964761\n",
      "Epoch: 89, Iteration: 1/2, Loss: 3.2717480604485165\n",
      "Epoch: 90, Iteration: 1/2, Loss: 3.065412957956861\n",
      "Epoch: 91, Iteration: 1/2, Loss: 3.08646742959344\n",
      "Epoch: 92, Iteration: 1/2, Loss: 2.9885962735401344\n",
      "Epoch: 93, Iteration: 1/2, Loss: 2.9147741165353556\n",
      "Epoch: 94, Iteration: 1/2, Loss: 2.9167282597235356\n",
      "Epoch: 95, Iteration: 1/2, Loss: 2.8066581443277934\n",
      "Epoch: 96, Iteration: 1/2, Loss: 2.7575852415881714\n",
      "Epoch: 97, Iteration: 1/2, Loss: 2.680438208874723\n",
      "Epoch: 98, Iteration: 1/2, Loss: 2.64744053787775\n",
      "Epoch: 99, Iteration: 1/2, Loss: 2.492869731508871\n",
      "Epoch: 100, Iteration: 1/2, Loss: 2.5054729657881665\n",
      "Epoch: 101, Iteration: 1/2, Loss: 2.481596569311395\n",
      "Epoch: 102, Iteration: 1/2, Loss: 2.4198086888387094\n",
      "Epoch: 103, Iteration: 1/2, Loss: 2.3526848481424114\n",
      "Epoch: 104, Iteration: 1/2, Loss: 2.3141147873080454\n",
      "Epoch: 105, Iteration: 1/2, Loss: 2.2791186604503553\n",
      "Epoch: 106, Iteration: 1/2, Loss: 2.2620208757413622\n",
      "Epoch: 107, Iteration: 1/2, Loss: 2.1460230171709602\n",
      "Epoch: 108, Iteration: 1/2, Loss: 2.124611944849339\n",
      "Epoch: 109, Iteration: 1/2, Loss: 2.19575326181842\n",
      "Epoch: 110, Iteration: 1/2, Loss: 2.055561580333632\n",
      "Epoch: 111, Iteration: 1/2, Loss: 2.0277825537038967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 124/1000 [00:00<00:04, 193.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 112, Iteration: 1/2, Loss: 2.063341911948105\n",
      "Epoch: 113, Iteration: 1/2, Loss: 1.979295937960584\n",
      "Epoch: 114, Iteration: 1/2, Loss: 1.9798556611006042\n",
      "Epoch: 115, Iteration: 1/2, Loss: 1.9927882157635746\n",
      "Epoch: 116, Iteration: 1/2, Loss: 1.9080823123661788\n",
      "Epoch: 117, Iteration: 1/2, Loss: 1.9213157610055345\n",
      "Epoch: 118, Iteration: 1/2, Loss: 1.9080167370227779\n",
      "Epoch: 119, Iteration: 1/2, Loss: 1.865351243756976\n",
      "Epoch: 120, Iteration: 1/2, Loss: 1.8221881033392648\n",
      "Epoch: 121, Iteration: 1/2, Loss: 1.8673281040160026\n",
      "Epoch: 122, Iteration: 1/2, Loss: 1.7978652956623207\n",
      "Epoch: 123, Iteration: 1/2, Loss: 1.8208556676098782\n",
      "Epoch: 124, Iteration: 1/2, Loss: 1.752591410939968\n",
      "Epoch: 125, Iteration: 1/2, Loss: 1.7717852952556523\n",
      "Epoch: 126, Iteration: 1/2, Loss: 1.7536893221334366\n",
      "Epoch: 127, Iteration: 1/2, Loss: 1.7798946474573654\n",
      "Epoch: 128, Iteration: 1/2, Loss: 1.6864772759200597\n",
      "Epoch: 129, Iteration: 1/2, Loss: 1.7895209057496761\n",
      "Epoch: 130, Iteration: 1/2, Loss: 1.6639868418140231\n",
      "Epoch: 131, Iteration: 1/2, Loss: 1.7296250575509726\n",
      "Epoch: 132, Iteration: 1/2, Loss: 1.649206294158144\n",
      "Epoch: 133, Iteration: 1/2, Loss: 1.6779927064062412\n",
      "Epoch: 134, Iteration: 1/2, Loss: 1.6664433450632683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 192/1000 [00:00<00:03, 203.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 135, Iteration: 1/2, Loss: 1.7042011225194087\n",
      "Epoch: 136, Iteration: 1/2, Loss: 1.6238805547941786\n",
      "Epoch: 137, Iteration: 1/2, Loss: 1.6310098265307302\n",
      "Epoch: 138, Iteration: 1/2, Loss: 1.6557846604900566\n",
      "Epoch: 139, Iteration: 1/2, Loss: 1.6302508713796169\n",
      "Epoch: 140, Iteration: 1/2, Loss: 1.6280724888740423\n",
      "Epoch: 141, Iteration: 1/2, Loss: 1.5827958374405056\n",
      "Epoch: 142, Iteration: 1/2, Loss: 1.6028736172783549\n",
      "Epoch: 143, Iteration: 1/2, Loss: 1.6096673584911423\n",
      "Epoch: 144, Iteration: 1/2, Loss: 1.6080696549728097\n",
      "Epoch: 145, Iteration: 1/2, Loss: 1.613108983540776\n",
      "Epoch: 146, Iteration: 1/2, Loss: 1.5593194981924863\n",
      "Epoch: 147, Iteration: 1/2, Loss: 1.5906977734625647\n",
      "Epoch: 148, Iteration: 1/2, Loss: 1.5673464663015735\n",
      "Epoch: 149, Iteration: 1/2, Loss: 1.5925825470903359\n",
      "Epoch: 150, Iteration: 1/2, Loss: 1.5578761223696505\n",
      "Epoch: 151, Iteration: 1/2, Loss: 1.5442749833297746\n",
      "Epoch: 152, Iteration: 1/2, Loss: 1.5551222204754402\n",
      "Epoch: 153, Iteration: 1/2, Loss: 1.5501923532116038\n",
      "Epoch: 154, Iteration: 1/2, Loss: 1.5475554633493798\n",
      "Epoch: 155, Iteration: 1/2, Loss: 1.5576059711537855\n",
      "Epoch: 156, Iteration: 1/2, Loss: 1.523098331406329\n",
      "Epoch: 157, Iteration: 1/2, Loss: 1.535886145325697\n",
      "Epoch: 158, Iteration: 1/2, Loss: 1.518863499857486\n",
      "Epoch: 159, Iteration: 1/2, Loss: 1.5474946949218014\n",
      "Epoch: 160, Iteration: 1/2, Loss: 1.5080402613032735\n",
      "Epoch: 161, Iteration: 1/2, Loss: 1.537024487064684\n",
      "Epoch: 162, Iteration: 1/2, Loss: 1.518814996905443\n",
      "Epoch: 163, Iteration: 1/2, Loss: 1.519265117343081\n",
      "Epoch: 164, Iteration: 1/2, Loss: 1.5125909159038267\n",
      "Epoch: 165, Iteration: 1/2, Loss: 1.509765058177738\n",
      "Epoch: 166, Iteration: 1/2, Loss: 1.5098803952725675\n",
      "Epoch: 167, Iteration: 1/2, Loss: 1.5052915145322672\n",
      "Epoch: 168, Iteration: 1/2, Loss: 1.5164301500147732\n",
      "Epoch: 169, Iteration: 1/2, Loss: 1.4883798500880157\n",
      "Epoch: 170, Iteration: 1/2, Loss: 1.5002391879924593\n",
      "Epoch: 171, Iteration: 1/2, Loss: 1.4986934465226214\n",
      "Epoch: 172, Iteration: 1/2, Loss: 1.5041110015866028\n",
      "Epoch: 173, Iteration: 1/2, Loss: 1.4914988456300455\n",
      "Epoch: 174, Iteration: 1/2, Loss: 1.4801519884969605\n",
      "Epoch: 175, Iteration: 1/2, Loss: 1.4871392166959125\n",
      "Epoch: 176, Iteration: 1/2, Loss: 1.4875235380149263\n",
      "Epoch: 177, Iteration: 1/2, Loss: 1.4852817064774446\n",
      "Epoch: 178, Iteration: 1/2, Loss: 1.4849204962708071\n",
      "Epoch: 179, Iteration: 1/2, Loss: 1.491099319589742\n",
      "Epoch: 180, Iteration: 1/2, Loss: 1.4700133372620723\n",
      "Epoch: 181, Iteration: 1/2, Loss: 1.4810515291651114\n",
      "Epoch: 182, Iteration: 1/2, Loss: 1.4758007289949675\n",
      "Epoch: 183, Iteration: 1/2, Loss: 1.4752732275734675\n",
      "Epoch: 184, Iteration: 1/2, Loss: 1.481579034918717\n",
      "Epoch: 185, Iteration: 1/2, Loss: 1.463293391965637\n",
      "Epoch: 186, Iteration: 1/2, Loss: 1.470420391115241\n",
      "Epoch: 187, Iteration: 1/2, Loss: 1.4620566697597992\n",
      "Epoch: 188, Iteration: 1/2, Loss: 1.4778334903853334\n",
      "Epoch: 189, Iteration: 1/2, Loss: 1.4575186302715464\n",
      "Epoch: 190, Iteration: 1/2, Loss: 1.4734914672628046\n",
      "Epoch: 191, Iteration: 1/2, Loss: 1.4549646411166326\n",
      "Epoch: 192, Iteration: 1/2, Loss: 1.4731743730589972\n",
      "Epoch: 193, Iteration: 1/2, Loss: 1.4697401332579205\n",
      "Epoch: 194, Iteration: 1/2, Loss: 1.459710893614928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 282/1000 [00:01<00:02, 302.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195, Iteration: 1/2, Loss: 1.4593527974184664\n",
      "Epoch: 196, Iteration: 1/2, Loss: 1.4500476753508815\n",
      "Epoch: 197, Iteration: 1/2, Loss: 1.4600512800555108\n",
      "Epoch: 198, Iteration: 1/2, Loss: 1.4478081470903161\n",
      "Epoch: 199, Iteration: 1/2, Loss: 1.4623103381902394\n",
      "Epoch: 200, Iteration: 1/2, Loss: 1.4561537265671984\n",
      "Epoch: 201, Iteration: 1/2, Loss: 1.4530226544473104\n",
      "Epoch: 202, Iteration: 1/2, Loss: 1.452143783205833\n",
      "Epoch: 203, Iteration: 1/2, Loss: 1.452336519884248\n",
      "Epoch: 204, Iteration: 1/2, Loss: 1.4450199068117255\n",
      "Epoch: 205, Iteration: 1/2, Loss: 1.4568608236924259\n",
      "Epoch: 206, Iteration: 1/2, Loss: 1.4472112765536935\n",
      "Epoch: 207, Iteration: 1/2, Loss: 1.4495188836199346\n",
      "Epoch: 208, Iteration: 1/2, Loss: 1.4422539557470209\n",
      "Epoch: 209, Iteration: 1/2, Loss: 1.4455454132361636\n",
      "Epoch: 210, Iteration: 1/2, Loss: 1.4524614581712236\n",
      "Epoch: 211, Iteration: 1/2, Loss: 1.4509342272820605\n",
      "Epoch: 212, Iteration: 1/2, Loss: 1.4389346505784977\n",
      "Epoch: 213, Iteration: 1/2, Loss: 1.443909451545137\n",
      "Epoch: 214, Iteration: 1/2, Loss: 1.4418053302967007\n",
      "Epoch: 215, Iteration: 1/2, Loss: 1.4372445219975871\n",
      "Epoch: 216, Iteration: 1/2, Loss: 1.4487149448351087\n",
      "Epoch: 217, Iteration: 1/2, Loss: 1.4401101802734826\n",
      "Epoch: 218, Iteration: 1/2, Loss: 1.4401753510336737\n",
      "Epoch: 219, Iteration: 1/2, Loss: 1.4385514151714767\n",
      "Epoch: 220, Iteration: 1/2, Loss: 1.4403114087215303\n",
      "Epoch: 221, Iteration: 1/2, Loss: 1.4386982952658123\n",
      "Epoch: 222, Iteration: 1/2, Loss: 1.4329820700490044\n",
      "Epoch: 223, Iteration: 1/2, Loss: 1.440795972369911\n",
      "Epoch: 224, Iteration: 1/2, Loss: 1.4372890809604135\n",
      "Epoch: 225, Iteration: 1/2, Loss: 1.4404047241466547\n",
      "Epoch: 226, Iteration: 1/2, Loss: 1.426986613256099\n",
      "Epoch: 227, Iteration: 1/2, Loss: 1.4349454820038021\n",
      "Epoch: 228, Iteration: 1/2, Loss: 1.438699171432745\n",
      "Epoch: 229, Iteration: 1/2, Loss: 1.43838945006351\n",
      "Epoch: 230, Iteration: 1/2, Loss: 1.4294145683783395\n",
      "Epoch: 231, Iteration: 1/2, Loss: 1.432528404057348\n",
      "Epoch: 232, Iteration: 1/2, Loss: 1.4332571753328303\n",
      "Epoch: 233, Iteration: 1/2, Loss: 1.4352321536496864\n",
      "Epoch: 234, Iteration: 1/2, Loss: 1.4267410470929627\n",
      "Epoch: 235, Iteration: 1/2, Loss: 1.4276640313246167\n",
      "Epoch: 236, Iteration: 1/2, Loss: 1.430930955582622\n",
      "Epoch: 237, Iteration: 1/2, Loss: 1.4381027551450676\n",
      "Epoch: 238, Iteration: 1/2, Loss: 1.4287162516813678\n",
      "Epoch: 239, Iteration: 1/2, Loss: 1.425291735529274\n",
      "Epoch: 240, Iteration: 1/2, Loss: 1.4290136182109647\n",
      "Epoch: 241, Iteration: 1/2, Loss: 1.4248052596925183\n",
      "Epoch: 242, Iteration: 1/2, Loss: 1.4311937051115908\n",
      "Epoch: 243, Iteration: 1/2, Loss: 1.4245896239510947\n",
      "Epoch: 244, Iteration: 1/2, Loss: 1.4305362665081922\n",
      "Epoch: 245, Iteration: 1/2, Loss: 1.4225857224080833\n",
      "Epoch: 246, Iteration: 1/2, Loss: 1.4305232917875286\n",
      "Epoch: 247, Iteration: 1/2, Loss: 1.4251101470755698\n",
      "Epoch: 248, Iteration: 1/2, Loss: 1.42655688889077\n",
      "Epoch: 249, Iteration: 1/2, Loss: 1.4252137425077605\n",
      "Epoch: 250, Iteration: 1/2, Loss: 1.4250860152963183\n",
      "Epoch: 251, Iteration: 1/2, Loss: 1.420620827206756\n",
      "Epoch: 252, Iteration: 1/2, Loss: 1.42374331227072\n",
      "Epoch: 253, Iteration: 1/2, Loss: 1.4238382977872397\n",
      "Epoch: 254, Iteration: 1/2, Loss: 1.4269433245922971\n",
      "Epoch: 255, Iteration: 1/2, Loss: 1.4233903621230928\n",
      "Epoch: 256, Iteration: 1/2, Loss: 1.4255130339732074\n",
      "Epoch: 257, Iteration: 1/2, Loss: 1.4197929830337808\n",
      "Epoch: 258, Iteration: 1/2, Loss: 1.4221472524802556\n",
      "Epoch: 259, Iteration: 1/2, Loss: 1.4217890899419878\n",
      "Epoch: 260, Iteration: 1/2, Loss: 1.421301224490266\n",
      "Epoch: 261, Iteration: 1/2, Loss: 1.4214171141807188\n",
      "Epoch: 262, Iteration: 1/2, Loss: 1.4237104602890711\n",
      "Epoch: 263, Iteration: 1/2, Loss: 1.4203525472180134\n",
      "Epoch: 264, Iteration: 1/2, Loss: 1.4148966687082587\n",
      "Epoch: 265, Iteration: 1/2, Loss: 1.4223932551796097\n",
      "Epoch: 266, Iteration: 1/2, Loss: 1.4201467266774292\n",
      "Epoch: 267, Iteration: 1/2, Loss: 1.4194689061358654\n",
      "Epoch: 268, Iteration: 1/2, Loss: 1.4168200591018234\n",
      "Epoch: 269, Iteration: 1/2, Loss: 1.4241627539592798\n",
      "Epoch: 270, Iteration: 1/2, Loss: 1.416467676870239\n",
      "Epoch: 271, Iteration: 1/2, Loss: 1.4177912077318557\n",
      "Epoch: 272, Iteration: 1/2, Loss: 1.4185490145833888\n",
      "Epoch: 273, Iteration: 1/2, Loss: 1.4177622073086913\n",
      "Epoch: 274, Iteration: 1/2, Loss: 1.4151974500358961\n",
      "Epoch: 275, Iteration: 1/2, Loss: 1.422662589421141\n",
      "Epoch: 276, Iteration: 1/2, Loss: 1.4165817901297972\n",
      "Epoch: 277, Iteration: 1/2, Loss: 1.4150518592441972\n",
      "Epoch: 278, Iteration: 1/2, Loss: 1.416682394497967\n",
      "Epoch: 279, Iteration: 1/2, Loss: 1.4184749956380434\n",
      "Epoch: 280, Iteration: 1/2, Loss: 1.4136895688042266\n",
      "Epoch: 281, Iteration: 1/2, Loss: 1.41583985816819\n",
      "Epoch: 282, Iteration: 1/2, Loss: 1.4183825007867161\n",
      "Epoch: 283, Iteration: 1/2, Loss: 1.412766555076028\n",
      "Epoch: 284, Iteration: 1/2, Loss: 1.4178711890891469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 321/1000 [00:01<00:02, 267.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 285, Iteration: 1/2, Loss: 1.4108544256927509\n",
      "Epoch: 286, Iteration: 1/2, Loss: 1.4169294413509195\n",
      "Epoch: 287, Iteration: 1/2, Loss: 1.4173673777322202\n",
      "Epoch: 288, Iteration: 1/2, Loss: 1.4121132061958226\n",
      "Epoch: 289, Iteration: 1/2, Loss: 1.4162902691114474\n",
      "Epoch: 290, Iteration: 1/2, Loss: 1.4119372289812557\n",
      "Epoch: 291, Iteration: 1/2, Loss: 1.4141736624211183\n",
      "Epoch: 292, Iteration: 1/2, Loss: 1.4133831545312794\n",
      "Epoch: 293, Iteration: 1/2, Loss: 1.4155301741530772\n",
      "Epoch: 294, Iteration: 1/2, Loss: 1.4131093609490608\n",
      "Epoch: 295, Iteration: 1/2, Loss: 1.4090360443660832\n",
      "Epoch: 296, Iteration: 1/2, Loss: 1.417128959751878\n",
      "Epoch: 297, Iteration: 1/2, Loss: 1.4104464257247624\n",
      "Epoch: 298, Iteration: 1/2, Loss: 1.4125532542560157\n",
      "Epoch: 299, Iteration: 1/2, Loss: 1.4123724754214626\n",
      "Epoch: 300, Iteration: 1/2, Loss: 1.412561163355328\n",
      "Epoch: 301, Iteration: 1/2, Loss: 1.409824057616584\n",
      "Epoch: 302, Iteration: 1/2, Loss: 1.4156749999603782\n",
      "Epoch: 303, Iteration: 1/2, Loss: 1.4118177129411944\n",
      "Epoch: 304, Iteration: 1/2, Loss: 1.4075720901226099\n",
      "Epoch: 305, Iteration: 1/2, Loss: 1.4110803975527246\n",
      "Epoch: 306, Iteration: 1/2, Loss: 1.4114499966280567\n",
      "Epoch: 307, Iteration: 1/2, Loss: 1.4125957795691397\n",
      "Epoch: 308, Iteration: 1/2, Loss: 1.4112321312434277\n",
      "Epoch: 309, Iteration: 1/2, Loss: 1.412479176596635\n",
      "Epoch: 310, Iteration: 1/2, Loss: 1.41076743089585\n",
      "Epoch: 311, Iteration: 1/2, Loss: 1.4103509948123958\n",
      "Epoch: 312, Iteration: 1/2, Loss: 1.409942634079062\n",
      "Epoch: 313, Iteration: 1/2, Loss: 1.4081368977914923\n",
      "Epoch: 314, Iteration: 1/2, Loss: 1.4099299606588573\n",
      "Epoch: 315, Iteration: 1/2, Loss: 1.410117190594886\n",
      "Epoch: 316, Iteration: 1/2, Loss: 1.4092140931781585\n",
      "Epoch: 317, Iteration: 1/2, Loss: 1.4097077308637076\n",
      "Epoch: 318, Iteration: 1/2, Loss: 1.407413230516016\n",
      "Epoch: 319, Iteration: 1/2, Loss: 1.4112267111361187\n",
      "Epoch: 320, Iteration: 1/2, Loss: 1.4090329732419997\n",
      "Epoch: 321, Iteration: 1/2, Loss: 1.4103057070603124\n",
      "Epoch: 322, Iteration: 1/2, Loss: 1.4054895246514318\n",
      "Epoch: 323, Iteration: 1/2, Loss: 1.4085038680034425\n",
      "Epoch: 324, Iteration: 1/2, Loss: 1.4082654542408781\n",
      "Epoch: 325, Iteration: 1/2, Loss: 1.4105445240137047\n",
      "Epoch: 326, Iteration: 1/2, Loss: 1.4076403095536658\n",
      "Epoch: 327, Iteration: 1/2, Loss: 1.4084495397027135\n",
      "Epoch: 328, Iteration: 1/2, Loss: 1.408160998900343\n",
      "Epoch: 329, Iteration: 1/2, Loss: 1.4072758282250037\n",
      "Epoch: 330, Iteration: 1/2, Loss: 1.408067018434868\n",
      "Epoch: 331, Iteration: 1/2, Loss: 1.4090900157895754\n",
      "Epoch: 332, Iteration: 1/2, Loss: 1.4040749977912235\n",
      "Epoch: 333, Iteration: 1/2, Loss: 1.4109067035282146\n",
      "Epoch: 334, Iteration: 1/2, Loss: 1.4051630390818048\n",
      "Epoch: 335, Iteration: 1/2, Loss: 1.408780869158136\n",
      "Epoch: 336, Iteration: 1/2, Loss: 1.4041520600507358\n",
      "Epoch: 337, Iteration: 1/2, Loss: 1.4097929020958229\n",
      "Epoch: 338, Iteration: 1/2, Loss: 1.4052942083382796\n",
      "Epoch: 339, Iteration: 1/2, Loss: 1.4050515911333354\n",
      "Epoch: 340, Iteration: 1/2, Loss: 1.4065230126715875\n",
      "Epoch: 341, Iteration: 1/2, Loss: 1.408125628415483\n",
      "Epoch: 342, Iteration: 1/2, Loss: 1.405989547000249\n",
      "Epoch: 343, Iteration: 1/2, Loss: 1.4076820653686928\n",
      "Epoch: 344, Iteration: 1/2, Loss: 1.4046651155958325\n",
      "Epoch: 345, Iteration: 1/2, Loss: 1.4057660574184672\n",
      "Epoch: 346, Iteration: 1/2, Loss: 1.4058519461996135\n",
      "Epoch: 347, Iteration: 1/2, Loss: 1.405809750513518\n",
      "Epoch: 348, Iteration: 1/2, Loss: 1.4056223174308422\n",
      "Epoch: 349, Iteration: 1/2, Loss: 1.4070163544676868\n",
      "Epoch: 350, Iteration: 1/2, Loss: 1.4039659049041988\n",
      "Epoch: 351, Iteration: 1/2, Loss: 1.4052612892203444\n",
      "Epoch: 352, Iteration: 1/2, Loss: 1.4039691830183687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 424/1000 [00:01<00:01, 368.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 353, Iteration: 1/2, Loss: 1.4052557936537067\n",
      "Epoch: 354, Iteration: 1/2, Loss: 1.4064028708437921\n",
      "Epoch: 355, Iteration: 1/2, Loss: 1.4034714744822052\n",
      "Epoch: 356, Iteration: 1/2, Loss: 1.4061142596503777\n",
      "Epoch: 357, Iteration: 1/2, Loss: 1.4048608685084965\n",
      "Epoch: 358, Iteration: 1/2, Loss: 1.4047994000841273\n",
      "Epoch: 359, Iteration: 1/2, Loss: 1.4058003823134086\n",
      "Epoch: 360, Iteration: 1/2, Loss: 1.4027464076431126\n",
      "Epoch: 361, Iteration: 1/2, Loss: 1.4058734558200425\n",
      "Epoch: 362, Iteration: 1/2, Loss: 1.4027525074827407\n",
      "Epoch: 363, Iteration: 1/2, Loss: 1.4058347601572498\n",
      "Epoch: 364, Iteration: 1/2, Loss: 1.4039115056527987\n",
      "Epoch: 365, Iteration: 1/2, Loss: 1.4041499887635327\n",
      "Epoch: 366, Iteration: 1/2, Loss: 1.401039289635714\n",
      "Epoch: 367, Iteration: 1/2, Loss: 1.4051957316389565\n",
      "Epoch: 368, Iteration: 1/2, Loss: 1.4037082344249667\n",
      "Epoch: 369, Iteration: 1/2, Loss: 1.4036424053671972\n",
      "Epoch: 370, Iteration: 1/2, Loss: 1.4022314682813537\n",
      "Epoch: 371, Iteration: 1/2, Loss: 1.4049048027923365\n",
      "Epoch: 372, Iteration: 1/2, Loss: 1.4033904449866497\n",
      "Epoch: 373, Iteration: 1/2, Loss: 1.4018894931689811\n",
      "Epoch: 374, Iteration: 1/2, Loss: 1.4033841378107\n",
      "Epoch: 375, Iteration: 1/2, Loss: 1.404239790090823\n",
      "Epoch: 376, Iteration: 1/2, Loss: 1.4033748891110072\n",
      "Epoch: 377, Iteration: 1/2, Loss: 1.4025788647059623\n",
      "Epoch: 378, Iteration: 1/2, Loss: 1.4042412871926349\n",
      "Epoch: 379, Iteration: 1/2, Loss: 1.4003448505746727\n",
      "Epoch: 380, Iteration: 1/2, Loss: 1.4040155727679977\n",
      "Epoch: 381, Iteration: 1/2, Loss: 1.4028088102153848\n",
      "Epoch: 382, Iteration: 1/2, Loss: 1.403779743856321\n",
      "Epoch: 383, Iteration: 1/2, Loss: 1.401148756472071\n",
      "Epoch: 384, Iteration: 1/2, Loss: 1.402460229269232\n",
      "Epoch: 385, Iteration: 1/2, Loss: 1.40235412797474\n",
      "Epoch: 386, Iteration: 1/2, Loss: 1.4010493434301112\n",
      "Epoch: 387, Iteration: 1/2, Loss: 1.403511871504585\n",
      "Epoch: 388, Iteration: 1/2, Loss: 1.4022935697587098\n",
      "Epoch: 389, Iteration: 1/2, Loss: 1.401830158791065\n",
      "Epoch: 390, Iteration: 1/2, Loss: 1.4022183849107177\n",
      "Epoch: 391, Iteration: 1/2, Loss: 1.4017631474698324\n",
      "Epoch: 392, Iteration: 1/2, Loss: 1.40187211649959\n",
      "Epoch: 393, Iteration: 1/2, Loss: 1.4019075648937376\n",
      "Epoch: 394, Iteration: 1/2, Loss: 1.4024949884073254\n",
      "Epoch: 395, Iteration: 1/2, Loss: 1.4016370495315855\n",
      "Epoch: 396, Iteration: 1/2, Loss: 1.4007873300864415\n",
      "Epoch: 397, Iteration: 1/2, Loss: 1.4011232228800385\n",
      "Epoch: 398, Iteration: 1/2, Loss: 1.4018113333275413\n",
      "Epoch: 399, Iteration: 1/2, Loss: 1.4012133656645407\n",
      "Epoch: 400, Iteration: 1/2, Loss: 1.401357535231646\n",
      "Epoch: 401, Iteration: 1/2, Loss: 1.400200380790583\n",
      "Epoch: 402, Iteration: 1/2, Loss: 1.4030541430140056\n",
      "Epoch: 403, Iteration: 1/2, Loss: 1.4011954909913782\n",
      "Epoch: 404, Iteration: 1/2, Loss: 1.400106734435889\n",
      "Epoch: 405, Iteration: 1/2, Loss: 1.4018788662642958\n",
      "Epoch: 406, Iteration: 1/2, Loss: 1.3989379130641328\n",
      "Epoch: 407, Iteration: 1/2, Loss: 1.401870355398441\n",
      "Epoch: 408, Iteration: 1/2, Loss: 1.400695450389433\n",
      "Epoch: 409, Iteration: 1/2, Loss: 1.400607694536554\n",
      "Epoch: 410, Iteration: 1/2, Loss: 1.4018080014342456\n",
      "Epoch: 411, Iteration: 1/2, Loss: 1.3996072096162777\n",
      "Epoch: 412, Iteration: 1/2, Loss: 1.4005474224596959\n",
      "Epoch: 413, Iteration: 1/2, Loss: 1.4004815933941177\n",
      "Epoch: 414, Iteration: 1/2, Loss: 1.3995080686354076\n",
      "Epoch: 415, Iteration: 1/2, Loss: 1.400229657771983\n",
      "Epoch: 416, Iteration: 1/2, Loss: 1.40144628022404\n",
      "Epoch: 417, Iteration: 1/2, Loss: 1.4001593973506536\n",
      "Epoch: 418, Iteration: 1/2, Loss: 1.4011478150375363\n",
      "Epoch: 419, Iteration: 1/2, Loss: 1.4002711083687407\n",
      "Epoch: 420, Iteration: 1/2, Loss: 1.3990489624316402\n",
      "Epoch: 421, Iteration: 1/2, Loss: 1.3989389731269615\n",
      "Epoch: 422, Iteration: 1/2, Loss: 1.400847953224119\n",
      "Epoch: 423, Iteration: 1/2, Loss: 1.4000469310993706\n",
      "Epoch: 424, Iteration: 1/2, Loss: 1.3998242625654305\n",
      "Epoch: 425, Iteration: 1/2, Loss: 1.400687905446325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 467/1000 [00:01<00:01, 272.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 426, Iteration: 1/2, Loss: 1.3990508360286764\n",
      "Epoch: 427, Iteration: 1/2, Loss: 1.3997140329896465\n",
      "Epoch: 428, Iteration: 1/2, Loss: 1.3985945035453153\n",
      "Epoch: 429, Iteration: 1/2, Loss: 1.4003272375871765\n",
      "Epoch: 430, Iteration: 1/2, Loss: 1.3997458577747073\n",
      "Epoch: 431, Iteration: 1/2, Loss: 1.3993718640481547\n",
      "Epoch: 432, Iteration: 1/2, Loss: 1.399530061607374\n",
      "Epoch: 433, Iteration: 1/2, Loss: 1.399243106147619\n",
      "Epoch: 434, Iteration: 1/2, Loss: 1.3984976134486513\n",
      "Epoch: 435, Iteration: 1/2, Loss: 1.4010007153320136\n",
      "Epoch: 436, Iteration: 1/2, Loss: 1.398242629141877\n",
      "Epoch: 437, Iteration: 1/2, Loss: 1.398332208326595\n",
      "Epoch: 438, Iteration: 1/2, Loss: 1.400247292412448\n",
      "Epoch: 439, Iteration: 1/2, Loss: 1.3980582507450252\n",
      "Epoch: 440, Iteration: 1/2, Loss: 1.3999579238226956\n",
      "Epoch: 441, Iteration: 1/2, Loss: 1.3988229136366774\n",
      "Epoch: 442, Iteration: 1/2, Loss: 1.3990275401765895\n",
      "Epoch: 443, Iteration: 1/2, Loss: 1.3988234121288707\n",
      "Epoch: 444, Iteration: 1/2, Loss: 1.3980427023729631\n",
      "Epoch: 445, Iteration: 1/2, Loss: 1.3997201831015285\n",
      "Epoch: 446, Iteration: 1/2, Loss: 1.3985841764977565\n",
      "Epoch: 447, Iteration: 1/2, Loss: 1.3985616311748692\n",
      "Epoch: 448, Iteration: 1/2, Loss: 1.3986423924043814\n",
      "Epoch: 449, Iteration: 1/2, Loss: 1.3988162387226077\n",
      "Epoch: 450, Iteration: 1/2, Loss: 1.3985022769489681\n",
      "Epoch: 451, Iteration: 1/2, Loss: 1.3984518467061098\n",
      "Epoch: 452, Iteration: 1/2, Loss: 1.398505020912717\n",
      "Epoch: 453, Iteration: 1/2, Loss: 1.3983654114213568\n",
      "Epoch: 454, Iteration: 1/2, Loss: 1.3992874384683973\n",
      "Epoch: 455, Iteration: 1/2, Loss: 1.397310780727946\n",
      "Epoch: 456, Iteration: 1/2, Loss: 1.3991673331151206\n",
      "Epoch: 457, Iteration: 1/2, Loss: 1.3974453544738936\n",
      "Epoch: 458, Iteration: 1/2, Loss: 1.3980987558750444\n",
      "Epoch: 459, Iteration: 1/2, Loss: 1.3981968674498833\n",
      "Epoch: 460, Iteration: 1/2, Loss: 1.3981993472413656\n",
      "Epoch: 461, Iteration: 1/2, Loss: 1.3981567227314957\n",
      "Epoch: 462, Iteration: 1/2, Loss: 1.3978838070120059\n",
      "Epoch: 463, Iteration: 1/2, Loss: 1.3973025803604266\n",
      "Epoch: 464, Iteration: 1/2, Loss: 1.3985705021152866\n",
      "Epoch: 465, Iteration: 1/2, Loss: 1.3979882609310792\n",
      "Epoch: 466, Iteration: 1/2, Loss: 1.3985913900861848\n",
      "Epoch: 467, Iteration: 1/2, Loss: 1.3963677498515212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 502/1000 [00:01<00:02, 243.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 468, Iteration: 1/2, Loss: 1.3991901805544977\n",
      "Epoch: 469, Iteration: 1/2, Loss: 1.3970539760502003\n",
      "Epoch: 470, Iteration: 1/2, Loss: 1.3977555001006383\n",
      "Epoch: 471, Iteration: 1/2, Loss: 1.3975902016483852\n",
      "Epoch: 472, Iteration: 1/2, Loss: 1.397519452105915\n",
      "Epoch: 473, Iteration: 1/2, Loss: 1.3976006449775176\n",
      "Epoch: 474, Iteration: 1/2, Loss: 1.3968197945903347\n",
      "Epoch: 475, Iteration: 1/2, Loss: 1.3981672029159706\n",
      "Epoch: 476, Iteration: 1/2, Loss: 1.3975880783126136\n",
      "Epoch: 477, Iteration: 1/2, Loss: 1.3981652968751344\n",
      "Epoch: 478, Iteration: 1/2, Loss: 1.396505977954807\n",
      "Epoch: 479, Iteration: 1/2, Loss: 1.3973862605790652\n",
      "Epoch: 480, Iteration: 1/2, Loss: 1.3973059970548523\n",
      "Epoch: 481, Iteration: 1/2, Loss: 1.3971561676312287\n",
      "Epoch: 482, Iteration: 1/2, Loss: 1.397424526031254\n",
      "Epoch: 483, Iteration: 1/2, Loss: 1.397233173690757\n",
      "Epoch: 484, Iteration: 1/2, Loss: 1.3970716539015382\n",
      "Epoch: 485, Iteration: 1/2, Loss: 1.3971648121529385\n",
      "Epoch: 486, Iteration: 1/2, Loss: 1.397122976894046\n",
      "Epoch: 487, Iteration: 1/2, Loss: 1.3962743011301624\n",
      "Epoch: 488, Iteration: 1/2, Loss: 1.3969089875966625\n",
      "Epoch: 489, Iteration: 1/2, Loss: 1.3977718828890275\n",
      "Epoch: 490, Iteration: 1/2, Loss: 1.3968565915735787\n",
      "Epoch: 491, Iteration: 1/2, Loss: 1.3976537321776141\n",
      "Epoch: 492, Iteration: 1/2, Loss: 1.3962835927933122\n",
      "Epoch: 493, Iteration: 1/2, Loss: 1.3966757329104889\n",
      "Epoch: 494, Iteration: 1/2, Loss: 1.3975140898636407\n",
      "Epoch: 495, Iteration: 1/2, Loss: 1.3967280544434857\n",
      "Epoch: 496, Iteration: 1/2, Loss: 1.3967942300528517\n",
      "Epoch: 497, Iteration: 1/2, Loss: 1.3960423164472169\n",
      "Epoch: 498, Iteration: 1/2, Loss: 1.3972535585953774\n",
      "Epoch: 499, Iteration: 1/2, Loss: 1.3966923155136344\n",
      "Epoch: 500, Iteration: 1/2, Loss: 1.3958378974544086\n",
      "Epoch: 501, Iteration: 1/2, Loss: 1.3966747626507172\n",
      "Epoch: 502, Iteration: 1/2, Loss: 1.3971735486703944\n",
      "Epoch: 503, Iteration: 1/2, Loss: 1.3964353387965165\n",
      "Epoch: 504, Iteration: 1/2, Loss: 1.3958886376571245\n",
      "Epoch: 505, Iteration: 1/2, Loss: 1.3965111120397729\n",
      "Epoch: 506, Iteration: 1/2, Loss: 1.3961891797175208\n",
      "Epoch: 507, Iteration: 1/2, Loss: 1.3957699938871189\n",
      "Epoch: 508, Iteration: 1/2, Loss: 1.3970410749801145\n",
      "Epoch: 509, Iteration: 1/2, Loss: 1.3969346883842426\n",
      "Epoch: 510, Iteration: 1/2, Loss: 1.3950237572718336\n",
      "Epoch: 511, Iteration: 1/2, Loss: 1.3974569905565934\n",
      "Epoch: 512, Iteration: 1/2, Loss: 1.3956187309329233\n",
      "Epoch: 513, Iteration: 1/2, Loss: 1.3962550456166363\n",
      "Epoch: 514, Iteration: 1/2, Loss: 1.396053014007677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 637/1000 [00:02<00:01, 317.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 515, Iteration: 1/2, Loss: 1.396070845513386\n",
      "Epoch: 516, Iteration: 1/2, Loss: 1.3962665641497858\n",
      "Epoch: 517, Iteration: 1/2, Loss: 1.3965651208314438\n",
      "Epoch: 518, Iteration: 1/2, Loss: 1.396027604313855\n",
      "Epoch: 519, Iteration: 1/2, Loss: 1.3947204420986457\n",
      "Epoch: 520, Iteration: 1/2, Loss: 1.3965686706246707\n",
      "Epoch: 521, Iteration: 1/2, Loss: 1.395939940490926\n",
      "Epoch: 522, Iteration: 1/2, Loss: 1.3959415809044304\n",
      "Epoch: 523, Iteration: 1/2, Loss: 1.3958963571234837\n",
      "Epoch: 524, Iteration: 1/2, Loss: 1.3958738353185656\n",
      "Epoch: 525, Iteration: 1/2, Loss: 1.3959505889127555\n",
      "Epoch: 526, Iteration: 1/2, Loss: 1.395628568841179\n",
      "Epoch: 527, Iteration: 1/2, Loss: 1.395930825861846\n",
      "Epoch: 528, Iteration: 1/2, Loss: 1.3955724012830517\n",
      "Epoch: 529, Iteration: 1/2, Loss: 1.3952246338477114\n",
      "Epoch: 530, Iteration: 1/2, Loss: 1.3962370488551263\n",
      "Epoch: 531, Iteration: 1/2, Loss: 1.3957174623262838\n",
      "Epoch: 532, Iteration: 1/2, Loss: 1.3955032120102764\n",
      "Epoch: 533, Iteration: 1/2, Loss: 1.395597540664147\n",
      "Epoch: 534, Iteration: 1/2, Loss: 1.3955547285116852\n",
      "Epoch: 535, Iteration: 1/2, Loss: 1.3956484784576768\n",
      "Epoch: 536, Iteration: 1/2, Loss: 1.3954505592835666\n",
      "Epoch: 537, Iteration: 1/2, Loss: 1.3949768386195336\n",
      "Epoch: 538, Iteration: 1/2, Loss: 1.39596850495256\n",
      "Epoch: 539, Iteration: 1/2, Loss: 1.3953694947559647\n",
      "Epoch: 540, Iteration: 1/2, Loss: 1.395381978706343\n",
      "Epoch: 541, Iteration: 1/2, Loss: 1.3955927878459315\n",
      "Epoch: 542, Iteration: 1/2, Loss: 1.3951438216746057\n",
      "Epoch: 543, Iteration: 1/2, Loss: 1.3959464816615799\n",
      "Epoch: 544, Iteration: 1/2, Loss: 1.3953290982112003\n",
      "Epoch: 545, Iteration: 1/2, Loss: 1.394750399542798\n",
      "Epoch: 546, Iteration: 1/2, Loss: 1.39461766425699\n",
      "Epoch: 547, Iteration: 1/2, Loss: 1.3958637568534344\n",
      "Epoch: 548, Iteration: 1/2, Loss: 1.395105036585902\n",
      "Epoch: 549, Iteration: 1/2, Loss: 1.395354525662889\n",
      "Epoch: 550, Iteration: 1/2, Loss: 1.395148903146132\n",
      "Epoch: 551, Iteration: 1/2, Loss: 1.3955716355972583\n",
      "Epoch: 552, Iteration: 1/2, Loss: 1.3950715316205733\n",
      "Epoch: 553, Iteration: 1/2, Loss: 1.394562313281686\n",
      "Epoch: 554, Iteration: 1/2, Loss: 1.395644240504975\n",
      "Epoch: 555, Iteration: 1/2, Loss: 1.3949632123775904\n",
      "Epoch: 556, Iteration: 1/2, Loss: 1.3944934668142013\n",
      "Epoch: 557, Iteration: 1/2, Loss: 1.3954534247255719\n",
      "Epoch: 558, Iteration: 1/2, Loss: 1.3949763302215246\n",
      "Epoch: 559, Iteration: 1/2, Loss: 1.3943801296032026\n",
      "Epoch: 560, Iteration: 1/2, Loss: 1.3943202913798154\n",
      "Epoch: 561, Iteration: 1/2, Loss: 1.3949403841701793\n",
      "Epoch: 562, Iteration: 1/2, Loss: 1.39479996820441\n",
      "Epoch: 563, Iteration: 1/2, Loss: 1.3949428345115953\n",
      "Epoch: 564, Iteration: 1/2, Loss: 1.3952972900849607\n",
      "Epoch: 565, Iteration: 1/2, Loss: 1.3947408048302248\n",
      "Epoch: 566, Iteration: 1/2, Loss: 1.3942736600934025\n",
      "Epoch: 567, Iteration: 1/2, Loss: 1.3952776432070508\n",
      "Epoch: 568, Iteration: 1/2, Loss: 1.394690773300254\n",
      "Epoch: 569, Iteration: 1/2, Loss: 1.3942332009598535\n",
      "Epoch: 570, Iteration: 1/2, Loss: 1.3952365828884936\n",
      "Epoch: 571, Iteration: 1/2, Loss: 1.3950166830187116\n",
      "Epoch: 572, Iteration: 1/2, Loss: 1.394206995740709\n",
      "Epoch: 573, Iteration: 1/2, Loss: 1.3950414296667561\n",
      "Epoch: 574, Iteration: 1/2, Loss: 1.3941282625335867\n",
      "Epoch: 575, Iteration: 1/2, Loss: 1.3944284766362376\n",
      "Epoch: 576, Iteration: 1/2, Loss: 1.3941492321156517\n",
      "Epoch: 577, Iteration: 1/2, Loss: 1.3944904831930935\n",
      "Epoch: 578, Iteration: 1/2, Loss: 1.3949030495754096\n",
      "Epoch: 579, Iteration: 1/2, Loss: 1.3945500368804353\n",
      "Epoch: 580, Iteration: 1/2, Loss: 1.3943678046266248\n",
      "Epoch: 581, Iteration: 1/2, Loss: 1.3940688903264677\n",
      "Epoch: 582, Iteration: 1/2, Loss: 1.3953290017692288\n",
      "Epoch: 583, Iteration: 1/2, Loss: 1.3939041849931866\n",
      "Epoch: 584, Iteration: 1/2, Loss: 1.3944164060187878\n",
      "Epoch: 585, Iteration: 1/2, Loss: 1.3937496002710459\n",
      "Epoch: 586, Iteration: 1/2, Loss: 1.3949119873404945\n",
      "Epoch: 587, Iteration: 1/2, Loss: 1.3942399593620372\n",
      "Epoch: 588, Iteration: 1/2, Loss: 1.3938034410793883\n",
      "Epoch: 589, Iteration: 1/2, Loss: 1.3942595505266646\n",
      "Epoch: 590, Iteration: 1/2, Loss: 1.3947560543388864\n",
      "Epoch: 591, Iteration: 1/2, Loss: 1.394228538490235\n",
      "Epoch: 592, Iteration: 1/2, Loss: 1.3937152273960034\n",
      "Epoch: 593, Iteration: 1/2, Loss: 1.3946044781794278\n",
      "Epoch: 594, Iteration: 1/2, Loss: 1.394227810890656\n",
      "Epoch: 595, Iteration: 1/2, Loss: 1.3945222057179363\n",
      "Epoch: 596, Iteration: 1/2, Loss: 1.3936948683690167\n",
      "Epoch: 597, Iteration: 1/2, Loss: 1.394055577019404\n",
      "Epoch: 598, Iteration: 1/2, Loss: 1.3940892600122874\n",
      "Epoch: 599, Iteration: 1/2, Loss: 1.394035000795217\n",
      "Epoch: 600, Iteration: 1/2, Loss: 1.39403467964585\n",
      "Epoch: 601, Iteration: 1/2, Loss: 1.394035067313978\n",
      "Epoch: 602, Iteration: 1/2, Loss: 1.3939576934047604\n",
      "Epoch: 603, Iteration: 1/2, Loss: 1.3940399159552963\n",
      "Epoch: 604, Iteration: 1/2, Loss: 1.3938629945618102\n",
      "Epoch: 605, Iteration: 1/2, Loss: 1.393969709399367\n",
      "Epoch: 606, Iteration: 1/2, Loss: 1.3944120792428683\n",
      "Epoch: 607, Iteration: 1/2, Loss: 1.3929288540913496\n",
      "Epoch: 608, Iteration: 1/2, Loss: 1.3938828577722941\n",
      "Epoch: 609, Iteration: 1/2, Loss: 1.394284225355102\n",
      "Epoch: 610, Iteration: 1/2, Loss: 1.3943423013915606\n",
      "Epoch: 611, Iteration: 1/2, Loss: 1.3934429719427772\n",
      "Epoch: 612, Iteration: 1/2, Loss: 1.393836178098709\n",
      "Epoch: 613, Iteration: 1/2, Loss: 1.393316931991039\n",
      "Epoch: 614, Iteration: 1/2, Loss: 1.3937275094333412\n",
      "Epoch: 615, Iteration: 1/2, Loss: 1.3942436001794576\n",
      "Epoch: 616, Iteration: 1/2, Loss: 1.3941138988347042\n",
      "Epoch: 617, Iteration: 1/2, Loss: 1.393320706110652\n",
      "Epoch: 618, Iteration: 1/2, Loss: 1.3940867967397377\n",
      "Epoch: 619, Iteration: 1/2, Loss: 1.3932151518952316\n",
      "Epoch: 620, Iteration: 1/2, Loss: 1.3937312682048484\n",
      "Epoch: 621, Iteration: 1/2, Loss: 1.393527980511785\n",
      "Epoch: 622, Iteration: 1/2, Loss: 1.394105854241873\n",
      "Epoch: 623, Iteration: 1/2, Loss: 1.3931784905221738\n",
      "Epoch: 624, Iteration: 1/2, Loss: 1.3936593080031185\n",
      "Epoch: 625, Iteration: 1/2, Loss: 1.3940130059406322\n",
      "Epoch: 626, Iteration: 1/2, Loss: 1.3931289760000132\n",
      "Epoch: 627, Iteration: 1/2, Loss: 1.3935356869662585\n",
      "Epoch: 628, Iteration: 1/2, Loss: 1.3939391711411395\n",
      "Epoch: 629, Iteration: 1/2, Loss: 1.3925908394107587\n",
      "Epoch: 630, Iteration: 1/2, Loss: 1.3938869090894015\n",
      "Epoch: 631, Iteration: 1/2, Loss: 1.3930670248145398\n",
      "Epoch: 632, Iteration: 1/2, Loss: 1.3938503700644476\n",
      "Epoch: 633, Iteration: 1/2, Loss: 1.3935191176779913\n",
      "Epoch: 634, Iteration: 1/2, Loss: 1.392956919527468\n",
      "Epoch: 635, Iteration: 1/2, Loss: 1.393858133341471\n",
      "Epoch: 636, Iteration: 1/2, Loss: 1.3932968498933835\n",
      "Epoch: 637, Iteration: 1/2, Loss: 1.3934229031245953\n",
      "Epoch: 638, Iteration: 1/2, Loss: 1.3933321212871461\n",
      "Epoch: 639, Iteration: 1/2, Loss: 1.3933088998630128\n",
      "Epoch: 640, Iteration: 1/2, Loss: 1.392932424522957\n",
      "Epoch: 641, Iteration: 1/2, Loss: 1.3937740153017106\n",
      "Epoch: 642, Iteration: 1/2, Loss: 1.3927880785758273\n",
      "Epoch: 643, Iteration: 1/2, Loss: 1.3936551972255455\n",
      "Epoch: 644, Iteration: 1/2, Loss: 1.3933580549442457\n",
      "Epoch: 645, Iteration: 1/2, Loss: 1.393077533882939\n",
      "Epoch: 646, Iteration: 1/2, Loss: 1.3929252275084172\n",
      "Epoch: 647, Iteration: 1/2, Loss: 1.3935866346623915\n",
      "Epoch: 648, Iteration: 1/2, Loss: 1.3932529814739525\n",
      "Epoch: 649, Iteration: 1/2, Loss: 1.3934622073041174\n",
      "Epoch: 650, Iteration: 1/2, Loss: 1.3927481587711523\n",
      "Epoch: 651, Iteration: 1/2, Loss: 1.3927958559641895\n",
      "Epoch: 652, Iteration: 1/2, Loss: 1.393560228295915\n",
      "Epoch: 653, Iteration: 1/2, Loss: 1.3934349461164595\n",
      "Epoch: 654, Iteration: 1/2, Loss: 1.393158074181348\n",
      "Epoch: 655, Iteration: 1/2, Loss: 1.3930766356371331\n",
      "Epoch: 656, Iteration: 1/2, Loss: 1.3925803225921114\n",
      "Epoch: 657, Iteration: 1/2, Loss: 1.3934459866851856\n",
      "Epoch: 658, Iteration: 1/2, Loss: 1.3927086409268634\n",
      "Epoch: 659, Iteration: 1/2, Loss: 1.3930054845934583\n",
      "Epoch: 660, Iteration: 1/2, Loss: 1.3929700716454287\n",
      "Epoch: 661, Iteration: 1/2, Loss: 1.392979281582818\n",
      "Epoch: 662, Iteration: 1/2, Loss: 1.3933752076687766\n",
      "Epoch: 663, Iteration: 1/2, Loss: 1.3926376430313077\n",
      "Epoch: 664, Iteration: 1/2, Loss: 1.3925116604959524\n",
      "Epoch: 665, Iteration: 1/2, Loss: 1.3936721568447876\n",
      "Epoch: 666, Iteration: 1/2, Loss: 1.3921545460304694\n",
      "Epoch: 667, Iteration: 1/2, Loss: 1.3936155056879351\n",
      "Epoch: 668, Iteration: 1/2, Loss: 1.3921434049791146\n",
      "Epoch: 669, Iteration: 1/2, Loss: 1.3932189288110175\n",
      "Epoch: 670, Iteration: 1/2, Loss: 1.393239048161429\n",
      "Epoch: 671, Iteration: 1/2, Loss: 1.392516831698701\n",
      "Epoch: 672, Iteration: 1/2, Loss: 1.3931587371617016\n",
      "Epoch: 673, Iteration: 1/2, Loss: 1.3923766304830343\n",
      "Epoch: 674, Iteration: 1/2, Loss: 1.393227765885909\n",
      "Epoch: 675, Iteration: 1/2, Loss: 1.3927674909144838\n",
      "Epoch: 676, Iteration: 1/2, Loss: 1.392842772592962\n",
      "Epoch: 677, Iteration: 1/2, Loss: 1.3922618007475456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 845/1000 [00:02<00:00, 582.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 678, Iteration: 1/2, Loss: 1.3928611125197898\n",
      "Epoch: 679, Iteration: 1/2, Loss: 1.3922989267500567\n",
      "Epoch: 680, Iteration: 1/2, Loss: 1.3935031357585852\n",
      "Epoch: 681, Iteration: 1/2, Loss: 1.3922797371783346\n",
      "Epoch: 682, Iteration: 1/2, Loss: 1.392312882259201\n",
      "Epoch: 683, Iteration: 1/2, Loss: 1.3933940433629048\n",
      "Epoch: 684, Iteration: 1/2, Loss: 1.3926782422909083\n",
      "Epoch: 685, Iteration: 1/2, Loss: 1.3923420311707158\n",
      "Epoch: 686, Iteration: 1/2, Loss: 1.392905043317731\n",
      "Epoch: 687, Iteration: 1/2, Loss: 1.392316509533614\n",
      "Epoch: 688, Iteration: 1/2, Loss: 1.3921853010448955\n",
      "Epoch: 689, Iteration: 1/2, Loss: 1.3926246220142262\n",
      "Epoch: 690, Iteration: 1/2, Loss: 1.392837019369977\n",
      "Epoch: 691, Iteration: 1/2, Loss: 1.3926291075566324\n",
      "Epoch: 692, Iteration: 1/2, Loss: 1.392148998749935\n",
      "Epoch: 693, Iteration: 1/2, Loss: 1.392902293712321\n",
      "Epoch: 694, Iteration: 1/2, Loss: 1.3925543015457538\n",
      "Epoch: 695, Iteration: 1/2, Loss: 1.3929104060700994\n",
      "Epoch: 696, Iteration: 1/2, Loss: 1.392099385452335\n",
      "Epoch: 697, Iteration: 1/2, Loss: 1.3928772712522184\n",
      "Epoch: 698, Iteration: 1/2, Loss: 1.392468961062792\n",
      "Epoch: 699, Iteration: 1/2, Loss: 1.391702599432131\n",
      "Epoch: 700, Iteration: 1/2, Loss: 1.3924079800183167\n",
      "Epoch: 701, Iteration: 1/2, Loss: 1.3931474021976027\n",
      "Epoch: 702, Iteration: 1/2, Loss: 1.3917044336186142\n",
      "Epoch: 703, Iteration: 1/2, Loss: 1.392843723406851\n",
      "Epoch: 704, Iteration: 1/2, Loss: 1.392322365076002\n",
      "Epoch: 705, Iteration: 1/2, Loss: 1.3923585629242203\n",
      "Epoch: 706, Iteration: 1/2, Loss: 1.3924040054989226\n",
      "Epoch: 707, Iteration: 1/2, Loss: 1.392750891019927\n",
      "Epoch: 708, Iteration: 1/2, Loss: 1.3923419979445613\n",
      "Epoch: 709, Iteration: 1/2, Loss: 1.3916168014154255\n",
      "Epoch: 710, Iteration: 1/2, Loss: 1.3926790838551601\n",
      "Epoch: 711, Iteration: 1/2, Loss: 1.3918880404426954\n",
      "Epoch: 712, Iteration: 1/2, Loss: 1.39267856830019\n",
      "Epoch: 713, Iteration: 1/2, Loss: 1.3926027191900103\n",
      "Epoch: 714, Iteration: 1/2, Loss: 1.3918785665126567\n",
      "Epoch: 715, Iteration: 1/2, Loss: 1.3923890720567393\n",
      "Epoch: 716, Iteration: 1/2, Loss: 1.3921336602030088\n",
      "Epoch: 717, Iteration: 1/2, Loss: 1.3919666592013429\n",
      "Epoch: 718, Iteration: 1/2, Loss: 1.392563531587504\n",
      "Epoch: 719, Iteration: 1/2, Loss: 1.392208187090326\n",
      "Epoch: 720, Iteration: 1/2, Loss: 1.392206896289565\n",
      "Epoch: 721, Iteration: 1/2, Loss: 1.3924794784067762\n",
      "Epoch: 722, Iteration: 1/2, Loss: 1.391800624322119\n",
      "Epoch: 723, Iteration: 1/2, Loss: 1.3925313571480529\n",
      "Epoch: 724, Iteration: 1/2, Loss: 1.3918349901333968\n",
      "Epoch: 725, Iteration: 1/2, Loss: 1.391743325077016\n",
      "Epoch: 726, Iteration: 1/2, Loss: 1.3925049742699052\n",
      "Epoch: 727, Iteration: 1/2, Loss: 1.3920400690407648\n",
      "Epoch: 728, Iteration: 1/2, Loss: 1.391865270083918\n",
      "Epoch: 729, Iteration: 1/2, Loss: 1.3924158604881074\n",
      "Epoch: 730, Iteration: 1/2, Loss: 1.3923666609708159\n",
      "Epoch: 731, Iteration: 1/2, Loss: 1.3917490964087933\n",
      "Epoch: 732, Iteration: 1/2, Loss: 1.391700427625905\n",
      "Epoch: 733, Iteration: 1/2, Loss: 1.3927726699988736\n",
      "Epoch: 734, Iteration: 1/2, Loss: 1.391693509176859\n",
      "Epoch: 735, Iteration: 1/2, Loss: 1.3920010199703667\n",
      "Epoch: 736, Iteration: 1/2, Loss: 1.391967657478277\n",
      "Epoch: 737, Iteration: 1/2, Loss: 1.3923471990792662\n",
      "Epoch: 738, Iteration: 1/2, Loss: 1.3913891074103437\n",
      "Epoch: 739, Iteration: 1/2, Loss: 1.3922500816884922\n",
      "Epoch: 740, Iteration: 1/2, Loss: 1.3916860045815613\n",
      "Epoch: 741, Iteration: 1/2, Loss: 1.3923214481911494\n",
      "Epoch: 742, Iteration: 1/2, Loss: 1.3922046216519393\n",
      "Epoch: 743, Iteration: 1/2, Loss: 1.3919118872178147\n",
      "Epoch: 744, Iteration: 1/2, Loss: 1.391580954920874\n",
      "Epoch: 745, Iteration: 1/2, Loss: 1.39163212044331\n",
      "Epoch: 746, Iteration: 1/2, Loss: 1.392262498850001\n",
      "Epoch: 747, Iteration: 1/2, Loss: 1.3914975095353004\n",
      "Epoch: 748, Iteration: 1/2, Loss: 1.391912738455762\n",
      "Epoch: 749, Iteration: 1/2, Loss: 1.392483508782384\n",
      "Epoch: 750, Iteration: 1/2, Loss: 1.391569806799695\n",
      "Epoch: 751, Iteration: 1/2, Loss: 1.391543352227895\n",
      "Epoch: 752, Iteration: 1/2, Loss: 1.3924793702982867\n",
      "Epoch: 753, Iteration: 1/2, Loss: 1.3917634257576776\n",
      "Epoch: 754, Iteration: 1/2, Loss: 1.3915301984756105\n",
      "Epoch: 755, Iteration: 1/2, Loss: 1.3915223146746434\n",
      "Epoch: 756, Iteration: 1/2, Loss: 1.391733834658326\n",
      "Epoch: 757, Iteration: 1/2, Loss: 1.3921203802815212\n",
      "Epoch: 758, Iteration: 1/2, Loss: 1.3920714704500838\n",
      "Epoch: 759, Iteration: 1/2, Loss: 1.3914948064764863\n",
      "Epoch: 760, Iteration: 1/2, Loss: 1.3913901236951745\n",
      "Epoch: 761, Iteration: 1/2, Loss: 1.3920759743956506\n",
      "Epoch: 762, Iteration: 1/2, Loss: 1.391709367715038\n",
      "Epoch: 763, Iteration: 1/2, Loss: 1.3917221970463787\n",
      "Epoch: 764, Iteration: 1/2, Loss: 1.3917637148141617\n",
      "Epoch: 765, Iteration: 1/2, Loss: 1.3914033304728202\n",
      "Epoch: 766, Iteration: 1/2, Loss: 1.391990326679254\n",
      "Epoch: 767, Iteration: 1/2, Loss: 1.391690433589205\n",
      "Epoch: 768, Iteration: 1/2, Loss: 1.391366111884314\n",
      "Epoch: 769, Iteration: 1/2, Loss: 1.3919448066436413\n",
      "Epoch: 770, Iteration: 1/2, Loss: 1.3913610691103857\n",
      "Epoch: 771, Iteration: 1/2, Loss: 1.391622022642489\n",
      "Epoch: 772, Iteration: 1/2, Loss: 1.3922150551464223\n",
      "Epoch: 773, Iteration: 1/2, Loss: 1.3916724778901952\n",
      "Epoch: 774, Iteration: 1/2, Loss: 1.3913108044581288\n",
      "Epoch: 775, Iteration: 1/2, Loss: 1.3919021761332329\n",
      "Epoch: 776, Iteration: 1/2, Loss: 1.3912703575614005\n",
      "Epoch: 777, Iteration: 1/2, Loss: 1.391612526656353\n",
      "Epoch: 778, Iteration: 1/2, Loss: 1.39150531528311\n",
      "Epoch: 779, Iteration: 1/2, Loss: 1.3915723618530904\n",
      "Epoch: 780, Iteration: 1/2, Loss: 1.3916118975483676\n",
      "Epoch: 781, Iteration: 1/2, Loss: 1.3918019877120062\n",
      "Epoch: 782, Iteration: 1/2, Loss: 1.3912765483516247\n",
      "Epoch: 783, Iteration: 1/2, Loss: 1.3917617903148174\n",
      "Epoch: 784, Iteration: 1/2, Loss: 1.391241091309121\n",
      "Epoch: 785, Iteration: 1/2, Loss: 1.3914491798163202\n",
      "Epoch: 786, Iteration: 1/2, Loss: 1.391516754983479\n",
      "Epoch: 787, Iteration: 1/2, Loss: 1.391815828337473\n",
      "Epoch: 788, Iteration: 1/2, Loss: 1.3912063824182337\n",
      "Epoch: 789, Iteration: 1/2, Loss: 1.3911850973182909\n",
      "Epoch: 790, Iteration: 1/2, Loss: 1.3917224635536605\n",
      "Epoch: 791, Iteration: 1/2, Loss: 1.3917681198717082\n",
      "Epoch: 792, Iteration: 1/2, Loss: 1.3911224044855983\n",
      "Epoch: 793, Iteration: 1/2, Loss: 1.3914874037859395\n",
      "Epoch: 794, Iteration: 1/2, Loss: 1.3916533260481796\n",
      "Epoch: 795, Iteration: 1/2, Loss: 1.3908097837025961\n",
      "Epoch: 796, Iteration: 1/2, Loss: 1.3916997447385477\n",
      "Epoch: 797, Iteration: 1/2, Loss: 1.3914705071871776\n",
      "Epoch: 798, Iteration: 1/2, Loss: 1.39107179846478\n",
      "Epoch: 799, Iteration: 1/2, Loss: 1.3916347519700998\n",
      "Epoch: 800, Iteration: 1/2, Loss: 1.3914231375187847\n",
      "Epoch: 801, Iteration: 1/2, Loss: 1.3913386903772298\n",
      "Epoch: 802, Iteration: 1/2, Loss: 1.3913210779475236\n",
      "Epoch: 803, Iteration: 1/2, Loss: 1.3913528144987934\n",
      "Epoch: 804, Iteration: 1/2, Loss: 1.391319258621576\n",
      "Epoch: 805, Iteration: 1/2, Loss: 1.3913350584871473\n",
      "Epoch: 806, Iteration: 1/2, Loss: 1.3916028884376845\n",
      "Epoch: 807, Iteration: 1/2, Loss: 1.3909688414866554\n",
      "Epoch: 808, Iteration: 1/2, Loss: 1.391344179384303\n",
      "Epoch: 809, Iteration: 1/2, Loss: 1.3912486783837168\n",
      "Epoch: 810, Iteration: 1/2, Loss: 1.3910469566289523\n",
      "Epoch: 811, Iteration: 1/2, Loss: 1.3917730889990731\n",
      "Epoch: 812, Iteration: 1/2, Loss: 1.390753635092525\n",
      "Epoch: 813, Iteration: 1/2, Loss: 1.3914912674377051\n",
      "Epoch: 814, Iteration: 1/2, Loss: 1.3909603863088198\n",
      "Epoch: 815, Iteration: 1/2, Loss: 1.3915736383629564\n",
      "Epoch: 816, Iteration: 1/2, Loss: 1.3914946903898804\n",
      "Epoch: 817, Iteration: 1/2, Loss: 1.3909100512043495\n",
      "Epoch: 818, Iteration: 1/2, Loss: 1.3912510761249228\n",
      "Epoch: 819, Iteration: 1/2, Loss: 1.3909139294687813\n",
      "Epoch: 820, Iteration: 1/2, Loss: 1.3914472967316727\n",
      "Epoch: 821, Iteration: 1/2, Loss: 1.391131256264977\n",
      "Epoch: 822, Iteration: 1/2, Loss: 1.3912023138049636\n",
      "Epoch: 823, Iteration: 1/2, Loss: 1.3914661548998666\n",
      "Epoch: 824, Iteration: 1/2, Loss: 1.390882651820232\n",
      "Epoch: 825, Iteration: 1/2, Loss: 1.3914542683468647\n",
      "Epoch: 826, Iteration: 1/2, Loss: 1.3905511408379452\n",
      "Epoch: 827, Iteration: 1/2, Loss: 1.3914375662967486\n",
      "Epoch: 828, Iteration: 1/2, Loss: 1.3910862079565924\n",
      "Epoch: 829, Iteration: 1/2, Loss: 1.3911247139251601\n",
      "Epoch: 830, Iteration: 1/2, Loss: 1.3911560156307323\n",
      "Epoch: 831, Iteration: 1/2, Loss: 1.3907907295662298\n",
      "Epoch: 832, Iteration: 1/2, Loss: 1.3914054446740964\n",
      "Epoch: 833, Iteration: 1/2, Loss: 1.391307316348402\n",
      "Epoch: 834, Iteration: 1/2, Loss: 1.390592474545071\n",
      "Epoch: 835, Iteration: 1/2, Loss: 1.3913674359085255\n",
      "Epoch: 836, Iteration: 1/2, Loss: 1.39076527686291\n",
      "Epoch: 837, Iteration: 1/2, Loss: 1.3912800635980984\n",
      "Epoch: 838, Iteration: 1/2, Loss: 1.390820548107719\n",
      "Epoch: 839, Iteration: 1/2, Loss: 1.391524519362797\n",
      "Epoch: 840, Iteration: 1/2, Loss: 1.3907877059270726\n",
      "Epoch: 841, Iteration: 1/2, Loss: 1.3907603804497146\n",
      "Epoch: 842, Iteration: 1/2, Loss: 1.3913075457765054\n",
      "Epoch: 843, Iteration: 1/2, Loss: 1.3912335931296387\n",
      "Epoch: 844, Iteration: 1/2, Loss: 1.3907897894296979\n",
      "Epoch: 845, Iteration: 1/2, Loss: 1.3909402514087266\n",
      "Epoch: 846, Iteration: 1/2, Loss: 1.391266096479846\n",
      "Epoch: 847, Iteration: 1/2, Loss: 1.3904074981649788\n",
      "Epoch: 848, Iteration: 1/2, Loss: 1.3912002132806462\n",
      "Epoch: 849, Iteration: 1/2, Loss: 1.3910110768562274\n",
      "Epoch: 850, Iteration: 1/2, Loss: 1.3912328842892498\n",
      "Epoch: 851, Iteration: 1/2, Loss: 1.3906943235210767\n",
      "Epoch: 852, Iteration: 1/2, Loss: 1.3909225163981458\n",
      "Epoch: 853, Iteration: 1/2, Loss: 1.391191350387342\n",
      "Epoch: 854, Iteration: 1/2, Loss: 1.3906235255607662\n",
      "Epoch: 855, Iteration: 1/2, Loss: 1.3909377851397289\n",
      "Epoch: 856, Iteration: 1/2, Loss: 1.3908496961081727\n",
      "Epoch: 857, Iteration: 1/2, Loss: 1.3909799961825127\n",
      "Epoch: 858, Iteration: 1/2, Loss: 1.3908284529418975\n",
      "Epoch: 859, Iteration: 1/2, Loss: 1.3911431045710971\n",
      "Epoch: 860, Iteration: 1/2, Loss: 1.390674215350541\n",
      "Epoch: 861, Iteration: 1/2, Loss: 1.3910937888826695\n",
      "Epoch: 862, Iteration: 1/2, Loss: 1.3908859450280344\n",
      "Epoch: 863, Iteration: 1/2, Loss: 1.3905798579499096\n",
      "Epoch: 864, Iteration: 1/2, Loss: 1.390796357626503\n",
      "Epoch: 865, Iteration: 1/2, Loss: 1.390889580370164\n",
      "Epoch: 866, Iteration: 1/2, Loss: 1.3908002568588347\n",
      "Epoch: 867, Iteration: 1/2, Loss: 1.3908613788428363\n",
      "Epoch: 868, Iteration: 1/2, Loss: 1.3905867803582246\n",
      "Epoch: 869, Iteration: 1/2, Loss: 1.3910040151752312\n",
      "Epoch: 870, Iteration: 1/2, Loss: 1.3905867328572823\n",
      "Epoch: 871, Iteration: 1/2, Loss: 1.391090956252346\n",
      "Epoch: 872, Iteration: 1/2, Loss: 1.390745898467439\n",
      "Epoch: 873, Iteration: 1/2, Loss: 1.3910019075612088\n",
      "Epoch: 874, Iteration: 1/2, Loss: 1.3905303967338076\n",
      "Epoch: 875, Iteration: 1/2, Loss: 1.3910282341326026\n",
      "Epoch: 876, Iteration: 1/2, Loss: 1.390564037098856\n",
      "Epoch: 877, Iteration: 1/2, Loss: 1.3906986337566065\n",
      "Epoch: 878, Iteration: 1/2, Loss: 1.3909761953375628\n",
      "Epoch: 879, Iteration: 1/2, Loss: 1.3904890111758208\n",
      "Epoch: 880, Iteration: 1/2, Loss: 1.3909759151053067\n",
      "Epoch: 881, Iteration: 1/2, Loss: 1.3904806331573205\n",
      "Epoch: 882, Iteration: 1/2, Loss: 1.390790235283219\n",
      "Epoch: 883, Iteration: 1/2, Loss: 1.3906334565041925\n",
      "Epoch: 884, Iteration: 1/2, Loss: 1.3909971535240682\n",
      "Epoch: 885, Iteration: 1/2, Loss: 1.3904272831540907"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 358.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 886, Iteration: 1/2, Loss: 1.3906967399992558\n",
      "Epoch: 887, Iteration: 1/2, Loss: 1.3906876464819915\n",
      "Epoch: 888, Iteration: 1/2, Loss: 1.3906407765893747\n",
      "Epoch: 889, Iteration: 1/2, Loss: 1.3907043858315848\n",
      "Epoch: 890, Iteration: 1/2, Loss: 1.3906272864823377\n",
      "Epoch: 891, Iteration: 1/2, Loss: 1.390690577716771\n",
      "Epoch: 892, Iteration: 1/2, Loss: 1.3906415535980226\n",
      "Epoch: 893, Iteration: 1/2, Loss: 1.3906599925693262\n",
      "Epoch: 894, Iteration: 1/2, Loss: 1.390854640885439\n",
      "Epoch: 895, Iteration: 1/2, Loss: 1.3903918069853538\n",
      "Epoch: 896, Iteration: 1/2, Loss: 1.390388416378433\n",
      "Epoch: 897, Iteration: 1/2, Loss: 1.3910846704502893\n",
      "Epoch: 898, Iteration: 1/2, Loss: 1.3903580166053202\n",
      "Epoch: 899, Iteration: 1/2, Loss: 1.390384732795792\n",
      "Epoch: 900, Iteration: 1/2, Loss: 1.3908127923048776\n",
      "Epoch: 901, Iteration: 1/2, Loss: 1.39086052651732\n",
      "Epoch: 902, Iteration: 1/2, Loss: 1.3900714568078139\n",
      "Epoch: 903, Iteration: 1/2, Loss: 1.3906165036998572\n",
      "Epoch: 904, Iteration: 1/2, Loss: 1.3907890384358712\n",
      "Epoch: 905, Iteration: 1/2, Loss: 1.3907700382013064\n",
      "Epoch: 906, Iteration: 1/2, Loss: 1.390326674222435\n",
      "Epoch: 907, Iteration: 1/2, Loss: 1.3905668745784139\n",
      "Epoch: 908, Iteration: 1/2, Loss: 1.3905400593722925\n",
      "Epoch: 909, Iteration: 1/2, Loss: 1.3907899113629147\n",
      "Epoch: 910, Iteration: 1/2, Loss: 1.390276816750537\n",
      "Epoch: 911, Iteration: 1/2, Loss: 1.3905531035925944\n",
      "Epoch: 912, Iteration: 1/2, Loss: 1.390487723934611\n",
      "Epoch: 913, Iteration: 1/2, Loss: 1.3907399396618152\n",
      "Epoch: 914, Iteration: 1/2, Loss: 1.3900272783903223\n",
      "Epoch: 915, Iteration: 1/2, Loss: 1.3909747139095254\n",
      "Epoch: 916, Iteration: 1/2, Loss: 1.390055860344416\n",
      "Epoch: 917, Iteration: 1/2, Loss: 1.3904859973075192\n",
      "Epoch: 918, Iteration: 1/2, Loss: 1.3906826045205918\n",
      "Epoch: 919, Iteration: 1/2, Loss: 1.3902739224352774\n",
      "Epoch: 920, Iteration: 1/2, Loss: 1.3906724355373559\n",
      "Epoch: 921, Iteration: 1/2, Loss: 1.390503464474373\n",
      "Epoch: 922, Iteration: 1/2, Loss: 1.390393834428863\n",
      "Epoch: 923, Iteration: 1/2, Loss: 1.3904190282420028\n",
      "Epoch: 924, Iteration: 1/2, Loss: 1.3904845528222771\n",
      "Epoch: 925, Iteration: 1/2, Loss: 1.390413721666108\n",
      "Epoch: 926, Iteration: 1/2, Loss: 1.3904293647330692\n",
      "Epoch: 927, Iteration: 1/2, Loss: 1.3902452554400426\n",
      "Epoch: 928, Iteration: 1/2, Loss: 1.390396881371664\n",
      "Epoch: 929, Iteration: 1/2, Loss: 1.3908332795369818\n",
      "Epoch: 930, Iteration: 1/2, Loss: 1.3899620098219774\n",
      "Epoch: 931, Iteration: 1/2, Loss: 1.3903993456352715\n",
      "Epoch: 932, Iteration: 1/2, Loss: 1.3908765108680927\n",
      "Epoch: 933, Iteration: 1/2, Loss: 1.3901889541101151\n",
      "Epoch: 934, Iteration: 1/2, Loss: 1.390352185434819\n",
      "Epoch: 935, Iteration: 1/2, Loss: 1.3901609002590358\n",
      "Epoch: 936, Iteration: 1/2, Loss: 1.3905939213688803\n",
      "Epoch: 937, Iteration: 1/2, Loss: 1.390337722148462\n",
      "Epoch: 938, Iteration: 1/2, Loss: 1.390311628068744\n",
      "Epoch: 939, Iteration: 1/2, Loss: 1.390392440655022\n",
      "Epoch: 940, Iteration: 1/2, Loss: 1.3903202061749775\n",
      "Epoch: 941, Iteration: 1/2, Loss: 1.3903389936769912\n",
      "Epoch: 942, Iteration: 1/2, Loss: 1.390558808441279\n",
      "Epoch: 943, Iteration: 1/2, Loss: 1.3901128276446313\n",
      "Epoch: 944, Iteration: 1/2, Loss: 1.3903591183106676\n",
      "Epoch: 945, Iteration: 1/2, Loss: 1.390491004942978\n",
      "Epoch: 946, Iteration: 1/2, Loss: 1.39010950189336\n",
      "Epoch: 947, Iteration: 1/2, Loss: 1.3902907101419257\n",
      "Epoch: 948, Iteration: 1/2, Loss: 1.3900988040612232\n",
      "Epoch: 949, Iteration: 1/2, Loss: 1.390292692531077\n",
      "Epoch: 950, Iteration: 1/2, Loss: 1.3907343236891305\n",
      "Epoch: 951, Iteration: 1/2, Loss: 1.3900239861307622\n",
      "Epoch: 952, Iteration: 1/2, Loss: 1.3903123011833565\n",
      "Epoch: 953, Iteration: 1/2, Loss: 1.3902769613335084\n",
      "Epoch: 954, Iteration: 1/2, Loss: 1.3902261679534942\n",
      "Epoch: 955, Iteration: 1/2, Loss: 1.3900610159344067\n",
      "Epoch: 956, Iteration: 1/2, Loss: 1.3904412061700286\n",
      "Epoch: 957, Iteration: 1/2, Loss: 1.3902707566123544\n",
      "Epoch: 958, Iteration: 1/2, Loss: 1.39002854261043\n",
      "Epoch: 959, Iteration: 1/2, Loss: 1.390471162624789\n",
      "Epoch: 960, Iteration: 1/2, Loss: 1.39020595219286\n",
      "Epoch: 961, Iteration: 1/2, Loss: 1.390217134844597\n",
      "Epoch: 962, Iteration: 1/2, Loss: 1.3904320686093428\n",
      "Epoch: 963, Iteration: 1/2, Loss: 1.3900456558463885\n",
      "Epoch: 964, Iteration: 1/2, Loss: 1.3899571658817078\n",
      "Epoch: 965, Iteration: 1/2, Loss: 1.3904352764533572\n",
      "Epoch: 966, Iteration: 1/2, Loss: 1.3902124539484597\n",
      "Epoch: 967, Iteration: 1/2, Loss: 1.390151106085898\n",
      "Epoch: 968, Iteration: 1/2, Loss: 1.3901811516563183\n",
      "Epoch: 969, Iteration: 1/2, Loss: 1.3903690201298795\n",
      "Epoch: 970, Iteration: 1/2, Loss: 1.3901769563629716\n",
      "Epoch: 971, Iteration: 1/2, Loss: 1.3900009601925754\n",
      "Epoch: 972, Iteration: 1/2, Loss: 1.3899356209318758\n",
      "Epoch: 973, Iteration: 1/2, Loss: 1.3903882969546713\n",
      "Epoch: 974, Iteration: 1/2, Loss: 1.3901055706867087\n",
      "Epoch: 975, Iteration: 1/2, Loss: 1.389980618628822\n",
      "Epoch: 976, Iteration: 1/2, Loss: 1.3903709007417095\n",
      "Epoch: 977, Iteration: 1/2, Loss: 1.3899078026290939\n",
      "Epoch: 978, Iteration: 1/2, Loss: 1.3901313614066702\n",
      "Epoch: 979, Iteration: 1/2, Loss: 1.3903270674367798\n",
      "Epoch: 980, Iteration: 1/2, Loss: 1.38992218318079\n",
      "Epoch: 981, Iteration: 1/2, Loss: 1.3904853253746459\n",
      "Epoch: 982, Iteration: 1/2, Loss: 1.3897373536785385\n",
      "Epoch: 983, Iteration: 1/2, Loss: 1.3903148519908337\n",
      "Epoch: 984, Iteration: 1/2, Loss: 1.3900963233623784\n",
      "Epoch: 985, Iteration: 1/2, Loss: 1.3900741260852887\n",
      "Epoch: 986, Iteration: 1/2, Loss: 1.3900911777296545\n",
      "Epoch: 987, Iteration: 1/2, Loss: 1.3898779383587296\n",
      "Epoch: 988, Iteration: 1/2, Loss: 1.3902570272300643\n",
      "Epoch: 989, Iteration: 1/2, Loss: 1.390275678421958\n",
      "Epoch: 990, Iteration: 1/2, Loss: 1.3896870427998738\n",
      "Epoch: 991, Iteration: 1/2, Loss: 1.3902758317661803\n",
      "Epoch: 992, Iteration: 1/2, Loss: 1.3900389104161224\n",
      "Epoch: 993, Iteration: 1/2, Loss: 1.390054472851204\n",
      "Epoch: 994, Iteration: 1/2, Loss: 1.390035383690786\n",
      "Epoch: 995, Iteration: 1/2, Loss: 1.3902376762119406\n",
      "Epoch: 996, Iteration: 1/2, Loss: 1.3900341510195735\n",
      "Epoch: 997, Iteration: 1/2, Loss: 1.3898571265525932\n",
      "Epoch: 998, Iteration: 1/2, Loss: 1.3898057838079088\n",
      "Epoch: 999, Iteration: 1/2, Loss: 1.3904341253293562\n",
      "Epoch: 1000, Iteration: 1/2, Loss: 1.3898064145860194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "# configurations\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "# define model\n",
    "skip_gram = SkipGram(len(word2idx), hidden_size, window_size)\n",
    "sgd_optimizer = SGD()\n",
    "trainer = Trainer(skip_gram, sgd_optimizer)\n",
    "\n",
    "# start training\n",
    "trainer.fit(contexts, targets, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 3130,
     "status": "ok",
     "timestamp": 1610367916856,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "M6xgIlAEublA",
    "outputId": "f00169c1-ff0f-4d48-b65e-4c52d3a676b5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3126,
     "status": "ok",
     "timestamp": 1610367916857,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "-HrG2iP3ublA",
    "outputId": "b2900311-52f8-4871-b597-e37558716717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". [ 0.00540129  0.00416394  0.00725283 -0.00497087  0.01710908]\n",
      "now [ 0.15975429 -1.9225913   0.41327745 -0.7595175  -1.9016107 ]\n",
      "am [-1.3899754  -0.02556935  1.9042108  -1.018543    1.2759961 ]\n",
      "processing [ 2.222649    1.4994948  -0.76909554 -0.0632517  -0.45858148]\n",
      "studying [-0.8803772   0.25252277 -1.4196982   1.8034607   1.4257361 ]\n",
      "language [-0.92387885 -1.8610517  -1.3427458   1.5364372  -1.003436  ]\n",
      "i [-0.00539189 -0.00331921  0.00413546 -0.0157114   0.00840823]\n",
      "natural [ 0.44818872  2.3492718   1.2361885  -1.4921843   0.3150651 ]\n"
     ]
    }
   ],
   "source": [
    "# check skip-gram results\n",
    "word_vecs = skip_gram.word_vecs\n",
    "for word_id, word in idx2word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "實作簡易word2vec模型_作業.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
