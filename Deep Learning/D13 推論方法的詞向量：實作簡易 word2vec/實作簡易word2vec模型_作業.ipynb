{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuRqMFQvubkz"
   },
   "source": [
    "### 作業目的: 實作word2vec Skip-gram模型\n",
    "在課程中了解如何搭建CBOW模型，這次的作業目的在於透過搭建Skip-gram模型來了解另外一種word2vec的架構。\n",
    "\n",
    "- Hint_1: 學員可以善用課程中以搭建好的function模組\n",
    "- Hint_2: Skip_gram所需的輸入資料與目標跟CBOW有些許不同，Skip_gram是由中間字詞預測上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1610367914831,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "JqCGzQPVubk7"
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils.utility import preprocess, convert_one_hot, Trainer\n",
    "from utils.layers import Dense, SoftmaxWithCrossEntropy\n",
    "from utils.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1492,
     "status": "ok",
     "timestamp": 1610367915199,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "_Nw5L5_8ubk8",
    "outputId": "2a4c9ec9-a1a4-45cf-cce0-8cc3e8a4d02f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 4, 5, 1, 0]),\n",
       " array([[6, 3],\n",
       "        [2, 4],\n",
       "        [3, 5],\n",
       "        [4, 1],\n",
       "        [5, 0],\n",
       "        [1, 7]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same corpus as in the lecture\n",
    "text = \"I am studying Natural Language Processing now.\"\n",
    "\n",
    "# define create_contexts_target function\n",
    "def create_contexts_target(corpus: List, window_size: int=1):\n",
    "    contexts = corpus[window_size:-window_size]\n",
    "    targets = []\n",
    "    for idx in range(window_size, len(corpus) - window_size):\n",
    "        ts = list(corpus[idx - window_size:idx]) + list(corpus[idx + 1:idx + 1 + window_size])\n",
    "        targets.append(ts)\n",
    "\n",
    "    return np.array(contexts), np.array(targets)\n",
    "\n",
    "# transform corpus to contexts and targets pair\n",
    "corpus, word2idx, idx2word = preprocess([text])\n",
    "contexts, targets = create_contexts_target(corpus[0], window_size=1)\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1488,
     "status": "ok",
     "timestamp": 1610367915200,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "YcxHObOPubk-",
    "outputId": "131aeb79-f7f2-481a-dfa1-8d095e234160",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0]], dtype=int32),\n",
       " array([[[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1]]], dtype=int32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform contexts and targets to one-hot encoding\n",
    "contexts = convert_one_hot(contexts, len(word2idx))\n",
    "targets = convert_one_hot(targets, len(word2idx))\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1483,
     "status": "ok",
     "timestamp": 1610367915200,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "HnLqi9QXubk-"
   },
   "outputs": [],
   "source": [
    "# define Skip-gram model\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # initialize weights\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # create layers\n",
    "        self.in_layer = Dense(W_in)\n",
    "        self.out_layer = Dense(W_out)\n",
    "        self.loss_layers = [SoftmaxWithCrossEntropy() for i in range(window_size * 2)]\n",
    "\n",
    "        layers = [self.in_layer, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # word vector matrix\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        h = self.in_layer.forward(contexts)\n",
    "        s = self.out_layer.forward(h)\n",
    "        loss = sum([self.loss_layers[i].forward(s, targets[:, i]) for i in range(self.window_size * 2)])\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ds = sum([self.loss_layers[i].backward(dout) for i in range(self.window_size * 2)])\n",
    "        dh = self.out_layer.backward(ds)\n",
    "        self.in_layer.backward(dh)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3135,
     "status": "ok",
     "timestamp": 1610367916856,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "O7H4N4gbubk_",
    "outputId": "7969a4cb-4a59-4956-f583-beafbf303b1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 213/1000 [00:00<00:00, 1099.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 1/2, Loss: 4.158683133063523\n",
      "Epoch: 2, Iteration: 1/2, Loss: 4.158829884418726\n",
      "Epoch: 3, Iteration: 1/2, Loss: 4.158748943819637\n",
      "Epoch: 4, Iteration: 1/2, Loss: 4.158641924971452\n",
      "Epoch: 5, Iteration: 1/2, Loss: 4.158664161763337\n",
      "Epoch: 6, Iteration: 1/2, Loss: 4.158550190295049\n",
      "Epoch: 7, Iteration: 1/2, Loss: 4.158653925113125\n",
      "Epoch: 8, Iteration: 1/2, Loss: 4.1583778876679816\n",
      "Epoch: 9, Iteration: 1/2, Loss: 4.158492072712999\n",
      "Epoch: 10, Iteration: 1/2, Loss: 4.158305888374532\n",
      "Epoch: 11, Iteration: 1/2, Loss: 4.158463987745089\n",
      "Epoch: 12, Iteration: 1/2, Loss: 4.158133139385151\n",
      "Epoch: 13, Iteration: 1/2, Loss: 4.1583276629360455\n",
      "Epoch: 14, Iteration: 1/2, Loss: 4.158143325648012\n",
      "Epoch: 15, Iteration: 1/2, Loss: 4.157813325742446\n",
      "Epoch: 16, Iteration: 1/2, Loss: 4.1581137870812075\n",
      "Epoch: 17, Iteration: 1/2, Loss: 4.157837101411868\n",
      "Epoch: 18, Iteration: 1/2, Loss: 4.1577483853316135\n",
      "Epoch: 19, Iteration: 1/2, Loss: 4.157744076896938\n",
      "Epoch: 20, Iteration: 1/2, Loss: 4.1568601682821775\n",
      "Epoch: 21, Iteration: 1/2, Loss: 4.1575170117463776\n",
      "Epoch: 22, Iteration: 1/2, Loss: 4.157027086376548\n",
      "Epoch: 23, Iteration: 1/2, Loss: 4.156898996508216\n",
      "Epoch: 24, Iteration: 1/2, Loss: 4.157189515491074\n",
      "Epoch: 25, Iteration: 1/2, Loss: 4.156485406879171\n",
      "Epoch: 26, Iteration: 1/2, Loss: 4.155718458073135\n",
      "Epoch: 27, Iteration: 1/2, Loss: 4.156433732880075\n",
      "Epoch: 28, Iteration: 1/2, Loss: 4.155531221054712\n",
      "Epoch: 29, Iteration: 1/2, Loss: 4.154414163590994\n",
      "Epoch: 30, Iteration: 1/2, Loss: 4.154662426957964\n",
      "Epoch: 31, Iteration: 1/2, Loss: 4.154745409807298\n",
      "Epoch: 32, Iteration: 1/2, Loss: 4.153678806396332\n",
      "Epoch: 33, Iteration: 1/2, Loss: 4.153068910667244\n",
      "Epoch: 34, Iteration: 1/2, Loss: 4.1538406248063655\n",
      "Epoch: 35, Iteration: 1/2, Loss: 4.1513930425286905\n",
      "Epoch: 36, Iteration: 1/2, Loss: 4.150992264346536\n",
      "Epoch: 37, Iteration: 1/2, Loss: 4.150636871243375\n",
      "Epoch: 38, Iteration: 1/2, Loss: 4.148057590549222\n",
      "Epoch: 39, Iteration: 1/2, Loss: 4.15038380810431\n",
      "Epoch: 40, Iteration: 1/2, Loss: 4.147259836359552\n",
      "Epoch: 41, Iteration: 1/2, Loss: 4.145042184499322\n",
      "Epoch: 42, Iteration: 1/2, Loss: 4.145230173346229\n",
      "Epoch: 43, Iteration: 1/2, Loss: 4.141200303168101\n",
      "Epoch: 44, Iteration: 1/2, Loss: 4.140381063751779\n",
      "Epoch: 45, Iteration: 1/2, Loss: 4.1374269312629\n",
      "Epoch: 46, Iteration: 1/2, Loss: 4.1391437551271455\n",
      "Epoch: 47, Iteration: 1/2, Loss: 4.130964983953235\n",
      "Epoch: 48, Iteration: 1/2, Loss: 4.1374289155279715\n",
      "Epoch: 49, Iteration: 1/2, Loss: 4.122381339519753\n",
      "Epoch: 50, Iteration: 1/2, Loss: 4.12307713233113\n",
      "Epoch: 51, Iteration: 1/2, Loss: 4.123465243633064\n",
      "Epoch: 52, Iteration: 1/2, Loss: 4.123986560914694\n",
      "Epoch: 53, Iteration: 1/2, Loss: 4.114067241275395\n",
      "Epoch: 54, Iteration: 1/2, Loss: 4.095992717520317\n",
      "Epoch: 55, Iteration: 1/2, Loss: 4.108827701400436\n",
      "Epoch: 56, Iteration: 1/2, Loss: 4.091437707861402\n",
      "Epoch: 57, Iteration: 1/2, Loss: 4.068055228315735\n",
      "Epoch: 58, Iteration: 1/2, Loss: 4.076837595603672\n",
      "Epoch: 59, Iteration: 1/2, Loss: 4.094191727762781\n",
      "Epoch: 60, Iteration: 1/2, Loss: 4.062032575773291\n",
      "Epoch: 61, Iteration: 1/2, Loss: 4.0393581019807785\n",
      "Epoch: 62, Iteration: 1/2, Loss: 4.055736483852057\n",
      "Epoch: 63, Iteration: 1/2, Loss: 3.9809631640520444\n",
      "Epoch: 64, Iteration: 1/2, Loss: 4.030166419784676\n",
      "Epoch: 65, Iteration: 1/2, Loss: 3.964119455750062\n",
      "Epoch: 66, Iteration: 1/2, Loss: 4.044473802167605\n",
      "Epoch: 67, Iteration: 1/2, Loss: 3.9408453478207752\n",
      "Epoch: 68, Iteration: 1/2, Loss: 3.8737957820509177\n",
      "Epoch: 69, Iteration: 1/2, Loss: 3.933785858285003\n",
      "Epoch: 70, Iteration: 1/2, Loss: 3.8783459894065193\n",
      "Epoch: 71, Iteration: 1/2, Loss: 3.8817946382193163\n",
      "Epoch: 72, Iteration: 1/2, Loss: 3.827804986002069\n",
      "Epoch: 73, Iteration: 1/2, Loss: 3.730248719777094\n",
      "Epoch: 74, Iteration: 1/2, Loss: 3.7900980765166796\n",
      "Epoch: 75, Iteration: 1/2, Loss: 3.7347972881582074\n",
      "Epoch: 76, Iteration: 1/2, Loss: 3.7140563021230113\n",
      "Epoch: 77, Iteration: 1/2, Loss: 3.6261697021265697\n",
      "Epoch: 78, Iteration: 1/2, Loss: 3.6779582329110667\n",
      "Epoch: 79, Iteration: 1/2, Loss: 3.4733593924726103\n",
      "Epoch: 80, Iteration: 1/2, Loss: 3.538184577916243\n",
      "Epoch: 81, Iteration: 1/2, Loss: 3.439027726733509\n",
      "Epoch: 82, Iteration: 1/2, Loss: 3.337943591808388\n",
      "Epoch: 83, Iteration: 1/2, Loss: 3.4454586852980515\n",
      "Epoch: 84, Iteration: 1/2, Loss: 3.297278249912676\n",
      "Epoch: 85, Iteration: 1/2, Loss: 3.2815404698927333\n",
      "Epoch: 86, Iteration: 1/2, Loss: 3.3411544663774544\n",
      "Epoch: 87, Iteration: 1/2, Loss: 2.9264371270691703\n",
      "Epoch: 88, Iteration: 1/2, Loss: 3.238851791232483\n",
      "Epoch: 89, Iteration: 1/2, Loss: 2.9364214248983354\n",
      "Epoch: 90, Iteration: 1/2, Loss: 3.170629699495508\n",
      "Epoch: 91, Iteration: 1/2, Loss: 3.0975362867101404\n",
      "Epoch: 92, Iteration: 1/2, Loss: 2.7941187687378477\n",
      "Epoch: 93, Iteration: 1/2, Loss: 2.710286133148413\n",
      "Epoch: 94, Iteration: 1/2, Loss: 2.95021089428778\n",
      "Epoch: 95, Iteration: 1/2, Loss: 2.9469125576294615\n",
      "Epoch: 96, Iteration: 1/2, Loss: 2.4838506214573113\n",
      "Epoch: 97, Iteration: 1/2, Loss: 2.9147603184953788\n",
      "Epoch: 98, Iteration: 1/2, Loss: 2.415116634924737\n",
      "Epoch: 99, Iteration: 1/2, Loss: 2.6952299890946168\n",
      "Epoch: 100, Iteration: 1/2, Loss: 2.6316169535057448\n",
      "Epoch: 101, Iteration: 1/2, Loss: 2.486338717893589\n",
      "Epoch: 102, Iteration: 1/2, Loss: 2.487291037403983\n",
      "Epoch: 103, Iteration: 1/2, Loss: 2.431256627782225\n",
      "Epoch: 104, Iteration: 1/2, Loss: 2.429176725592415\n",
      "Epoch: 105, Iteration: 1/2, Loss: 2.428784215212835\n",
      "Epoch: 106, Iteration: 1/2, Loss: 2.3119705699627406\n",
      "Epoch: 107, Iteration: 1/2, Loss: 2.310562726864898\n",
      "Epoch: 108, Iteration: 1/2, Loss: 2.269164228613778\n",
      "Epoch: 109, Iteration: 1/2, Loss: 2.2955594841207008\n",
      "Epoch: 110, Iteration: 1/2, Loss: 2.146917566312676\n",
      "Epoch: 111, Iteration: 1/2, Loss: 2.1907649223455863\n",
      "Epoch: 112, Iteration: 1/2, Loss: 2.1542578998311717\n",
      "Epoch: 113, Iteration: 1/2, Loss: 2.134067047775421\n",
      "Epoch: 114, Iteration: 1/2, Loss: 2.023238924515757\n",
      "Epoch: 115, Iteration: 1/2, Loss: 2.077846469347934\n",
      "Epoch: 116, Iteration: 1/2, Loss: 2.083876759044089\n",
      "Epoch: 117, Iteration: 1/2, Loss: 2.0170593040642584\n",
      "Epoch: 118, Iteration: 1/2, Loss: 1.9644488422229887\n",
      "Epoch: 119, Iteration: 1/2, Loss: 1.9317948091307526\n",
      "Epoch: 120, Iteration: 1/2, Loss: 1.9857422782767091\n",
      "Epoch: 121, Iteration: 1/2, Loss: 1.921260224550271\n",
      "Epoch: 122, Iteration: 1/2, Loss: 1.9098205104159471\n",
      "Epoch: 123, Iteration: 1/2, Loss: 1.9221647780519515\n",
      "Epoch: 124, Iteration: 1/2, Loss: 1.8063386166924054\n",
      "Epoch: 125, Iteration: 1/2, Loss: 1.9184673191813404\n",
      "Epoch: 126, Iteration: 1/2, Loss: 1.785506731559856\n",
      "Epoch: 127, Iteration: 1/2, Loss: 1.8473714727189372\n",
      "Epoch: 128, Iteration: 1/2, Loss: 1.8345484933210128\n",
      "Epoch: 129, Iteration: 1/2, Loss: 1.7768624082255426\n",
      "Epoch: 130, Iteration: 1/2, Loss: 1.7836496903776373\n",
      "Epoch: 131, Iteration: 1/2, Loss: 1.7434206542153574\n",
      "Epoch: 132, Iteration: 1/2, Loss: 1.76158115912386\n",
      "Epoch: 133, Iteration: 1/2, Loss: 1.7686427610634083\n",
      "Epoch: 134, Iteration: 1/2, Loss: 1.706471129513275\n",
      "Epoch: 135, Iteration: 1/2, Loss: 1.7215504981078977\n",
      "Epoch: 136, Iteration: 1/2, Loss: 1.7006984446933147\n",
      "Epoch: 137, Iteration: 1/2, Loss: 1.6970975659749268\n",
      "Epoch: 138, Iteration: 1/2, Loss: 1.7125490126631464\n",
      "Epoch: 139, Iteration: 1/2, Loss: 1.6727674054182042\n",
      "Epoch: 140, Iteration: 1/2, Loss: 1.64885412422522\n",
      "Epoch: 141, Iteration: 1/2, Loss: 1.6960193974311062\n",
      "Epoch: 142, Iteration: 1/2, Loss: 1.6357574053454882\n",
      "Epoch: 143, Iteration: 1/2, Loss: 1.6545494811015948\n",
      "Epoch: 144, Iteration: 1/2, Loss: 1.6248132448699195\n",
      "Epoch: 145, Iteration: 1/2, Loss: 1.6688906577731193\n",
      "Epoch: 146, Iteration: 1/2, Loss: 1.6034035893451164\n",
      "Epoch: 147, Iteration: 1/2, Loss: 1.638013232268397\n",
      "Epoch: 148, Iteration: 1/2, Loss: 1.5762291771791865\n",
      "Epoch: 149, Iteration: 1/2, Loss: 1.5988093878239429\n",
      "Epoch: 150, Iteration: 1/2, Loss: 1.5861909756516557\n",
      "Epoch: 151, Iteration: 1/2, Loss: 1.646606182074509\n",
      "Epoch: 152, Iteration: 1/2, Loss: 1.5879262539118697\n",
      "Epoch: 153, Iteration: 1/2, Loss: 1.5477729045914512\n",
      "Epoch: 154, Iteration: 1/2, Loss: 1.5858031494905924\n",
      "Epoch: 155, Iteration: 1/2, Loss: 1.5851203367278277\n",
      "Epoch: 156, Iteration: 1/2, Loss: 1.5580249994632491\n",
      "Epoch: 157, Iteration: 1/2, Loss: 1.54871699759717\n",
      "Epoch: 158, Iteration: 1/2, Loss: 1.553985440096052\n",
      "Epoch: 159, Iteration: 1/2, Loss: 1.5875637046481934\n",
      "Epoch: 160, Iteration: 1/2, Loss: 1.5516003309550654\n",
      "Epoch: 161, Iteration: 1/2, Loss: 1.5412517221409083\n",
      "Epoch: 162, Iteration: 1/2, Loss: 1.5370738985282393\n",
      "Epoch: 163, Iteration: 1/2, Loss: 1.5582970578153772\n",
      "Epoch: 164, Iteration: 1/2, Loss: 1.5366682198498434\n",
      "Epoch: 165, Iteration: 1/2, Loss: 1.5166499887576026\n",
      "Epoch: 166, Iteration: 1/2, Loss: 1.5179798131036781\n",
      "Epoch: 167, Iteration: 1/2, Loss: 1.5453833035456206\n",
      "Epoch: 168, Iteration: 1/2, Loss: 1.5237161011651046\n",
      "Epoch: 169, Iteration: 1/2, Loss: 1.503474597406157\n",
      "Epoch: 170, Iteration: 1/2, Loss: 1.5317970274628268\n",
      "Epoch: 171, Iteration: 1/2, Loss: 1.5100633794458473\n",
      "Epoch: 172, Iteration: 1/2, Loss: 1.5180373336291946\n",
      "Epoch: 173, Iteration: 1/2, Loss: 1.5016895537236605\n",
      "Epoch: 174, Iteration: 1/2, Loss: 1.5144702485094228\n",
      "Epoch: 175, Iteration: 1/2, Loss: 1.5001344561040462\n",
      "Epoch: 176, Iteration: 1/2, Loss: 1.5244292859060375\n",
      "Epoch: 177, Iteration: 1/2, Loss: 1.5004803852244546\n",
      "Epoch: 178, Iteration: 1/2, Loss: 1.4860410845327547\n",
      "Epoch: 179, Iteration: 1/2, Loss: 1.4808755201620347\n",
      "Epoch: 180, Iteration: 1/2, Loss: 1.5097668832600717\n",
      "Epoch: 181, Iteration: 1/2, Loss: 1.4890993128580687\n",
      "Epoch: 182, Iteration: 1/2, Loss: 1.4934998836490965\n",
      "Epoch: 183, Iteration: 1/2, Loss: 1.494168527733642\n",
      "Epoch: 184, Iteration: 1/2, Loss: 1.4792960297674267\n",
      "Epoch: 185, Iteration: 1/2, Loss: 1.4838460761907553\n",
      "Epoch: 186, Iteration: 1/2, Loss: 1.4811170116227599\n",
      "Epoch: 187, Iteration: 1/2, Loss: 1.4870332980162142\n",
      "Epoch: 188, Iteration: 1/2, Loss: 1.477850012283627\n",
      "Epoch: 189, Iteration: 1/2, Loss: 1.4704871262601862\n",
      "Epoch: 190, Iteration: 1/2, Loss: 1.4842300541077396\n",
      "Epoch: 191, Iteration: 1/2, Loss: 1.4776175262230058\n",
      "Epoch: 192, Iteration: 1/2, Loss: 1.4705345595643267\n",
      "Epoch: 193, Iteration: 1/2, Loss: 1.4738414463454603\n",
      "Epoch: 194, Iteration: 1/2, Loss: 1.464727283701363\n",
      "Epoch: 195, Iteration: 1/2, Loss: 1.4818727480676959\n",
      "Epoch: 196, Iteration: 1/2, Loss: 1.4597239140866183\n",
      "Epoch: 197, Iteration: 1/2, Loss: 1.4628797976820573\n",
      "Epoch: 198, Iteration: 1/2, Loss: 1.4818623894964575\n",
      "Epoch: 199, Iteration: 1/2, Loss: 1.4631129533449947\n",
      "Epoch: 200, Iteration: 1/2, Loss: 1.44935098913077\n",
      "Epoch: 201, Iteration: 1/2, Loss: 1.465247766952474\n",
      "Epoch: 202, Iteration: 1/2, Loss: 1.4592033115037657\n",
      "Epoch: 203, Iteration: 1/2, Loss: 1.4708785240068\n",
      "Epoch: 204, Iteration: 1/2, Loss: 1.4539313539108347\n",
      "Epoch: 205, Iteration: 1/2, Loss: 1.464783115344977\n",
      "Epoch: 206, Iteration: 1/2, Loss: 1.4490308122211562\n",
      "Epoch: 207, Iteration: 1/2, Loss: 1.4647691725928156\n",
      "Epoch: 208, Iteration: 1/2, Loss: 1.4528249365220784\n",
      "Epoch: 209, Iteration: 1/2, Loss: 1.4532773855480174\n",
      "Epoch: 210, Iteration: 1/2, Loss: 1.449442082481331\n",
      "Epoch: 211, Iteration: 1/2, Loss: 1.449733371323969\n",
      "Epoch: 212, Iteration: 1/2, Loss: 1.45066168122783\n",
      "Epoch: 213, Iteration: 1/2, Loss: 1.4460404872827968\n",
      "Epoch: 214, Iteration: 1/2, Loss: 1.453190219902118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 323/1000 [00:00<00:00, 1067.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 215, Iteration: 1/2, Loss: 1.4524233683135352\n",
      "Epoch: 216, Iteration: 1/2, Loss: 1.4519207250460615\n",
      "Epoch: 217, Iteration: 1/2, Loss: 1.441949404600586\n",
      "Epoch: 218, Iteration: 1/2, Loss: 1.4531522568520894\n",
      "Epoch: 219, Iteration: 1/2, Loss: 1.4383727021815642\n",
      "Epoch: 220, Iteration: 1/2, Loss: 1.4449056022402842\n",
      "Epoch: 221, Iteration: 1/2, Loss: 1.4443441443360252\n",
      "Epoch: 222, Iteration: 1/2, Loss: 1.4378818497101744\n",
      "Epoch: 223, Iteration: 1/2, Loss: 1.4480104261943931\n",
      "Epoch: 224, Iteration: 1/2, Loss: 1.4370317777921708\n",
      "Epoch: 225, Iteration: 1/2, Loss: 1.4480640644900609\n",
      "Epoch: 226, Iteration: 1/2, Loss: 1.4444938592194214\n",
      "Epoch: 227, Iteration: 1/2, Loss: 1.434365772555874\n",
      "Epoch: 228, Iteration: 1/2, Loss: 1.4445886788232514\n",
      "Epoch: 229, Iteration: 1/2, Loss: 1.4352546533994301\n",
      "Epoch: 230, Iteration: 1/2, Loss: 1.4339379119628042\n",
      "Epoch: 231, Iteration: 1/2, Loss: 1.4466415093976528\n",
      "Epoch: 232, Iteration: 1/2, Loss: 1.437663311753476\n",
      "Epoch: 233, Iteration: 1/2, Loss: 1.431427471227762\n",
      "Epoch: 234, Iteration: 1/2, Loss: 1.4357011759856058\n",
      "Epoch: 235, Iteration: 1/2, Loss: 1.440098858426932\n",
      "Epoch: 236, Iteration: 1/2, Loss: 1.4348581867007446\n",
      "Epoch: 237, Iteration: 1/2, Loss: 1.4293524195976177\n",
      "Epoch: 238, Iteration: 1/2, Loss: 1.4333299375858146\n",
      "Epoch: 239, Iteration: 1/2, Loss: 1.4391743890553794\n",
      "Epoch: 240, Iteration: 1/2, Loss: 1.4238599611718121\n",
      "Epoch: 241, Iteration: 1/2, Loss: 1.4362278840826201\n",
      "Epoch: 242, Iteration: 1/2, Loss: 1.4358565984638885\n",
      "Epoch: 243, Iteration: 1/2, Loss: 1.4274410373448885\n",
      "Epoch: 244, Iteration: 1/2, Loss: 1.4322478594183352\n",
      "Epoch: 245, Iteration: 1/2, Loss: 1.4338555891592724\n",
      "Epoch: 246, Iteration: 1/2, Loss: 1.427029508925828\n",
      "Epoch: 247, Iteration: 1/2, Loss: 1.4291346802283034\n",
      "Epoch: 248, Iteration: 1/2, Loss: 1.431199270355331\n",
      "Epoch: 249, Iteration: 1/2, Loss: 1.425242896985881\n",
      "Epoch: 250, Iteration: 1/2, Loss: 1.4317609092672772\n",
      "Epoch: 251, Iteration: 1/2, Loss: 1.425485471177344\n",
      "Epoch: 252, Iteration: 1/2, Loss: 1.4270886950239063\n",
      "Epoch: 253, Iteration: 1/2, Loss: 1.4234130457267764\n",
      "Epoch: 254, Iteration: 1/2, Loss: 1.4308160399256438\n",
      "Epoch: 255, Iteration: 1/2, Loss: 1.4253758462258512\n",
      "Epoch: 256, Iteration: 1/2, Loss: 1.4259603362656548\n",
      "Epoch: 257, Iteration: 1/2, Loss: 1.4262685341459447\n",
      "Epoch: 258, Iteration: 1/2, Loss: 1.4252159757161769\n",
      "Epoch: 259, Iteration: 1/2, Loss: 1.4245206094872433\n",
      "Epoch: 260, Iteration: 1/2, Loss: 1.425383821089034\n",
      "Epoch: 261, Iteration: 1/2, Loss: 1.4226123241407977\n",
      "Epoch: 262, Iteration: 1/2, Loss: 1.4213052237921793\n",
      "Epoch: 263, Iteration: 1/2, Loss: 1.425690293540967\n",
      "Epoch: 264, Iteration: 1/2, Loss: 1.423158559388043\n",
      "Epoch: 265, Iteration: 1/2, Loss: 1.4263636663798618\n",
      "Epoch: 266, Iteration: 1/2, Loss: 1.4171657714797457\n",
      "Epoch: 267, Iteration: 1/2, Loss: 1.4249145418848181\n",
      "Epoch: 268, Iteration: 1/2, Loss: 1.4223518966155462\n",
      "Epoch: 269, Iteration: 1/2, Loss: 1.4215600212784216\n",
      "Epoch: 270, Iteration: 1/2, Loss: 1.4210545605379985\n",
      "Epoch: 271, Iteration: 1/2, Loss: 1.4204213595166366\n",
      "Epoch: 272, Iteration: 1/2, Loss: 1.420378186501913\n",
      "Epoch: 273, Iteration: 1/2, Loss: 1.420631794525021\n",
      "Epoch: 274, Iteration: 1/2, Loss: 1.423580286365545\n",
      "Epoch: 275, Iteration: 1/2, Loss: 1.4170678090532511\n",
      "Epoch: 276, Iteration: 1/2, Loss: 1.419093833996675\n",
      "Epoch: 277, Iteration: 1/2, Loss: 1.4199573196710547\n",
      "Epoch: 278, Iteration: 1/2, Loss: 1.4161356504895866\n",
      "Epoch: 279, Iteration: 1/2, Loss: 1.4206633233436197\n",
      "Epoch: 280, Iteration: 1/2, Loss: 1.4217003984439867\n",
      "Epoch: 281, Iteration: 1/2, Loss: 1.4179638431517645\n",
      "Epoch: 282, Iteration: 1/2, Loss: 1.4179447932565326\n",
      "Epoch: 283, Iteration: 1/2, Loss: 1.4129285618499914\n",
      "Epoch: 284, Iteration: 1/2, Loss: 1.4196878220633182\n",
      "Epoch: 285, Iteration: 1/2, Loss: 1.416818539434134\n",
      "Epoch: 286, Iteration: 1/2, Loss: 1.4172310594342339\n",
      "Epoch: 287, Iteration: 1/2, Loss: 1.4169450227921834\n",
      "Epoch: 288, Iteration: 1/2, Loss: 1.4136837101613577\n",
      "Epoch: 289, Iteration: 1/2, Loss: 1.4192458900276281\n",
      "Epoch: 290, Iteration: 1/2, Loss: 1.4154606299641874\n",
      "Epoch: 291, Iteration: 1/2, Loss: 1.416020488272735\n",
      "Epoch: 292, Iteration: 1/2, Loss: 1.4150398557371688\n",
      "Epoch: 293, Iteration: 1/2, Loss: 1.4157471254394696\n",
      "Epoch: 294, Iteration: 1/2, Loss: 1.4149831860738566\n",
      "Epoch: 295, Iteration: 1/2, Loss: 1.4151755665372585\n",
      "Epoch: 296, Iteration: 1/2, Loss: 1.4150507856152357\n",
      "Epoch: 297, Iteration: 1/2, Loss: 1.4147192166289984\n",
      "Epoch: 298, Iteration: 1/2, Loss: 1.4116403161553048\n",
      "Epoch: 299, Iteration: 1/2, Loss: 1.4190021709535394\n",
      "Epoch: 300, Iteration: 1/2, Loss: 1.4117456937584816\n",
      "Epoch: 301, Iteration: 1/2, Loss: 1.41587629217426\n",
      "Epoch: 302, Iteration: 1/2, Loss: 1.411604637912876\n",
      "Epoch: 303, Iteration: 1/2, Loss: 1.4126697667119528\n",
      "Epoch: 304, Iteration: 1/2, Loss: 1.4112138753601158\n",
      "Epoch: 305, Iteration: 1/2, Loss: 1.414568284084246\n",
      "Epoch: 306, Iteration: 1/2, Loss: 1.411070781366215\n",
      "Epoch: 307, Iteration: 1/2, Loss: 1.414804182730548\n",
      "Epoch: 308, Iteration: 1/2, Loss: 1.4104067808580565\n",
      "Epoch: 309, Iteration: 1/2, Loss: 1.414390217504853\n",
      "Epoch: 310, Iteration: 1/2, Loss: 1.4139382252422275\n",
      "Epoch: 311, Iteration: 1/2, Loss: 1.4077960012286923\n",
      "Epoch: 312, Iteration: 1/2, Loss: 1.414154509718729\n",
      "Epoch: 313, Iteration: 1/2, Loss: 1.411028660744532\n",
      "Epoch: 314, Iteration: 1/2, Loss: 1.4116941063343948\n",
      "Epoch: 315, Iteration: 1/2, Loss: 1.4112111696645018\n",
      "Epoch: 316, Iteration: 1/2, Loss: 1.4111825314445472\n",
      "Epoch: 317, Iteration: 1/2, Loss: 1.4086366533419967\n",
      "Epoch: 318, Iteration: 1/2, Loss: 1.4130414515858505\n",
      "Epoch: 319, Iteration: 1/2, Loss: 1.41037714080455\n",
      "Epoch: 320, Iteration: 1/2, Loss: 1.410116443930379\n",
      "Epoch: 321, Iteration: 1/2, Loss: 1.4106719845791984\n",
      "Epoch: 322, Iteration: 1/2, Loss: 1.4115078540910853\n",
      "Epoch: 323, Iteration: 1/2, Loss: 1.410129859310945\n",
      "Epoch: 324, Iteration: 1/2, Loss: 1.4078889980090517\n",
      "Epoch: 325, Iteration: 1/2, Loss: 1.4096545754701106\n",
      "Epoch: 326, Iteration: 1/2, Loss: 1.4115814817882786\n",
      "Epoch: 327, Iteration: 1/2, Loss: 1.4072240480416998\n",
      "Epoch: 328, Iteration: 1/2, Loss: 1.4112277650812088\n",
      "Epoch: 329, Iteration: 1/2, Loss: 1.4088096654688331\n",
      "Epoch: 330, Iteration: 1/2, Loss: 1.4091927692087054\n",
      "Epoch: 331, Iteration: 1/2, Loss: 1.4052085774571856\n",
      "Epoch: 332, Iteration: 1/2, Loss: 1.4105582144717688\n",
      "Epoch: 333, Iteration: 1/2, Loss: 1.4080850625996897\n",
      "Epoch: 334, Iteration: 1/2, Loss: 1.4087384494452029\n",
      "Epoch: 335, Iteration: 1/2, Loss: 1.4080024905883768\n",
      "Epoch: 336, Iteration: 1/2, Loss: 1.4085723626627256\n",
      "Epoch: 337, Iteration: 1/2, Loss: 1.4078312970657243\n",
      "Epoch: 338, Iteration: 1/2, Loss: 1.4063157072855668\n",
      "Epoch: 339, Iteration: 1/2, Loss: 1.409028358414955\n",
      "Epoch: 340, Iteration: 1/2, Loss: 1.4062830867488778\n",
      "Epoch: 341, Iteration: 1/2, Loss: 1.408765433363659\n",
      "Epoch: 342, Iteration: 1/2, Loss: 1.4073735745447782\n",
      "Epoch: 343, Iteration: 1/2, Loss: 1.4060710055983248\n",
      "Epoch: 344, Iteration: 1/2, Loss: 1.4089459665839212\n",
      "Epoch: 345, Iteration: 1/2, Loss: 1.4050653540789573\n",
      "Epoch: 346, Iteration: 1/2, Loss: 1.4070459596297438\n",
      "Epoch: 347, Iteration: 1/2, Loss: 1.4082617576459586\n",
      "Epoch: 348, Iteration: 1/2, Loss: 1.406551862775316\n",
      "Epoch: 349, Iteration: 1/2, Loss: 1.4067802923431492\n",
      "Epoch: 350, Iteration: 1/2, Loss: 1.4064274337078846\n",
      "Epoch: 351, Iteration: 1/2, Loss: 1.4060036420298019\n",
      "Epoch: 352, Iteration: 1/2, Loss: 1.406357533758872\n",
      "Epoch: 353, Iteration: 1/2, Loss: 1.4074291400521362\n",
      "Epoch: 354, Iteration: 1/2, Loss: 1.4032265903338874\n",
      "Epoch: 355, Iteration: 1/2, Loss: 1.4088973151325352\n",
      "Epoch: 356, Iteration: 1/2, Loss: 1.4056968751927172\n",
      "Epoch: 357, Iteration: 1/2, Loss: 1.4042071188039456\n",
      "Epoch: 358, Iteration: 1/2, Loss: 1.4055709435187147\n",
      "Epoch: 359, Iteration: 1/2, Loss: 1.4057472189536293\n",
      "Epoch: 360, Iteration: 1/2, Loss: 1.4051639873387574\n",
      "Epoch: 361, Iteration: 1/2, Loss: 1.4065576066439516\n",
      "Epoch: 362, Iteration: 1/2, Loss: 1.403988099462202\n",
      "Epoch: 363, Iteration: 1/2, Loss: 1.4045215494427514\n",
      "Epoch: 364, Iteration: 1/2, Loss: 1.406677632498348\n",
      "Epoch: 365, Iteration: 1/2, Loss: 1.4033159563679005\n",
      "Epoch: 366, Iteration: 1/2, Loss: 1.4050308966987226\n",
      "Epoch: 367, Iteration: 1/2, Loss: 1.4045240493580016\n",
      "Epoch: 368, Iteration: 1/2, Loss: 1.4059367699743908\n",
      "Epoch: 369, Iteration: 1/2, Loss: 1.4031642458819564\n",
      "Epoch: 370, Iteration: 1/2, Loss: 1.4045438489198783\n",
      "Epoch: 371, Iteration: 1/2, Loss: 1.4042818604945677\n",
      "Epoch: 372, Iteration: 1/2, Loss: 1.405249628508446\n",
      "Epoch: 373, Iteration: 1/2, Loss: 1.4040996093501528\n",
      "Epoch: 374, Iteration: 1/2, Loss: 1.402876778010134\n",
      "Epoch: 375, Iteration: 1/2, Loss: 1.4050476219702137\n",
      "Epoch: 376, Iteration: 1/2, Loss: 1.403831099922543\n",
      "Epoch: 377, Iteration: 1/2, Loss: 1.4022973570923352\n",
      "Epoch: 378, Iteration: 1/2, Loss: 1.4038371394005515\n",
      "Epoch: 379, Iteration: 1/2, Loss: 1.403399658459214\n",
      "Epoch: 380, Iteration: 1/2, Loss: 1.4048821525300959\n",
      "Epoch: 381, Iteration: 1/2, Loss: 1.4032733701937774\n",
      "Epoch: 382, Iteration: 1/2, Loss: 1.4009427302226098\n",
      "Epoch: 383, Iteration: 1/2, Loss: 1.4032929587912242\n",
      "Epoch: 384, Iteration: 1/2, Loss: 1.404164178156666\n",
      "Epoch: 385, Iteration: 1/2, Loss: 1.4033726403865843\n",
      "Epoch: 386, Iteration: 1/2, Loss: 1.4041640708593288\n",
      "Epoch: 387, Iteration: 1/2, Loss: 1.401647941874262\n",
      "Epoch: 388, Iteration: 1/2, Loss: 1.403062419086075\n",
      "Epoch: 389, Iteration: 1/2, Loss: 1.4023403472035267\n",
      "Epoch: 390, Iteration: 1/2, Loss: 1.4018228162321238\n",
      "Epoch: 391, Iteration: 1/2, Loss: 1.4036756107179598\n",
      "Epoch: 392, Iteration: 1/2, Loss: 1.4025229220193458\n",
      "Epoch: 393, Iteration: 1/2, Loss: 1.402340715086083\n",
      "Epoch: 394, Iteration: 1/2, Loss: 1.4025085201862817\n",
      "Epoch: 395, Iteration: 1/2, Loss: 1.402151437307066\n",
      "Epoch: 396, Iteration: 1/2, Loss: 1.4032983314399\n",
      "Epoch: 397, Iteration: 1/2, Loss: 1.40133339523821\n",
      "Epoch: 398, Iteration: 1/2, Loss: 1.4016786712069185\n",
      "Epoch: 399, Iteration: 1/2, Loss: 1.402385415867513\n",
      "Epoch: 400, Iteration: 1/2, Loss: 1.4017015377476234\n",
      "Epoch: 401, Iteration: 1/2, Loss: 1.4017111123034756\n",
      "Epoch: 402, Iteration: 1/2, Loss: 1.402941134971321\n",
      "Epoch: 403, Iteration: 1/2, Loss: 1.4007682851090404\n",
      "Epoch: 404, Iteration: 1/2, Loss: 1.4014330104773491\n",
      "Epoch: 405, Iteration: 1/2, Loss: 1.402875254642257\n",
      "Epoch: 406, Iteration: 1/2, Loss: 1.3994312689322164\n",
      "Epoch: 407, Iteration: 1/2, Loss: 1.4024655643737594\n",
      "Epoch: 408, Iteration: 1/2, Loss: 1.4014864958535205\n",
      "Epoch: 409, Iteration: 1/2, Loss: 1.4009891925603302\n",
      "Epoch: 410, Iteration: 1/2, Loss: 1.4002925902618522\n",
      "Epoch: 411, Iteration: 1/2, Loss: 1.4022318511314096\n",
      "Epoch: 412, Iteration: 1/2, Loss: 1.4011108704278552\n",
      "Epoch: 413, Iteration: 1/2, Loss: 1.4011314812098483\n",
      "Epoch: 414, Iteration: 1/2, Loss: 1.3998875838263105\n",
      "Epoch: 415, Iteration: 1/2, Loss: 1.4030069574669115\n",
      "Epoch: 416, Iteration: 1/2, Loss: 1.398776607719256\n",
      "Epoch: 417, Iteration: 1/2, Loss: 1.401655265720507\n",
      "Epoch: 418, Iteration: 1/2, Loss: 1.4010425322744176\n",
      "Epoch: 419, Iteration: 1/2, Loss: 1.4015100079131981\n",
      "Epoch: 420, Iteration: 1/2, Loss: 1.3994436710980809\n",
      "Epoch: 421, Iteration: 1/2, Loss: 1.4017172674420206\n",
      "Epoch: 422, Iteration: 1/2, Loss: 1.3984736577712322\n",
      "Epoch: 423, Iteration: 1/2, Loss: 1.4012871651367629\n",
      "Epoch: 424, Iteration: 1/2, Loss: 1.401375725697573\n",
      "Epoch: 425, Iteration: 1/2, Loss: 1.399276568781957\n",
      "Epoch: 426, Iteration: 1/2, Loss: 1.4004212595026317\n",
      "Epoch: 427, Iteration: 1/2, Loss: 1.399291871072986\n",
      "Epoch: 428, Iteration: 1/2, Loss: 1.40114719501039\n",
      "Epoch: 429, Iteration: 1/2, Loss: 1.3997801536728602\n",
      "Epoch: 430, Iteration: 1/2, Loss: 1.4001925801841169\n",
      "Epoch: 431, Iteration: 1/2, Loss: 1.3997833532006214\n",
      "Epoch: 432, Iteration: 1/2, Loss: 1.3999074869975519\n",
      "Epoch: 433, Iteration: 1/2, Loss: 1.3991410008976244\n",
      "Epoch: 434, Iteration: 1/2, Loss: 1.4007777221078963\n",
      "Epoch: 435, Iteration: 1/2, Loss: 1.3994779751795172\n",
      "Epoch: 436, Iteration: 1/2, Loss: 1.3999486097234313\n",
      "Epoch: 437, Iteration: 1/2, Loss: 1.4003176501762347\n",
      "Epoch: 438, Iteration: 1/2, Loss: 1.399681269755575\n",
      "Epoch: 439, Iteration: 1/2, Loss: 1.3984722381276322\n",
      "Epoch: 440, Iteration: 1/2, Loss: 1.3994543151904173\n",
      "Epoch: 441, Iteration: 1/2, Loss: 1.3995789559368093\n",
      "Epoch: 442, Iteration: 1/2, Loss: 1.3984280285326145\n",
      "Epoch: 443, Iteration: 1/2, Loss: 1.4010401641318573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 561/1000 [00:00<00:00, 1078.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 444, Iteration: 1/2, Loss: 1.3984976058716674\n",
      "Epoch: 445, Iteration: 1/2, Loss: 1.3992059197101017\n",
      "Epoch: 446, Iteration: 1/2, Loss: 1.400018187083923\n",
      "Epoch: 447, Iteration: 1/2, Loss: 1.399018188124533\n",
      "Epoch: 448, Iteration: 1/2, Loss: 1.398398533440506\n",
      "Epoch: 449, Iteration: 1/2, Loss: 1.3980904432509575\n",
      "Epoch: 450, Iteration: 1/2, Loss: 1.399636203802979\n",
      "Epoch: 451, Iteration: 1/2, Loss: 1.3989152833745537\n",
      "Epoch: 452, Iteration: 1/2, Loss: 1.3981129199847806\n",
      "Epoch: 453, Iteration: 1/2, Loss: 1.398835556229071\n",
      "Epoch: 454, Iteration: 1/2, Loss: 1.4003960378658171\n",
      "Epoch: 455, Iteration: 1/2, Loss: 1.3979774183857367\n",
      "Epoch: 456, Iteration: 1/2, Loss: 1.3978113347670664\n",
      "Epoch: 457, Iteration: 1/2, Loss: 1.3986211554224783\n",
      "Epoch: 458, Iteration: 1/2, Loss: 1.3985894090241828\n",
      "Epoch: 459, Iteration: 1/2, Loss: 1.3993439903435831\n",
      "Epoch: 460, Iteration: 1/2, Loss: 1.3984070715080945\n",
      "Epoch: 461, Iteration: 1/2, Loss: 1.3993999589238069\n",
      "Epoch: 462, Iteration: 1/2, Loss: 1.3983114999476711\n",
      "Epoch: 463, Iteration: 1/2, Loss: 1.3975861862896346\n",
      "Epoch: 464, Iteration: 1/2, Loss: 1.397594023352031\n",
      "Epoch: 465, Iteration: 1/2, Loss: 1.3991256099050253\n",
      "Epoch: 466, Iteration: 1/2, Loss: 1.3980627074322234\n",
      "Epoch: 467, Iteration: 1/2, Loss: 1.398178274634466\n",
      "Epoch: 468, Iteration: 1/2, Loss: 1.3981502840814781\n",
      "Epoch: 469, Iteration: 1/2, Loss: 1.3980926329189103\n",
      "Epoch: 470, Iteration: 1/2, Loss: 1.3981700739405034\n",
      "Epoch: 471, Iteration: 1/2, Loss: 1.3971042164360088\n",
      "Epoch: 472, Iteration: 1/2, Loss: 1.3988062554442475\n",
      "Epoch: 473, Iteration: 1/2, Loss: 1.397102946372479\n",
      "Epoch: 474, Iteration: 1/2, Loss: 1.3978776355718225\n",
      "Epoch: 475, Iteration: 1/2, Loss: 1.3994019378628044\n",
      "Epoch: 476, Iteration: 1/2, Loss: 1.3962432396066764\n",
      "Epoch: 477, Iteration: 1/2, Loss: 1.3985624853188479\n",
      "Epoch: 478, Iteration: 1/2, Loss: 1.3977775258225287\n",
      "Epoch: 479, Iteration: 1/2, Loss: 1.3968049065853048\n",
      "Epoch: 480, Iteration: 1/2, Loss: 1.3977188834003305\n",
      "Epoch: 481, Iteration: 1/2, Loss: 1.3975372611740995\n",
      "Epoch: 482, Iteration: 1/2, Loss: 1.3982820209007933\n",
      "Epoch: 483, Iteration: 1/2, Loss: 1.3976492057663232\n",
      "Epoch: 484, Iteration: 1/2, Loss: 1.3980512245710852\n",
      "Epoch: 485, Iteration: 1/2, Loss: 1.3967974644976344\n",
      "Epoch: 486, Iteration: 1/2, Loss: 1.397331590379403\n",
      "Epoch: 487, Iteration: 1/2, Loss: 1.3980620501337384\n",
      "Epoch: 488, Iteration: 1/2, Loss: 1.3966224290615163\n",
      "Epoch: 489, Iteration: 1/2, Loss: 1.3965772247046675\n",
      "Epoch: 490, Iteration: 1/2, Loss: 1.397958913505604\n",
      "Epoch: 491, Iteration: 1/2, Loss: 1.3972733371380266\n",
      "Epoch: 492, Iteration: 1/2, Loss: 1.3971516850102965\n",
      "Epoch: 493, Iteration: 1/2, Loss: 1.3963980674858147\n",
      "Epoch: 494, Iteration: 1/2, Loss: 1.3985295009733076\n",
      "Epoch: 495, Iteration: 1/2, Loss: 1.3962523326220162\n",
      "Epoch: 496, Iteration: 1/2, Loss: 1.3971020014588769\n",
      "Epoch: 497, Iteration: 1/2, Loss: 1.3977159737821738\n",
      "Epoch: 498, Iteration: 1/2, Loss: 1.3962729603885733\n",
      "Epoch: 499, Iteration: 1/2, Loss: 1.3969366618902952\n",
      "Epoch: 500, Iteration: 1/2, Loss: 1.3961961852467644\n",
      "Epoch: 501, Iteration: 1/2, Loss: 1.3967983579811813\n",
      "Epoch: 502, Iteration: 1/2, Loss: 1.3974863209613035\n",
      "Epoch: 503, Iteration: 1/2, Loss: 1.3968189586473614\n",
      "Epoch: 504, Iteration: 1/2, Loss: 1.3974311138156377\n",
      "Epoch: 505, Iteration: 1/2, Loss: 1.3959801753266718\n",
      "Epoch: 506, Iteration: 1/2, Loss: 1.3967155888161034\n",
      "Epoch: 507, Iteration: 1/2, Loss: 1.396689849054445\n",
      "Epoch: 508, Iteration: 1/2, Loss: 1.3958599807023528\n",
      "Epoch: 509, Iteration: 1/2, Loss: 1.397920706087229\n",
      "Epoch: 510, Iteration: 1/2, Loss: 1.3964894664938812\n",
      "Epoch: 511, Iteration: 1/2, Loss: 1.3959072756855186\n",
      "Epoch: 512, Iteration: 1/2, Loss: 1.3971401810230424\n",
      "Epoch: 513, Iteration: 1/2, Loss: 1.3964393490150262\n",
      "Epoch: 514, Iteration: 1/2, Loss: 1.395679248878014\n",
      "Epoch: 515, Iteration: 1/2, Loss: 1.3963531250303132\n",
      "Epoch: 516, Iteration: 1/2, Loss: 1.39649867636001\n",
      "Epoch: 517, Iteration: 1/2, Loss: 1.3968708172747957\n",
      "Epoch: 518, Iteration: 1/2, Loss: 1.395026976168432\n",
      "Epoch: 519, Iteration: 1/2, Loss: 1.3969412251164963\n",
      "Epoch: 520, Iteration: 1/2, Loss: 1.395528251725351\n",
      "Epoch: 521, Iteration: 1/2, Loss: 1.3973812201441314\n",
      "Epoch: 522, Iteration: 1/2, Loss: 1.3954699499895686\n",
      "Epoch: 523, Iteration: 1/2, Loss: 1.3955762589355314\n",
      "Epoch: 524, Iteration: 1/2, Loss: 1.3968164395106095\n",
      "Epoch: 525, Iteration: 1/2, Loss: 1.396603646692267\n",
      "Epoch: 526, Iteration: 1/2, Loss: 1.394747712854139\n",
      "Epoch: 527, Iteration: 1/2, Loss: 1.3967435426411132\n",
      "Epoch: 528, Iteration: 1/2, Loss: 1.39653429090235\n",
      "Epoch: 529, Iteration: 1/2, Loss: 1.3952723751384712\n",
      "Epoch: 530, Iteration: 1/2, Loss: 1.3959494919968962\n",
      "Epoch: 531, Iteration: 1/2, Loss: 1.3958475606851155\n",
      "Epoch: 532, Iteration: 1/2, Loss: 1.3959507890513114\n",
      "Epoch: 533, Iteration: 1/2, Loss: 1.3963112367148949\n",
      "Epoch: 534, Iteration: 1/2, Loss: 1.3958601868845872\n",
      "Epoch: 535, Iteration: 1/2, Loss: 1.3950466670830441\n",
      "Epoch: 536, Iteration: 1/2, Loss: 1.3964237462345377\n",
      "Epoch: 537, Iteration: 1/2, Loss: 1.395146836322275\n",
      "Epoch: 538, Iteration: 1/2, Loss: 1.3950358176071365\n",
      "Epoch: 539, Iteration: 1/2, Loss: 1.396812115810174\n",
      "Epoch: 540, Iteration: 1/2, Loss: 1.3956224806971953\n",
      "Epoch: 541, Iteration: 1/2, Loss: 1.3944402753337646\n",
      "Epoch: 542, Iteration: 1/2, Loss: 1.396784824566384\n",
      "Epoch: 543, Iteration: 1/2, Loss: 1.3943319816768356\n",
      "Epoch: 544, Iteration: 1/2, Loss: 1.396049294900477\n",
      "Epoch: 545, Iteration: 1/2, Loss: 1.3961229235421875\n",
      "Epoch: 546, Iteration: 1/2, Loss: 1.3954197759148812\n",
      "Epoch: 547, Iteration: 1/2, Loss: 1.3948327296348642\n",
      "Epoch: 548, Iteration: 1/2, Loss: 1.395407857263423\n",
      "Epoch: 549, Iteration: 1/2, Loss: 1.3953727611838573\n",
      "Epoch: 550, Iteration: 1/2, Loss: 1.3953180352520094\n",
      "Epoch: 551, Iteration: 1/2, Loss: 1.3959440688155453\n",
      "Epoch: 552, Iteration: 1/2, Loss: 1.3947133391938122\n",
      "Epoch: 553, Iteration: 1/2, Loss: 1.3952362862629248\n",
      "Epoch: 554, Iteration: 1/2, Loss: 1.3947559197168662\n",
      "Epoch: 555, Iteration: 1/2, Loss: 1.3957716905173558\n",
      "Epoch: 556, Iteration: 1/2, Loss: 1.395164763847764\n",
      "Epoch: 557, Iteration: 1/2, Loss: 1.3952924735922438\n",
      "Epoch: 558, Iteration: 1/2, Loss: 1.3950458540685333\n",
      "Epoch: 559, Iteration: 1/2, Loss: 1.3951795994054934\n",
      "Epoch: 560, Iteration: 1/2, Loss: 1.3951192470288478\n",
      "Epoch: 561, Iteration: 1/2, Loss: 1.3950036332820472\n",
      "Epoch: 562, Iteration: 1/2, Loss: 1.3955832613811259\n",
      "Epoch: 563, Iteration: 1/2, Loss: 1.3939180651573078\n",
      "Epoch: 564, Iteration: 1/2, Loss: 1.3960558867948945\n",
      "Epoch: 565, Iteration: 1/2, Loss: 1.3944960971194047\n",
      "Epoch: 566, Iteration: 1/2, Loss: 1.3949145536658176\n",
      "Epoch: 567, Iteration: 1/2, Loss: 1.3949439138677215\n",
      "Epoch: 568, Iteration: 1/2, Loss: 1.3948090922116358\n",
      "Epoch: 569, Iteration: 1/2, Loss: 1.394835204033241\n",
      "Epoch: 570, Iteration: 1/2, Loss: 1.395490026843411\n",
      "Epoch: 571, Iteration: 1/2, Loss: 1.3937249101601792\n",
      "Epoch: 572, Iteration: 1/2, Loss: 1.3953752598043305\n",
      "Epoch: 573, Iteration: 1/2, Loss: 1.3952559217336353\n",
      "Epoch: 574, Iteration: 1/2, Loss: 1.394157340366547\n",
      "Epoch: 575, Iteration: 1/2, Loss: 1.3942954099003786\n",
      "Epoch: 576, Iteration: 1/2, Loss: 1.3952149034612917\n",
      "Epoch: 577, Iteration: 1/2, Loss: 1.3946813124771054\n",
      "Epoch: 578, Iteration: 1/2, Loss: 1.3946652820788232\n",
      "Epoch: 579, Iteration: 1/2, Loss: 1.3946288984903688\n",
      "Epoch: 580, Iteration: 1/2, Loss: 1.3946124570503762\n",
      "Epoch: 581, Iteration: 1/2, Loss: 1.3946257384586294\n",
      "Epoch: 582, Iteration: 1/2, Loss: 1.395069363037527\n",
      "Epoch: 583, Iteration: 1/2, Loss: 1.3939532607167335\n",
      "Epoch: 584, Iteration: 1/2, Loss: 1.3945599249337066\n",
      "Epoch: 585, Iteration: 1/2, Loss: 1.3945539720432878\n",
      "Epoch: 586, Iteration: 1/2, Loss: 1.3944170555121413\n",
      "Epoch: 587, Iteration: 1/2, Loss: 1.3949828821314862\n",
      "Epoch: 588, Iteration: 1/2, Loss: 1.3939709731163554\n",
      "Epoch: 589, Iteration: 1/2, Loss: 1.3944318672931328\n",
      "Epoch: 590, Iteration: 1/2, Loss: 1.394830702237261\n",
      "Epoch: 591, Iteration: 1/2, Loss: 1.393873177978878\n",
      "Epoch: 592, Iteration: 1/2, Loss: 1.3943477760846985\n",
      "Epoch: 593, Iteration: 1/2, Loss: 1.3938446790164547\n",
      "Epoch: 594, Iteration: 1/2, Loss: 1.3952521721682503\n",
      "Epoch: 595, Iteration: 1/2, Loss: 1.3937499613802884\n",
      "Epoch: 596, Iteration: 1/2, Loss: 1.3942797305464794\n",
      "Epoch: 597, Iteration: 1/2, Loss: 1.3937938932959115\n",
      "Epoch: 598, Iteration: 1/2, Loss: 1.3947001584794316\n",
      "Epoch: 599, Iteration: 1/2, Loss: 1.3941549556356008\n",
      "Epoch: 600, Iteration: 1/2, Loss: 1.3947046804211194\n",
      "Epoch: 601, Iteration: 1/2, Loss: 1.3941838293520556\n",
      "Epoch: 602, Iteration: 1/2, Loss: 1.3936069891957676\n",
      "Epoch: 603, Iteration: 1/2, Loss: 1.3941031191461943\n",
      "Epoch: 604, Iteration: 1/2, Loss: 1.3941889977942397\n",
      "Epoch: 605, Iteration: 1/2, Loss: 1.3935357949621334\n",
      "Epoch: 606, Iteration: 1/2, Loss: 1.39504067809716\n",
      "Epoch: 607, Iteration: 1/2, Loss: 1.3935081874024886\n",
      "Epoch: 608, Iteration: 1/2, Loss: 1.394017584572453\n",
      "Epoch: 609, Iteration: 1/2, Loss: 1.3939977676311477\n",
      "Epoch: 610, Iteration: 1/2, Loss: 1.3940663541751448\n",
      "Epoch: 611, Iteration: 1/2, Loss: 1.3939884542624539\n",
      "Epoch: 612, Iteration: 1/2, Loss: 1.3943416702090397\n",
      "Epoch: 613, Iteration: 1/2, Loss: 1.3930121169371263\n",
      "Epoch: 614, Iteration: 1/2, Loss: 1.393880020585538\n",
      "Epoch: 615, Iteration: 1/2, Loss: 1.3944181866244674\n",
      "Epoch: 616, Iteration: 1/2, Loss: 1.3938227636075204\n",
      "Epoch: 617, Iteration: 1/2, Loss: 1.393373272620091\n",
      "Epoch: 618, Iteration: 1/2, Loss: 1.3947200654217844\n",
      "Epoch: 619, Iteration: 1/2, Loss: 1.393358483427519\n",
      "Epoch: 620, Iteration: 1/2, Loss: 1.3942413726692036\n",
      "Epoch: 621, Iteration: 1/2, Loss: 1.392859419242365\n",
      "Epoch: 622, Iteration: 1/2, Loss: 1.3942139887495708\n",
      "Epoch: 623, Iteration: 1/2, Loss: 1.3936899003026477\n",
      "Epoch: 624, Iteration: 1/2, Loss: 1.3937639619604172\n",
      "Epoch: 625, Iteration: 1/2, Loss: 1.3936229066829111\n",
      "Epoch: 626, Iteration: 1/2, Loss: 1.3932787570291976\n",
      "Epoch: 627, Iteration: 1/2, Loss: 1.3941655910417436\n",
      "Epoch: 628, Iteration: 1/2, Loss: 1.3931449181642903\n",
      "Epoch: 629, Iteration: 1/2, Loss: 1.394095541907892\n",
      "Epoch: 630, Iteration: 1/2, Loss: 1.393111686592977\n",
      "Epoch: 631, Iteration: 1/2, Loss: 1.3939877466273805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 775/1000 [00:00<00:00, 969.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 632, Iteration: 1/2, Loss: 1.3935886784766858\n",
      "Epoch: 633, Iteration: 1/2, Loss: 1.3936381880284914\n",
      "Epoch: 634, Iteration: 1/2, Loss: 1.3934442739601334\n",
      "Epoch: 635, Iteration: 1/2, Loss: 1.3934842180747846\n",
      "Epoch: 636, Iteration: 1/2, Loss: 1.3936034647857787\n",
      "Epoch: 637, Iteration: 1/2, Loss: 1.3933723474509283\n",
      "Epoch: 638, Iteration: 1/2, Loss: 1.3930976303136153\n",
      "Epoch: 639, Iteration: 1/2, Loss: 1.393840554104112\n",
      "Epoch: 640, Iteration: 1/2, Loss: 1.3930272059690718\n",
      "Epoch: 641, Iteration: 1/2, Loss: 1.3938202747847677\n",
      "Epoch: 642, Iteration: 1/2, Loss: 1.3929879060986474\n",
      "Epoch: 643, Iteration: 1/2, Loss: 1.3942586736697433\n",
      "Epoch: 644, Iteration: 1/2, Loss: 1.3929516846484442\n",
      "Epoch: 645, Iteration: 1/2, Loss: 1.3928739948772844\n",
      "Epoch: 646, Iteration: 1/2, Loss: 1.393722811096235\n",
      "Epoch: 647, Iteration: 1/2, Loss: 1.3933445830899718\n",
      "Epoch: 648, Iteration: 1/2, Loss: 1.3936860287876707\n",
      "Epoch: 649, Iteration: 1/2, Loss: 1.3928503695976566\n",
      "Epoch: 650, Iteration: 1/2, Loss: 1.3932774961044685\n",
      "Epoch: 651, Iteration: 1/2, Loss: 1.392795206004038\n",
      "Epoch: 652, Iteration: 1/2, Loss: 1.3932710215567012\n",
      "Epoch: 653, Iteration: 1/2, Loss: 1.39363403676297\n",
      "Epoch: 654, Iteration: 1/2, Loss: 1.3927338618281953\n",
      "Epoch: 655, Iteration: 1/2, Loss: 1.3931806395289645\n",
      "Epoch: 656, Iteration: 1/2, Loss: 1.3935905447632393\n",
      "Epoch: 657, Iteration: 1/2, Loss: 1.393168546453653\n",
      "Epoch: 658, Iteration: 1/2, Loss: 1.3935410935850638\n",
      "Epoch: 659, Iteration: 1/2, Loss: 1.3922920347002536\n",
      "Epoch: 660, Iteration: 1/2, Loss: 1.3931013893761302\n",
      "Epoch: 661, Iteration: 1/2, Loss: 1.3939038735174638\n",
      "Epoch: 662, Iteration: 1/2, Loss: 1.392221307970314\n",
      "Epoch: 663, Iteration: 1/2, Loss: 1.3930846828761476\n",
      "Epoch: 664, Iteration: 1/2, Loss: 1.3930507213751466\n",
      "Epoch: 665, Iteration: 1/2, Loss: 1.392981386298036\n",
      "Epoch: 666, Iteration: 1/2, Loss: 1.3933940550220576\n",
      "Epoch: 667, Iteration: 1/2, Loss: 1.3930212210602828\n",
      "Epoch: 668, Iteration: 1/2, Loss: 1.3930065610831863\n",
      "Epoch: 669, Iteration: 1/2, Loss: 1.3933327259517974\n",
      "Epoch: 670, Iteration: 1/2, Loss: 1.392517027101412\n",
      "Epoch: 671, Iteration: 1/2, Loss: 1.3933581478610146\n",
      "Epoch: 672, Iteration: 1/2, Loss: 1.3924861275114717\n",
      "Epoch: 673, Iteration: 1/2, Loss: 1.3929633408385167\n",
      "Epoch: 674, Iteration: 1/2, Loss: 1.3932498362683936\n",
      "Epoch: 675, Iteration: 1/2, Loss: 1.3925497968467606\n",
      "Epoch: 676, Iteration: 1/2, Loss: 1.3927966985453282\n",
      "Epoch: 677, Iteration: 1/2, Loss: 1.392465350308965\n",
      "Epoch: 678, Iteration: 1/2, Loss: 1.392783703776471\n",
      "Epoch: 679, Iteration: 1/2, Loss: 1.3928444095590486\n",
      "Epoch: 680, Iteration: 1/2, Loss: 1.3932462393830232\n",
      "Epoch: 681, Iteration: 1/2, Loss: 1.392724987786162\n",
      "Epoch: 682, Iteration: 1/2, Loss: 1.392383235746622\n",
      "Epoch: 683, Iteration: 1/2, Loss: 1.393514021422983\n",
      "Epoch: 684, Iteration: 1/2, Loss: 1.3923563274465727\n",
      "Epoch: 685, Iteration: 1/2, Loss: 1.3926963238570993\n",
      "Epoch: 686, Iteration: 1/2, Loss: 1.392799467414398\n",
      "Epoch: 687, Iteration: 1/2, Loss: 1.3930671808691102\n",
      "Epoch: 688, Iteration: 1/2, Loss: 1.3922280015385922\n",
      "Epoch: 689, Iteration: 1/2, Loss: 1.3927576783955182\n",
      "Epoch: 690, Iteration: 1/2, Loss: 1.392612494608228\n",
      "Epoch: 691, Iteration: 1/2, Loss: 1.3925988670520466\n",
      "Epoch: 692, Iteration: 1/2, Loss: 1.392308394075862\n",
      "Epoch: 693, Iteration: 1/2, Loss: 1.393341957071298\n",
      "Epoch: 694, Iteration: 1/2, Loss: 1.3922824501075968\n",
      "Epoch: 695, Iteration: 1/2, Loss: 1.3921399632078468\n",
      "Epoch: 696, Iteration: 1/2, Loss: 1.3933820179809957\n",
      "Epoch: 697, Iteration: 1/2, Loss: 1.3921574792034819\n",
      "Epoch: 698, Iteration: 1/2, Loss: 1.392491304977363\n",
      "Epoch: 699, Iteration: 1/2, Loss: 1.3926321745987231\n",
      "Epoch: 700, Iteration: 1/2, Loss: 1.3928764811205478\n",
      "Epoch: 701, Iteration: 1/2, Loss: 1.392119894213869\n",
      "Epoch: 702, Iteration: 1/2, Loss: 1.3921262727632056\n",
      "Epoch: 703, Iteration: 1/2, Loss: 1.3928233979358644\n",
      "Epoch: 704, Iteration: 1/2, Loss: 1.3924919867652916\n",
      "Epoch: 705, Iteration: 1/2, Loss: 1.3924842705576816\n",
      "Epoch: 706, Iteration: 1/2, Loss: 1.3927622593612323\n",
      "Epoch: 707, Iteration: 1/2, Loss: 1.3917141882313049\n",
      "Epoch: 708, Iteration: 1/2, Loss: 1.392766274418809\n",
      "Epoch: 709, Iteration: 1/2, Loss: 1.3927518282455815\n",
      "Epoch: 710, Iteration: 1/2, Loss: 1.3923892932297912\n",
      "Epoch: 711, Iteration: 1/2, Loss: 1.3920393044462656\n",
      "Epoch: 712, Iteration: 1/2, Loss: 1.3923100127905945\n",
      "Epoch: 713, Iteration: 1/2, Loss: 1.3927402612659112\n",
      "Epoch: 714, Iteration: 1/2, Loss: 1.3923493221857717\n",
      "Epoch: 715, Iteration: 1/2, Loss: 1.391982486565849\n",
      "Epoch: 716, Iteration: 1/2, Loss: 1.3923004473410954\n",
      "Epoch: 717, Iteration: 1/2, Loss: 1.391947301642356\n",
      "Epoch: 718, Iteration: 1/2, Loss: 1.3926325606415029\n",
      "Epoch: 719, Iteration: 1/2, Loss: 1.3926378843654643\n",
      "Epoch: 720, Iteration: 1/2, Loss: 1.3922634373997216\n",
      "Epoch: 721, Iteration: 1/2, Loss: 1.3915606162417928\n",
      "Epoch: 722, Iteration: 1/2, Loss: 1.3925696219211927\n",
      "Epoch: 723, Iteration: 1/2, Loss: 1.3919008514706286\n",
      "Epoch: 724, Iteration: 1/2, Loss: 1.3925381781731445\n",
      "Epoch: 725, Iteration: 1/2, Loss: 1.3918680477469048\n",
      "Epoch: 726, Iteration: 1/2, Loss: 1.392546682094952\n",
      "Epoch: 727, Iteration: 1/2, Loss: 1.3922082435592789\n",
      "Epoch: 728, Iteration: 1/2, Loss: 1.3921145773653527\n",
      "Epoch: 729, Iteration: 1/2, Loss: 1.3921279721091864\n",
      "Epoch: 730, Iteration: 1/2, Loss: 1.3921894507412147\n",
      "Epoch: 731, Iteration: 1/2, Loss: 1.3920699668223728\n",
      "Epoch: 732, Iteration: 1/2, Loss: 1.392222412838175\n",
      "Epoch: 733, Iteration: 1/2, Loss: 1.392382275393289\n",
      "Epoch: 734, Iteration: 1/2, Loss: 1.3914389915204612\n",
      "Epoch: 735, Iteration: 1/2, Loss: 1.3920886175022356\n",
      "Epoch: 736, Iteration: 1/2, Loss: 1.3927220300955931\n",
      "Epoch: 737, Iteration: 1/2, Loss: 1.391787744707184\n",
      "Epoch: 738, Iteration: 1/2, Loss: 1.3916314352285326\n",
      "Epoch: 739, Iteration: 1/2, Loss: 1.3924051344675865\n",
      "Epoch: 740, Iteration: 1/2, Loss: 1.3923887266526669\n",
      "Epoch: 741, Iteration: 1/2, Loss: 1.3917011427312787\n",
      "Epoch: 742, Iteration: 1/2, Loss: 1.3919503436185416\n",
      "Epoch: 743, Iteration: 1/2, Loss: 1.3916744266567587\n",
      "Epoch: 744, Iteration: 1/2, Loss: 1.3926221379690702\n",
      "Epoch: 745, Iteration: 1/2, Loss: 1.3916838405068361\n",
      "Epoch: 746, Iteration: 1/2, Loss: 1.3919622136712795\n",
      "Epoch: 747, Iteration: 1/2, Loss: 1.3915844300372984\n",
      "Epoch: 748, Iteration: 1/2, Loss: 1.3922147228896746\n",
      "Epoch: 749, Iteration: 1/2, Loss: 1.3919643386480927\n",
      "Epoch: 750, Iteration: 1/2, Loss: 1.3918735592927327\n",
      "Epoch: 751, Iteration: 1/2, Loss: 1.3919372834739454\n",
      "Epoch: 752, Iteration: 1/2, Loss: 1.3915428094549007\n",
      "Epoch: 753, Iteration: 1/2, Loss: 1.3922375975112669\n",
      "Epoch: 754, Iteration: 1/2, Loss: 1.3921913292543375\n",
      "Epoch: 755, Iteration: 1/2, Loss: 1.3914939819468901\n",
      "Epoch: 756, Iteration: 1/2, Loss: 1.3915371316124654\n",
      "Epoch: 757, Iteration: 1/2, Loss: 1.3918813474280325\n",
      "Epoch: 758, Iteration: 1/2, Loss: 1.392485108683235\n",
      "Epoch: 759, Iteration: 1/2, Loss: 1.3918153073405282\n",
      "Epoch: 760, Iteration: 1/2, Loss: 1.3911358531478888\n",
      "Epoch: 761, Iteration: 1/2, Loss: 1.3924190550290363\n",
      "Epoch: 762, Iteration: 1/2, Loss: 1.3914382193237336\n",
      "Epoch: 763, Iteration: 1/2, Loss: 1.3917655713819288\n",
      "Epoch: 764, Iteration: 1/2, Loss: 1.3918136679364115\n",
      "Epoch: 765, Iteration: 1/2, Loss: 1.3917521173242164\n",
      "Epoch: 766, Iteration: 1/2, Loss: 1.3920543492866058\n",
      "Epoch: 767, Iteration: 1/2, Loss: 1.3914511578553466\n",
      "Epoch: 768, Iteration: 1/2, Loss: 1.3913861755951222\n",
      "Epoch: 769, Iteration: 1/2, Loss: 1.3917117729410005\n",
      "Epoch: 770, Iteration: 1/2, Loss: 1.3919972813912813\n",
      "Epoch: 771, Iteration: 1/2, Loss: 1.391990057635799\n",
      "Epoch: 772, Iteration: 1/2, Loss: 1.39141670988439\n",
      "Epoch: 773, Iteration: 1/2, Loss: 1.3916829925901704\n",
      "Epoch: 774, Iteration: 1/2, Loss: 1.3913093324595245\n",
      "Epoch: 775, Iteration: 1/2, Loss: 1.3922901336174742\n",
      "Epoch: 776, Iteration: 1/2, Loss: 1.3912678260913336\n",
      "Epoch: 777, Iteration: 1/2, Loss: 1.3913691342585082\n",
      "Epoch: 778, Iteration: 1/2, Loss: 1.3919604920271793\n",
      "Epoch: 779, Iteration: 1/2, Loss: 1.3915952423812485\n",
      "Epoch: 780, Iteration: 1/2, Loss: 1.3918567845110466\n",
      "Epoch: 781, Iteration: 1/2, Loss: 1.3910005941246042\n",
      "Epoch: 782, Iteration: 1/2, Loss: 1.3918374099152488\n",
      "Epoch: 783, Iteration: 1/2, Loss: 1.3916431652365249\n",
      "Epoch: 784, Iteration: 1/2, Loss: 1.3912304396925705\n",
      "Epoch: 785, Iteration: 1/2, Loss: 1.3918792814415455\n",
      "Epoch: 786, Iteration: 1/2, Loss: 1.3915538965679575\n",
      "Epoch: 787, Iteration: 1/2, Loss: 1.391486900172987\n",
      "Epoch: 788, Iteration: 1/2, Loss: 1.39181803721288\n",
      "Epoch: 789, Iteration: 1/2, Loss: 1.3911715181180238\n",
      "Epoch: 790, Iteration: 1/2, Loss: 1.3915820183691319\n",
      "Epoch: 791, Iteration: 1/2, Loss: 1.391160211587339\n",
      "Epoch: 792, Iteration: 1/2, Loss: 1.3917426607707832\n",
      "Epoch: 793, Iteration: 1/2, Loss: 1.3915369784645426\n",
      "Epoch: 794, Iteration: 1/2, Loss: 1.391141166640693\n",
      "Epoch: 795, Iteration: 1/2, Loss: 1.3917474627563724\n",
      "Epoch: 796, Iteration: 1/2, Loss: 1.391438787847625\n",
      "Epoch: 797, Iteration: 1/2, Loss: 1.3914699406026907\n",
      "Epoch: 798, Iteration: 1/2, Loss: 1.3911004514047216\n",
      "Epoch: 799, Iteration: 1/2, Loss: 1.3920034469077782\n",
      "Epoch: 800, Iteration: 1/2, Loss: 1.3910694068593874\n",
      "Epoch: 801, Iteration: 1/2, Loss: 1.391432887843095\n",
      "Epoch: 802, Iteration: 1/2, Loss: 1.3914031927218917\n",
      "Epoch: 803, Iteration: 1/2, Loss: 1.3914217163912541\n",
      "Epoch: 804, Iteration: 1/2, Loss: 1.3913564661944353\n",
      "Epoch: 805, Iteration: 1/2, Loss: 1.3916050537732945\n",
      "Epoch: 806, Iteration: 1/2, Loss: 1.3911086891519355\n",
      "Epoch: 807, Iteration: 1/2, Loss: 1.3915858806302235\n",
      "Epoch: 808, Iteration: 1/2, Loss: 1.3910159629722298\n",
      "Epoch: 809, Iteration: 1/2, Loss: 1.3913734017799997\n",
      "Epoch: 810, Iteration: 1/2, Loss: 1.3915937938318539\n",
      "Epoch: 811, Iteration: 1/2, Loss: 1.391298215104793\n",
      "Epoch: 812, Iteration: 1/2, Loss: 1.3910717609266614\n",
      "Epoch: 813, Iteration: 1/2, Loss: 1.3912753545781094\n",
      "Epoch: 814, Iteration: 1/2, Loss: 1.3912607449575018\n",
      "Epoch: 815, Iteration: 1/2, Loss: 1.3912627370005706\n",
      "Epoch: 816, Iteration: 1/2, Loss: 1.3912169024641283\n",
      "Epoch: 817, Iteration: 1/2, Loss: 1.391259312699062\n",
      "Epoch: 818, Iteration: 1/2, Loss: 1.3912832933100918\n",
      "Epoch: 819, Iteration: 1/2, Loss: 1.3915140958257717\n",
      "Epoch: 820, Iteration: 1/2, Loss: 1.391218468771781\n",
      "Epoch: 821, Iteration: 1/2, Loss: 1.390923958030226\n",
      "Epoch: 822, Iteration: 1/2, Loss: 1.3911963506660858\n",
      "Epoch: 823, Iteration: 1/2, Loss: 1.3915243969910938\n",
      "Epoch: 824, Iteration: 1/2, Loss: 1.3911934608522107\n",
      "Epoch: 825, Iteration: 1/2, Loss: 1.3906344717418597\n",
      "Epoch: 826, Iteration: 1/2, Loss: 1.3911443616857586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1001.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 827, Iteration: 1/2, Loss: 1.3912016247771941\n",
      "Epoch: 828, Iteration: 1/2, Loss: 1.3911700215782288\n",
      "Epoch: 829, Iteration: 1/2, Loss: 1.3911377066389874\n",
      "Epoch: 830, Iteration: 1/2, Loss: 1.3916782271147006\n",
      "Epoch: 831, Iteration: 1/2, Loss: 1.3911440537332684\n",
      "Epoch: 832, Iteration: 1/2, Loss: 1.390852906283401\n",
      "Epoch: 833, Iteration: 1/2, Loss: 1.3911640594951429\n",
      "Epoch: 834, Iteration: 1/2, Loss: 1.3908082869617513\n",
      "Epoch: 835, Iteration: 1/2, Loss: 1.3913631152659804\n",
      "Epoch: 836, Iteration: 1/2, Loss: 1.3910992791222383\n",
      "Epoch: 837, Iteration: 1/2, Loss: 1.3913448186568251\n",
      "Epoch: 838, Iteration: 1/2, Loss: 1.3910719399668983\n",
      "Epoch: 839, Iteration: 1/2, Loss: 1.3908062031545887\n",
      "Epoch: 840, Iteration: 1/2, Loss: 1.3910134034237602\n",
      "Epoch: 841, Iteration: 1/2, Loss: 1.3913589733247829\n",
      "Epoch: 842, Iteration: 1/2, Loss: 1.3905114534712317\n",
      "Epoch: 843, Iteration: 1/2, Loss: 1.3913423191590346\n",
      "Epoch: 844, Iteration: 1/2, Loss: 1.3910276809286615\n",
      "Epoch: 845, Iteration: 1/2, Loss: 1.3909389621596178\n",
      "Epoch: 846, Iteration: 1/2, Loss: 1.3910434527165463\n",
      "Epoch: 847, Iteration: 1/2, Loss: 1.3910037493013405\n",
      "Epoch: 848, Iteration: 1/2, Loss: 1.3907449582928657\n",
      "Epoch: 849, Iteration: 1/2, Loss: 1.3915411020533672\n",
      "Epoch: 850, Iteration: 1/2, Loss: 1.3906981834233052\n",
      "Epoch: 851, Iteration: 1/2, Loss: 1.3912106424709005\n",
      "Epoch: 852, Iteration: 1/2, Loss: 1.3907536681135237\n",
      "Epoch: 853, Iteration: 1/2, Loss: 1.3909079807709377\n",
      "Epoch: 854, Iteration: 1/2, Loss: 1.3912061445700703\n",
      "Epoch: 855, Iteration: 1/2, Loss: 1.3904360394748259\n",
      "Epoch: 856, Iteration: 1/2, Loss: 1.391191509824033\n",
      "Epoch: 857, Iteration: 1/2, Loss: 1.3912122525870534\n",
      "Epoch: 858, Iteration: 1/2, Loss: 1.3906568086887816\n",
      "Epoch: 859, Iteration: 1/2, Loss: 1.3906236055177517\n",
      "Epoch: 860, Iteration: 1/2, Loss: 1.3912025948419464\n",
      "Epoch: 861, Iteration: 1/2, Loss: 1.3908525233420095\n",
      "Epoch: 862, Iteration: 1/2, Loss: 1.3911729323631383\n",
      "Epoch: 863, Iteration: 1/2, Loss: 1.390309713207023\n",
      "Epoch: 864, Iteration: 1/2, Loss: 1.3911300913008493\n",
      "Epoch: 865, Iteration: 1/2, Loss: 1.3906376103568205\n",
      "Epoch: 866, Iteration: 1/2, Loss: 1.3911140879150548\n",
      "Epoch: 867, Iteration: 1/2, Loss: 1.3908347872489017\n",
      "Epoch: 868, Iteration: 1/2, Loss: 1.3911064452305977\n",
      "Epoch: 869, Iteration: 1/2, Loss: 1.3906206273621078\n",
      "Epoch: 870, Iteration: 1/2, Loss: 1.3910400223542791\n",
      "Epoch: 871, Iteration: 1/2, Loss: 1.3905286825609724\n",
      "Epoch: 872, Iteration: 1/2, Loss: 1.3905998677587905\n",
      "Epoch: 873, Iteration: 1/2, Loss: 1.3910645901012113\n",
      "Epoch: 874, Iteration: 1/2, Loss: 1.3908247807688636\n",
      "Epoch: 875, Iteration: 1/2, Loss: 1.3907930461193878\n",
      "Epoch: 876, Iteration: 1/2, Loss: 1.3907799131838257\n",
      "Epoch: 877, Iteration: 1/2, Loss: 1.3907638627942887\n",
      "Epoch: 878, Iteration: 1/2, Loss: 1.3907022795664221\n",
      "Epoch: 879, Iteration: 1/2, Loss: 1.3905545792816967\n",
      "Epoch: 880, Iteration: 1/2, Loss: 1.3909607311870595\n",
      "Epoch: 881, Iteration: 1/2, Loss: 1.390761136724449\n",
      "Epoch: 882, Iteration: 1/2, Loss: 1.3905194213109724\n",
      "Epoch: 883, Iteration: 1/2, Loss: 1.3912106338998182\n",
      "Epoch: 884, Iteration: 1/2, Loss: 1.390494539677728\n",
      "Epoch: 885, Iteration: 1/2, Loss: 1.3907530567851611\n",
      "Epoch: 886, Iteration: 1/2, Loss: 1.3906720991863022\n",
      "Epoch: 887, Iteration: 1/2, Loss: 1.3907014580942263\n",
      "Epoch: 888, Iteration: 1/2, Loss: 1.390738207826996\n",
      "Epoch: 889, Iteration: 1/2, Loss: 1.390895321334467\n",
      "Epoch: 890, Iteration: 1/2, Loss: 1.3906707706568642\n",
      "Epoch: 891, Iteration: 1/2, Loss: 1.3906878958672606\n",
      "Epoch: 892, Iteration: 1/2, Loss: 1.390466883664069\n",
      "Epoch: 893, Iteration: 1/2, Loss: 1.3906132052329319\n",
      "Epoch: 894, Iteration: 1/2, Loss: 1.390662698409254\n",
      "Epoch: 895, Iteration: 1/2, Loss: 1.3906138975376248\n",
      "Epoch: 896, Iteration: 1/2, Loss: 1.3904388942153108\n",
      "Epoch: 897, Iteration: 1/2, Loss: 1.3911148835173823\n",
      "Epoch: 898, Iteration: 1/2, Loss: 1.3903967538862632\n",
      "Epoch: 899, Iteration: 1/2, Loss: 1.3906136378350156\n",
      "Epoch: 900, Iteration: 1/2, Loss: 1.390878012004554\n",
      "Epoch: 901, Iteration: 1/2, Loss: 1.3901162665972318\n",
      "Epoch: 902, Iteration: 1/2, Loss: 1.3905601280343052\n",
      "Epoch: 903, Iteration: 1/2, Loss: 1.3908354251976798\n",
      "Epoch: 904, Iteration: 1/2, Loss: 1.3906012610269616\n",
      "Epoch: 905, Iteration: 1/2, Loss: 1.390628455193783\n",
      "Epoch: 906, Iteration: 1/2, Loss: 1.3905718151383275\n",
      "Epoch: 907, Iteration: 1/2, Loss: 1.3907654575418895\n",
      "Epoch: 908, Iteration: 1/2, Loss: 1.3903023422752807\n",
      "Epoch: 909, Iteration: 1/2, Loss: 1.3905726056539458\n",
      "Epoch: 910, Iteration: 1/2, Loss: 1.3905755914435383\n",
      "Epoch: 911, Iteration: 1/2, Loss: 1.3905403664674532\n",
      "Epoch: 912, Iteration: 1/2, Loss: 1.3904723647998813\n",
      "Epoch: 913, Iteration: 1/2, Loss: 1.3905889897957746\n",
      "Epoch: 914, Iteration: 1/2, Loss: 1.3904613035007911\n",
      "Epoch: 915, Iteration: 1/2, Loss: 1.3908101466997589\n",
      "Epoch: 916, Iteration: 1/2, Loss: 1.3904797146432535\n",
      "Epoch: 917, Iteration: 1/2, Loss: 1.3902475892956487\n",
      "Epoch: 918, Iteration: 1/2, Loss: 1.390554061646245\n",
      "Epoch: 919, Iteration: 1/2, Loss: 1.390195005045077\n",
      "Epoch: 920, Iteration: 1/2, Loss: 1.390745109396709\n",
      "Epoch: 921, Iteration: 1/2, Loss: 1.390687190485147\n",
      "Epoch: 922, Iteration: 1/2, Loss: 1.390289318762161\n",
      "Epoch: 923, Iteration: 1/2, Loss: 1.3906573236311432\n",
      "Epoch: 924, Iteration: 1/2, Loss: 1.390455146499629\n",
      "Epoch: 925, Iteration: 1/2, Loss: 1.390213356955005\n",
      "Epoch: 926, Iteration: 1/2, Loss: 1.3904571755927564\n",
      "Epoch: 927, Iteration: 1/2, Loss: 1.3904249719916653\n",
      "Epoch: 928, Iteration: 1/2, Loss: 1.3906950476472804\n",
      "Epoch: 929, Iteration: 1/2, Loss: 1.390208552217708\n",
      "Epoch: 930, Iteration: 1/2, Loss: 1.3903872419010979\n",
      "Epoch: 931, Iteration: 1/2, Loss: 1.3901812397885502\n",
      "Epoch: 932, Iteration: 1/2, Loss: 1.3906285044331614\n",
      "Epoch: 933, Iteration: 1/2, Loss: 1.390368780525793\n",
      "Epoch: 934, Iteration: 1/2, Loss: 1.3904405226270058\n",
      "Epoch: 935, Iteration: 1/2, Loss: 1.390369576347183\n",
      "Epoch: 936, Iteration: 1/2, Loss: 1.3906148651911368\n",
      "Epoch: 937, Iteration: 1/2, Loss: 1.3901750939904371\n",
      "Epoch: 938, Iteration: 1/2, Loss: 1.3903525168580613\n",
      "Epoch: 939, Iteration: 1/2, Loss: 1.3903680501423124\n",
      "Epoch: 940, Iteration: 1/2, Loss: 1.3901255143493887\n",
      "Epoch: 941, Iteration: 1/2, Loss: 1.3905788224260909\n",
      "Epoch: 942, Iteration: 1/2, Loss: 1.390119564660799\n",
      "Epoch: 943, Iteration: 1/2, Loss: 1.3905971841491391\n",
      "Epoch: 944, Iteration: 1/2, Loss: 1.39028933503625\n",
      "Epoch: 945, Iteration: 1/2, Loss: 1.3903278147654612\n",
      "Epoch: 946, Iteration: 1/2, Loss: 1.390084573322853\n",
      "Epoch: 947, Iteration: 1/2, Loss: 1.3905715486984012\n",
      "Epoch: 948, Iteration: 1/2, Loss: 1.390336687272776\n",
      "Epoch: 949, Iteration: 1/2, Loss: 1.3903039900241119\n",
      "Epoch: 950, Iteration: 1/2, Loss: 1.390298067763298\n",
      "Epoch: 951, Iteration: 1/2, Loss: 1.390277744897741\n",
      "Epoch: 952, Iteration: 1/2, Loss: 1.3900606264752542\n",
      "Epoch: 953, Iteration: 1/2, Loss: 1.3905060710489663\n",
      "Epoch: 954, Iteration: 1/2, Loss: 1.3902316895247804\n",
      "Epoch: 955, Iteration: 1/2, Loss: 1.3903112013003702\n",
      "Epoch: 956, Iteration: 1/2, Loss: 1.3904439798506034\n",
      "Epoch: 957, Iteration: 1/2, Loss: 1.3900459003421008\n",
      "Epoch: 958, Iteration: 1/2, Loss: 1.3904767746428168\n",
      "Epoch: 959, Iteration: 1/2, Loss: 1.3900389251315297\n",
      "Epoch: 960, Iteration: 1/2, Loss: 1.390015410735836\n",
      "Epoch: 961, Iteration: 1/2, Loss: 1.3904153394275551\n",
      "Epoch: 962, Iteration: 1/2, Loss: 1.3902983399929512\n",
      "Epoch: 963, Iteration: 1/2, Loss: 1.389974055639596\n",
      "Epoch: 964, Iteration: 1/2, Loss: 1.3906701860031845\n",
      "Epoch: 965, Iteration: 1/2, Loss: 1.3900074963690388\n",
      "Epoch: 966, Iteration: 1/2, Loss: 1.3901362912902289\n",
      "Epoch: 967, Iteration: 1/2, Loss: 1.390239952744377\n",
      "Epoch: 968, Iteration: 1/2, Loss: 1.3901685668191723\n",
      "Epoch: 969, Iteration: 1/2, Loss: 1.390420913796171\n",
      "Epoch: 970, Iteration: 1/2, Loss: 1.3899372976375646\n",
      "Epoch: 971, Iteration: 1/2, Loss: 1.3901921986881742\n",
      "Epoch: 972, Iteration: 1/2, Loss: 1.39018733186515\n",
      "Epoch: 973, Iteration: 1/2, Loss: 1.390137768753127\n",
      "Epoch: 974, Iteration: 1/2, Loss: 1.3902043854276072\n",
      "Epoch: 975, Iteration: 1/2, Loss: 1.3899116433952807\n",
      "Epoch: 976, Iteration: 1/2, Loss: 1.3903801542375227\n",
      "Epoch: 977, Iteration: 1/2, Loss: 1.3901154071101502\n",
      "Epoch: 978, Iteration: 1/2, Loss: 1.3899397912151352\n",
      "Epoch: 979, Iteration: 1/2, Loss: 1.3904022244065868\n",
      "Epoch: 980, Iteration: 1/2, Loss: 1.3900850461834515\n",
      "Epoch: 981, Iteration: 1/2, Loss: 1.3901368555887292\n",
      "Epoch: 982, Iteration: 1/2, Loss: 1.3899049630199183\n",
      "Epoch: 983, Iteration: 1/2, Loss: 1.3903148341270577\n",
      "Epoch: 984, Iteration: 1/2, Loss: 1.3901166353128593\n",
      "Epoch: 985, Iteration: 1/2, Loss: 1.3903277562678733\n",
      "Epoch: 986, Iteration: 1/2, Loss: 1.3896584857529928\n",
      "Epoch: 987, Iteration: 1/2, Loss: 1.3902919487683856\n",
      "Epoch: 988, Iteration: 1/2, Loss: 1.3900563786385234\n",
      "Epoch: 989, Iteration: 1/2, Loss: 1.3900803495039322\n",
      "Epoch: 990, Iteration: 1/2, Loss: 1.3903130297266733\n",
      "Epoch: 991, Iteration: 1/2, Loss: 1.389674674173143\n",
      "Epoch: 992, Iteration: 1/2, Loss: 1.390263536376671\n",
      "Epoch: 993, Iteration: 1/2, Loss: 1.3902539493559818\n",
      "Epoch: 994, Iteration: 1/2, Loss: 1.3900535909131038\n",
      "Epoch: 995, Iteration: 1/2, Loss: 1.3900340747614066\n",
      "Epoch: 996, Iteration: 1/2, Loss: 1.3898632269295517\n",
      "Epoch: 997, Iteration: 1/2, Loss: 1.3900239979939193\n",
      "Epoch: 998, Iteration: 1/2, Loss: 1.3898498703519067\n",
      "Epoch: 999, Iteration: 1/2, Loss: 1.3904035539129411\n",
      "Epoch: 1000, Iteration: 1/2, Loss: 1.3898402748456302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "# configurations\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "# define model\n",
    "skip_gram = SkipGram(len(word2idx), hidden_size, window_size)\n",
    "sgd_optimizer = SGD()\n",
    "trainer = Trainer(skip_gram, sgd_optimizer)\n",
    "\n",
    "# start training\n",
    "trainer.fit(contexts, targets, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 3130,
     "status": "ok",
     "timestamp": 1610367916856,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "M6xgIlAEublA",
    "outputId": "f00169c1-ff0f-4d48-b65e-4c52d3a676b5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3126,
     "status": "ok",
     "timestamp": 1610367916857,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "-HrG2iP3ublA",
    "outputId": "b2900311-52f8-4871-b597-e37558716717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now [-2.406494   -1.3359886  -0.01463528  0.17371699 -0.60850954]\n",
      "processing [ 1.0699152  -0.19422366 -1.734612    0.7705752  -1.8127654 ]\n",
      "am [ 0.90440714 -0.95872253  0.97527564 -0.16870174  2.338234  ]\n",
      "studying [ 0.6148318   2.4574852   1.296611   -0.34457648 -0.11082134]\n",
      "natural [ 2.2434552  -1.220744   -1.5721378   0.12666838  0.9266584 ]\n",
      "language [-2.3770816   1.466507    0.86329347 -1.074731   -0.08798598]\n",
      "i [ 0.00642992  0.00231732  0.00313393 -0.01434269  0.02408556]\n",
      ". [ 0.00239632  0.00177278  0.00878207 -0.01484943 -0.01563045]\n"
     ]
    }
   ],
   "source": [
    "# check skip-gram results\n",
    "word_vecs = skip_gram.word_vecs\n",
    "for word_id, word in idx2word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "實作簡易word2vec模型_作業.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
