{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 了解為何需要推論方法的詞向量及其優缺點\n",
    "\n",
    "本次作業主要為思考題，請學員根據題目思考適合的回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1:\n",
    "請學員思考為何不直接使用one-hot encoding的方式建立詞向量，而要有其他計數方法與推論方法的詞向量產生方式？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "- 文本詞彙數量大時，詞向量太過稀疏(sparse vector)造成記憶體資源浪費\n",
    "- 詞向量之間為正交關係(orthogonal)，無法充分表達字詞間的相關性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2:\n",
    "相較於計數手法的詞向量(ex: one-hot, 共現矩陣, PPMI)，word2vec的方法有何優點？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "- 根據分布假說(distribution hypothesis)word2vec會考慮上下文，與計數手法比起來效果較佳\n",
    "- 當新字詞加入時，可以利用先前訓練好的模型當預訓練權重，而不需從頭訓練\n",
    "- 以小批次(mini-batch)進行訓練，因此當文本數量很龐大時，也可以訓練並使用GPU進行運算加速"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
