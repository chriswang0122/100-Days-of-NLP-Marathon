{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCIvz30AOj-H"
   },
   "source": [
    "# 作業 : 觀察機器翻譯 Attention 內容 \n",
    "- 仔細地觀察機器翻譯 Attention 結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWGLeN9BOxEF"
   },
   "source": [
    "# [作業重點]\n",
    "- 透過視覺化注意力層瞭解 Attention 的運作方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8406,
     "status": "ok",
     "timestamp": 1612194264232,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "UIBD2Nn-OI-1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import spacy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11424,
     "status": "ok",
     "timestamp": 1612194267257,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "FQoAR8K-RyHd",
    "outputId": "41776292-4196-48a2-cce3-6d423bb871fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-01 15:44:23--  https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n",
      "Resolving drive.google.com (drive.google.com)... 172.217.7.238, 2607:f8b0:4004:808::200e\n",
      "Connecting to drive.google.com (drive.google.com)|172.217.7.238|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fqal8vqhvj10kac2i6atu3un4bu54iv6/1612194225000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2021-02-01 15:44:25--  https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fqal8vqhvj10kac2i6atu3un4bu54iv6/1612194225000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n",
      "Resolving doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)... 172.217.13.65, 2607:f8b0:4004:808::2001\n",
      "Connecting to doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)|172.217.13.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-font-ttf]\n",
      "Saving to: ‘taipei_sans_tc_beta.ttf’\n",
      "\n",
      "taipei_sans_tc_beta     [  <=>               ]  19.70M  58.4MB/s    in 0.3s    \n",
      "\n",
      "2021-02-01 15:44:27 (58.4 MB/s) - ‘taipei_sans_tc_beta.ttf’ saved [20659344]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Colab 進行 matplotlib 繪圖繁體中文\n",
    "# 下載字體\n",
    "!wget -O taipei_sans_tc_beta.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.font_manager import FontProperties\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# 自定義字體\n",
    "myfont = FontProperties(fname='taipei_sans_tc_beta.ttf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qib-OcCLIkup"
   },
   "source": [
    "機器翻譯的訓練資料來源: https://www.manythings.org/anki/\r\n",
    "\r\n",
    "Chinese (Mandarin) - English --> cmn-eng.zip (24360)\r\n",
    "\r\n",
    "解壓檔案並放置於 data 目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12292,
     "status": "ok",
     "timestamp": 1612194268132,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "v1GC9mHUJByB",
    "outputId": "1bd016d8-bf8e-4ea1-def2-a341c9657c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-01 15:44:27--  https://www.manythings.org/anki/cmn-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.21.55.222, 172.67.173.198, 2606:4700:3036::ac43:adc6, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.21.55.222|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1062383 (1.0M) [application/zip]\n",
      "Saving to: ‘cmn-eng.zip’\n",
      "\n",
      "cmn-eng.zip         100%[===================>]   1.01M  4.14MB/s    in 0.2s    \n",
      "\n",
      "2021-02-01 15:44:27 (4.14 MB/s) - ‘cmn-eng.zip’ saved [1062383/1062383]\n",
      "\n",
      "Archive:  cmn-eng.zip\n",
      "  inflating: data/cmn.txt            \n",
      "  inflating: data/_about.txt         \n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/cmn-eng.zip\r\n",
    "!unzip cmn-eng.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12286,
     "status": "ok",
     "timestamp": 1612194268132,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "wFjVGqegR5U8",
    "outputId": "03546029-4c6c-43ab-aef5-86816b4cc8ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: ['He was drowned.', '他被淹死了。']\n",
      "Total records: 24360\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "with open(os.path.join(data_dir, 'cmn.txt'), encoding='utf-8') as f:\n",
    "    lines = f.read().strip().split('\\n')\n",
    "    trnslt_pairs = [l.split('\\t') for l in lines]\n",
    "\n",
    "print(f\"Sample: {trnslt_pairs[1000][0:2]}\")\n",
    "print(f\"Total records: {len(trnslt_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iL_qV-iBK1jn"
   },
   "source": [
    "將資料切分成 train/valiation/test 三個資料集，且以 csv 格式儲存在 data 目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12281,
     "status": "ok",
     "timestamp": 1612194268133,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "Gnp47zRCK0gQ",
    "outputId": "aa41c2a3-d98c-484c-acb1-c198e4ada1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 19731 , validation data: 2193 , testing data: 2436\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(trnslt_pairs, test_size=0.1)\r\n",
    "train, val = train_test_split(train, test_size=0.1)\r\n",
    "print(f\"training data: {len(train)} , validation data: {len(val)} , testing data: {len(test)}\")\r\n",
    "\r\n",
    "def write_csv(data, file_path):\r\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as f:\r\n",
    "        writer = csv.writer(f)\r\n",
    "        for item in data:\r\n",
    "            writer.writerow([item[0], item[1]])\r\n",
    "\r\n",
    "write_csv(train, os.path.join(data_dir, 'train.csv'))\r\n",
    "write_csv(val, os.path.join(data_dir, 'val.csv'))\r\n",
    "write_csv(test, os.path.join(data_dir, 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ba8ALJB4MWOe"
   },
   "source": [
    "下載 spacy 英文/中文語料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23090,
     "status": "ok",
     "timestamp": 1612194278948,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "PvnlDPENQEsO",
    "outputId": "a17373b2-0f5e-4801-863f-6099445b140d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('zh_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\r\n",
    "spacy.cli.download(\"en_core_web_sm\")\r\n",
    "spacy.cli.download(\"zh_core_web_sm\")\r\n",
    "\r\n",
    "import en_core_web_sm, zh_core_web_sm\r\n",
    "spacy_en, spacy_zh = en_core_web_sm.load(), zh_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTG14b5wueNs"
   },
   "source": [
    "使用 torchtext 來準備訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 23084,
     "status": "ok",
     "timestamp": 1612194278949,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "okavgkx0uk3y"
   },
   "outputs": [],
   "source": [
    "def tokenize_en(text):\r\n",
    "    # 清除不需要的字元\r\n",
    "    text = re.sub(r'([.!?])', r' \\1', text)\r\n",
    "\r\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\r\n",
    "\r\n",
    "def tokenize_zh(text):\r\n",
    "    # 去掉非中文字元\r\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5A-Za-z0-9]', '', text)\r\n",
    "\r\n",
    "    return [word.text for word in spacy_zh.tokenizer(text)]\r\n",
    "\r\n",
    "TRG = Field(tokenize=tokenize_en, init_token='<sos>',\r\n",
    "            eos_token='<eos>', lower=True)\r\n",
    "SRC = Field(tokenize=tokenize_zh, init_token='<sos>', eos_token='<eos>',\r\n",
    "            lower=True, include_lengths=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwkGkK6tv295"
   },
   "source": [
    "使用 TabularDataset 讀資料並建立辭典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31816,
     "status": "ok",
     "timestamp": 1612194287685,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "xHJSLLihv4Cp",
    "outputId": "4ad9c006-7b6f-477f-ba23-fefe3cfbb5a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文語料的字元表長度: 12388, 英文的字元表長度: 6133\n",
      "Sample SRC: ['basho', '是', '最', '偉', '大', '的', '詩人'], TRG: ['basho', 'was', 'the', 'greatest', 'poet', '.']\n"
     ]
    }
   ],
   "source": [
    "train_dataset, dev_dataset, test_dataset = TabularDataset.splits(\r\n",
    "    path=data_dir, format='csv', skip_header=True,\r\n",
    "    train='train.csv', validation='val.csv', test='test.csv',\r\n",
    "    fields=[('trg', TRG), ('src', SRC)]\r\n",
    ")\r\n",
    "SRC.build_vocab(train_dataset, min_freq=1)\r\n",
    "TRG.build_vocab(train_dataset, min_freq=1)\r\n",
    "print(f\"中文語料的字元表長度: {len(SRC.vocab)}, 英文的字元表長度: {len(TRG.vocab)}\")\r\n",
    "print(f\"Sample SRC: {test_dataset[0].src}, TRG: {test_dataset[0].trg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 31811,
     "status": "ok",
     "timestamp": 1612194287686,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "Tl-KIM-nSA-H"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_dataset, dev_dataset, test_dataset),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYoqlKcrq2Z_"
   },
   "source": [
    "重點 Attention 層(點積)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 31806,
     "status": "ok",
     "timestamp": 1612194287686,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "wj3ZTHDMSGOF"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        '''\n",
    "            hidden: [batch_size, dec_hid_dim]\n",
    "            encoder_outputs: [src_len, batch_size, enc_hid_dim x 2]\n",
    "            mask: [batch_size , src_len]\n",
    "        '''\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        hidden = hidden.unsqueeze(1)  # (batch_size, 1 dec_hid_dim)\n",
    "        # (batch_size, 1, src_len)\n",
    "        attention = torch.matmul(hidden , encoder_outputs.permute(1, 2, 0))\n",
    "        attention = attention.squeeze(1)  # (batch_size, src_len)\n",
    "\n",
    "        attention = attention.masked_fill(mask==0, -1e10)\n",
    "\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5Svj0D91vrq"
   },
   "source": [
    "GRU 為底層的 bi-directional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 31803,
     "status": "ok",
     "timestamp": 1612194287687,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "L8AVtNly1opU"
   },
   "outputs": [],
   "source": [
    "class RNNEncoder(nn.Module):\r\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\r\n",
    "        super().__init__()\r\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\r\n",
    "\r\n",
    "        # bi-directional GRU encoder\r\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\r\n",
    "        \r\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "        \r\n",
    "    def forward(self, src, src_len):\r\n",
    "        '''\r\n",
    "        Args:\r\n",
    "            src: [src_len, batch_size]\r\n",
    "            src_len: [batch_size]\r\n",
    "        Returns:\r\n",
    "            outputs: [src_len, batch_size, enc_hid_dim * 2]\r\n",
    "            hidden: [batch_size, dec_hid_dim]\r\n",
    "        '''\r\n",
    "        # (src_len, batch_size, emb_dim)\r\n",
    "        embedded = self.dropout(self.embedding(src))\r\n",
    "                \r\n",
    "        packed_embedded = pack_padded_sequence(embedded, src_len)\r\n",
    "        # hidden: [n_layers * num_directions, batch_size, hid_dim]\r\n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\r\n",
    "        outputs, _ = pad_packed_sequence(packed_outputs) \r\n",
    "        # (src_len, batch_size, hid_dim * num_directions)\r\n",
    "        \r\n",
    "        # hidden[-2, :, : ] 是最後一層 forwards RNN\r\n",
    "        # hidden[-1, :, : ] 是最後一層 backwards RNN\r\n",
    "        hidden = torch.tanh(\r\n",
    "            self.fc(self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\r\n",
    "        )\r\n",
    "\r\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVVFtNZv1-zA"
   },
   "source": [
    "GRU 為底層的 RNN decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 31798,
     "status": "ok",
     "timestamp": 1612194287688,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "P-W2XwE51_IF"
   },
   "outputs": [],
   "source": [
    "class RNNDecoder(nn.Module):\r\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\r\n",
    "        super().__init__()\r\n",
    "        self.output_dim = output_dim\r\n",
    "        self.attention = attention\r\n",
    "        \r\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
    "        \r\n",
    "        # GRU decoder\r\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\r\n",
    "        \r\n",
    "        self.fc_out = nn.Linear(\r\n",
    "            (enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim\r\n",
    "        )\r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "        \r\n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\r\n",
    "        '''\r\n",
    "            input: [batch_size]\r\n",
    "            hidden: [batch_size, dec_hid_dim]\r\n",
    "            encoder_outputs: [src_len, batch_size, enc_hid_dim * 2]\r\n",
    "            mask: [batch_size, src_len]\r\n",
    "        '''\r\n",
    "        input = input.unsqueeze(0)  # (1, batch_size)\r\n",
    "        # (1, batch_size, emb_dim)\r\n",
    "        embedded = self.dropout(self.embedding(input))\r\n",
    "        \r\n",
    "        # (batch_size, src_len)\r\n",
    "        att = self.attention(hidden, encoder_outputs, mask)\r\n",
    "        att = att.unsqueeze(1)  # (batch_size, 1, src_len)\r\n",
    "\r\n",
    "        # (batch_size, src_len, enc_hid_dim * 2)\r\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
    "        # (batch_size, 1, enc_hid_dim * 2)\r\n",
    "        weighted = torch.bmm(att, encoder_outputs)\r\n",
    "        weighted = weighted.permute(1, 0, 2)  # (1, batch_size, enc_hid_dim * 2)\r\n",
    "        \r\n",
    "        # (1, batch_size, (enc_hid_dim * 2) + emb_dim)\r\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\r\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\r\n",
    "        # output: [seq_len, batch_size, dec_hid_dim * n_directions]\r\n",
    "        # hidden: [n_layers * n_directions, batch_size, dec_hid_dim]\r\n",
    "        \r\n",
    "        # seq_len, n_layers and n_directions will always be 1 in this decoder, therefore:\r\n",
    "        # output: [1, batch_size, dec_hid_dim]\r\n",
    "        # hidden: [1, batch_size, dec_hid_dim]\r\n",
    "        # this also means that output == hidden\r\n",
    "        assert (output == hidden).all()\r\n",
    "        \r\n",
    "        embedded = embedded.squeeze(0)\r\n",
    "        output = output.squeeze(0)\r\n",
    "        weighted = weighted.squeeze(0)\r\n",
    "        \r\n",
    "        # (batch_size, output_dim)\r\n",
    "        prediction = self.fc_out(self.dropout(torch.cat((output, weighted, embedded), dim=1)))\r\n",
    "                \r\n",
    "        return prediction, hidden.squeeze(0), att.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiytVpfk4isG"
   },
   "source": [
    "Seq2Seq 模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 31794,
     "status": "ok",
     "timestamp": 1612194287688,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "TNzgZqHcS2CX"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqATTN(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
    "\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
    "        '''\n",
    "            src: [src_len, batch_size]\n",
    "            src_len: [batch_size]\n",
    "            trg: [trg_len, batch_size]\n",
    "            teacher_forcing_ratio is probability to use teacher forcing\n",
    "            e.g. if teacher_forcing_ratio is 0.75, we use teacher forcing 75% of the time\n",
    "        '''\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        # hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "                \n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        mask = self.create_mask(src)  # (batch_size, src_len)\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            # insert input token embedding, previous hidden state, all encoder hidden states and mask\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
    "            \n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW2KIxhxrMGf"
   },
   "source": [
    "建立模型和重要參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42371,
     "status": "ok",
     "timestamp": 1612194298269,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "ybIY0kKGS_gI",
    "outputId": "fbd2fa64-cced-4da5-87f8-c803b2974d2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型全部參數量: 15,619,061 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqATTN(\n",
       "  (encoder): RNNEncoder(\n",
       "    (embedding): Embedding(12388, 256)\n",
       "    (rnn): GRU(256, 256, bidirectional=True)\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): RNNDecoder(\n",
       "    (attention): Attention()\n",
       "    (embedding): Embedding(6133, 256)\n",
       "    (rnn): GRU(768, 512)\n",
       "    (fc_out): Linear(in_features=1280, out_features=6133, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 256  # 注意 encoder hidden layer 設定必須為 decoder 的一半 \n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = RNNEncoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = RNNDecoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "model = Seq2SeqATTN(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
    "\n",
    "def initial_mdl_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(initial_mdl_weights)\n",
    "print(f\"模型全部參數量: {sum(p.numel() for p in model.parameters()):10,d} \")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrjwJTlB70h7"
   },
   "source": [
    "train and evalutate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 42365,
     "status": "ok",
     "timestamp": 1612194298269,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "KOpjxQJmTDYU"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src, src_len = batch.src\n",
    "        trg = batch.trg  # (trg_len, batch_size)\n",
    "        \n",
    "        # (trg_len, batch_size, output_dim)\n",
    "        output = model(src, src_len.cpu() , trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        # ((trg_len - 1) * batch_size, output_dim)\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)  # ((trg_len - 1) * batch_size)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src, src_len = batch.src\n",
    "            trg = batch.trg  # (trg_len, batch_size)\n",
    "\n",
    "            # (trg_len, batch_size, output_dim)\n",
    "            output = model(src, src_len.cpu(), trg, 0)  # turn off teacher forcing\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            # ((trg len - 1) * batch_size, output_dim)\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)  # ((trg len - 1) * batch_size)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFZUwxJA8CF6"
   },
   "source": [
    "訓練設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405630,
     "status": "ok",
     "timestamp": 1612194661539,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "bcmz65KO8FF1",
    "outputId": "00eb82ff-7c89-4a4a-9cd6-50852b2e262a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training time: 17.98 sec, Training Loss: 5.075 , Valiation Loss: 4.770\n",
      "Epoch 1 training time: 18.06 sec, Training Loss: 4.291 , Valiation Loss: 4.421\n",
      "Epoch 2 training time: 18.08 sec, Training Loss: 3.819 , Valiation Loss: 4.195\n",
      "Epoch 3 training time: 18.12 sec, Training Loss: 3.451 , Valiation Loss: 3.951\n",
      "Epoch 4 training time: 18.08 sec, Training Loss: 3.124 , Valiation Loss: 3.833\n",
      "Epoch 5 training time: 17.93 sec, Training Loss: 2.807 , Valiation Loss: 3.715\n",
      "Epoch 6 training time: 17.86 sec, Training Loss: 2.563 , Valiation Loss: 3.688\n",
      "Epoch 7 training time: 17.92 sec, Training Loss: 2.337 , Valiation Loss: 3.690\n",
      "Epoch 8 training time: 17.95 sec, Training Loss: 2.173 , Valiation Loss: 3.639\n",
      "Epoch 9 training time: 18.09 sec, Training Loss: 1.990 , Valiation Loss: 3.672\n",
      "Epoch 10 training time: 17.92 sec, Training Loss: 1.885 , Valiation Loss: 3.624\n",
      "Epoch 11 training time: 17.91 sec, Training Loss: 1.764 , Valiation Loss: 3.675\n",
      "Epoch 12 training time: 17.95 sec, Training Loss: 1.661 , Valiation Loss: 3.708\n",
      "Epoch 13 training time: 17.97 sec, Training Loss: 1.584 , Valiation Loss: 3.688\n",
      "Epoch 14 training time: 17.99 sec, Training Loss: 1.504 , Valiation Loss: 3.723\n",
      "Epoch 15 training time: 17.87 sec, Training Loss: 1.437 , Valiation Loss: 3.704\n",
      "Epoch 16 training time: 17.84 sec, Training Loss: 1.382 , Valiation Loss: 3.704\n",
      "Epoch 17 training time: 17.91 sec, Training Loss: 1.349 , Valiation Loss: 3.778\n",
      "Epoch 18 training time: 17.94 sec, Training Loss: 1.301 , Valiation Loss: 3.772\n",
      "Epoch 19 training time: 17.89 sec, Training Loss: 1.255 , Valiation Loss: 3.752\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 20\r\n",
    "CLIP = 5\r\n",
    "model_dir = 'model'\r\n",
    "os.makedirs(model_dir, exist_ok=True)\r\n",
    "\r\n",
    "best_valid_loss = 9999999\r\n",
    "for epoch in range(MAX_EPOCHS):\r\n",
    "    start_time = time.time()\r\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
    "    end_time = time.time()\r\n",
    "    \r\n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, f\"model-{epoch}.pt\"))\r\n",
    "    if valid_loss < best_valid_loss:\r\n",
    "        best_valid_loss = valid_loss\r\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'best-model.pt'))\r\n",
    "   \r\n",
    "    print(f\"Epoch {epoch} training time: {end_time - start_time:.2f} sec, \"\r\n",
    "          f\"Training Loss: {train_loss:.3f} , Valiation Loss: {valid_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9F-sWnV9f28"
   },
   "source": [
    "Evaluate testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406587,
     "status": "ok",
     "timestamp": 1612194662501,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "Ukg9t_iOTHlG",
    "outputId": "d0405310-90f6-4543-aea1-9b3edc4fbc29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.545 | Test PPL:  34.638 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(model_dir, 'best-model.pt')))\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 406581,
     "status": "ok",
     "timestamp": 1612194662501,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "Q-caE1Y1TL5p"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
    "    model.eval()\n",
    "        \n",
    "    tokens = [token.lower() for token in sentence]\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor, src_len.cpu())\n",
    "\n",
    "    mask = model.create_mask(src_tensor)\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
    "\n",
    "        attentions[i] = attention\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JxlvTVD-kvT"
   },
   "source": [
    "選擇一句來看翻譯結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406577,
     "status": "ok",
     "timestamp": 1612194662502,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "b22YJ_44-l_O",
    "outputId": "cf3de078-f0d8-4499-9555-ea97209116bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['对', '了', '你', '的', '地址', '是', '什么']\n",
      "trg = ['by', 'the', 'way', ',', 'what', 'is', 'your', 'address', '?']\n",
      "predicted trg = ['what', \"'s\", 'your', 'address', 'address', '?', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 123\r\n",
    "\r\n",
    "src = vars(train_dataset.examples[example_idx])['src']\r\n",
    "print(f'src = {src}')\r\n",
    "trg = vars(train_dataset.examples[example_idx])['trg']\r\n",
    "print(f'trg = {trg}')\r\n",
    "\r\n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWpOXdiL_c9A"
   },
   "source": [
    "BLEU score evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 406571,
     "status": "ok",
     "timestamp": 1612194662502,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "vgHrm83K_dNX"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\r\n",
    "\r\n",
    "def calculate_bleu(data, src_field, trg_field, model, device, max_len=50):    \r\n",
    "    trgs, pred_trgs = [], []\r\n",
    "    for datum in data:\r\n",
    "        src = vars(datum)['src']\r\n",
    "        trg = vars(datum)['trg']\r\n",
    "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\r\n",
    "        \r\n",
    "        # cut off <eos> token\r\n",
    "        pred_trg = pred_trg[:-1]\r\n",
    "        \r\n",
    "        pred_trgs.append(pred_trg)\r\n",
    "        trgs.append([trg])\r\n",
    "        \r\n",
    "    return bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 427483,
     "status": "ok",
     "timestamp": 1612194683418,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "SUvCDups_mdB",
    "outputId": "bdfac027-4b0f-4e45-9ab9-c87a4f0e1591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 19.67\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(test_dataset, SRC, TRG, model, device)\r\n",
    "print(f'BLEU score = {bleu_score * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 427478,
     "status": "ok",
     "timestamp": 1612194683419,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "9jhh_5_SYYLT"
   },
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in sentence] + ['<eos>'], \n",
    "                       rotation=45 , fontproperties=myfont)\n",
    "    ax.set_yticklabels([''] + translation, fontproperties=myfont)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4n7915Mrcs1"
   },
   "source": [
    "## 作業重點\n",
    "請選擇一個好的翻譯結果並將其 Attention 視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 427475,
     "status": "ok",
     "timestamp": 1612194683420,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "pRYXjqgvYb-E",
    "outputId": "ba70a0a5-8c43-4b39-d51a-face73d914b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['我', '确定', '你', '不久', '就', '回来']\n",
      "trg = ['i', \"'m\", 'sure', 'you', \"'ll\", 'be', 'back', 'before', 'long', '.']\n",
      "predicted trg = ['i', \"'m\", 'sure', 'you', \"'ll\", 'come', 'back', 'in', 'you', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# 請在這自行調整 sample index 觀察不同句子的 Attention 結果\n",
    "example_idx = 456\n",
    "\n",
    "src = vars(train_dataset.examples[example_idx])['src']\n",
    "print(f'src = {src}')\n",
    "trg = vars(train_dataset.examples[example_idx])['trg']\n",
    "print(f'trg = {trg}')\n",
    "\n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cdlptGJrsfv"
   },
   "source": [
    "# 觀察翻譯文和被翻譯文的語意對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "executionInfo": {
     "elapsed": 427468,
     "status": "ok",
     "timestamp": 1612194683421,
     "user": {
      "displayName": "王俊煒",
      "photoUrl": "",
      "userId": "10865038187423164500"
     },
     "user_tz": -480
    },
    "id": "H8f8csPSYfkU",
    "outputId": "0512d2e5-5d97-413a-d644-be13b1496cb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我确定你不久就回来\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(''.join(src))\n",
    "display_attention(src, translation, attention)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
