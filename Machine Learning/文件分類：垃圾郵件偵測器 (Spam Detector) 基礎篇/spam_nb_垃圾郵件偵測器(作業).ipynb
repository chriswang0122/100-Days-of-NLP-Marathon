{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2,"kernelspec":{"name":"python_defaultSpec_1597542987315","display_name":"Python 3.6.8 64-bit ('ENV': venv)"},"colab":{"name":"spam_nb_垃圾郵件偵測器(作業).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CCKd8G9l6JjM"},"source":["題目: 將已整理好的文件以機器學習方式分辨是否為垃圾郵件<br>\r\n","說明：輸入文件已處理過，為一D乘V(V=48)+1矩陣，D代表電郵數，V代表選出來(判斷是否垃圾)的字(特徵)，<br>\r\n","所以我們是用48個特徵來判斷。列中每行表達的特徵值(feature)=出現次數 / 該電郵總字數 * 100，<br>\r\n","最後一行是標註(Label)是否為垃圾郵件。請用ML方法開發出垃圾郵件偵測器並算出預測準確度<br>\r\n","延伸:可用不同ML分類法，可準備自己的垃圾郵件做預處理。<br>\r\n","範例程式檔名: spam_nb_垃圾郵件偵測器.py，以Naïve Bayes方式完成<br>\r\n","模組: sklearn, pandas, numpy<br>\r\n","輸入檔：spambase(作業數據).data<br>\r\n","成績：辨識百分率<br>"]},{"cell_type":"code","metadata":{"id":"vtwPZqeKbJFA","executionInfo":{"status":"ok","timestamp":1608557103255,"user_tz":-480,"elapsed":652,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["import numpy as np\r\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OCy3tz_VcuOw"},"source":["註: 理論上 multinomial NB 是針對出現次數 \"counts\", 但文件上說對出現比率 \"word proportions\"也適合"]},{"cell_type":"code","metadata":{"id":"cTJyR3wjbJRk","executionInfo":{"status":"ok","timestamp":1608557103821,"user_tz":-480,"elapsed":1215,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["data = pd.read_csv('spambase(作業數據).data').values   # use pandas for convenience\r\n","np.random.shuffle(data)   # shuffle each row in-place, but preserve the row\r\n","\r\n","X = data[:,:48]\r\n","Y = data[:,-1]"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C3Tc3JxJdEhC"},"source":["不一定用100列 作測試 100->80 試試"]},{"cell_type":"code","metadata":{"id":"FrhmMCbobJVF","executionInfo":{"status":"ok","timestamp":1608557103821,"user_tz":-480,"elapsed":1213,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["Xtrain, Ytrain = X[:-80,], Y[:-80,]\r\n","Xtest, Ytest = X[-80:,], Y[-80:,]"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RqwlRmrwdN-k"},"source":["我們在習題中，不用Naive Bayes"]},{"cell_type":"code","metadata":{"id":"p_n2lACbbJYH","executionInfo":{"status":"ok","timestamp":1608557103821,"user_tz":-480,"elapsed":1211,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["# from sklearn.naive_bayes import MultinomialNB\r\n","# model = MultinomialNB()\r\n","# model.fit(Xtrain, Ytrain)\r\n","# print(\"Classification rate for NB:\", model.score(Xtest, Ytest))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3q93ZiOdRpI"},"source":["Decision Tree 的準確度如何？"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M50KQs_TbTqJ","executionInfo":{"status":"ok","timestamp":1608557104460,"user_tz":-480,"elapsed":1843,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"b78e19b1-4262-4122-efb0-f3d4ae1c56d2"},"source":["from sklearn.tree import DecisionTreeClassifier\r\n","model = DecisionTreeClassifier()\r\n","model.fit(Xtrain, Ytrain)\r\n","print(\"Classification rate for Decision Tree:\", model.score(Xtest, Ytest))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Classification rate for Decision Tree: 0.875\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZAmYGTxjdVeJ"},"source":["任何 model都行，以下試試 AdaBoost!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5obHQRVBbTtk","executionInfo":{"status":"ok","timestamp":1608557104699,"user_tz":-480,"elapsed":2076,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"cae0a77f-fca5-4a3f-c653-ed59dca6587f"},"source":["from sklearn.ensemble import AdaBoostClassifier\r\n","model = AdaBoostClassifier()\r\n","model.fit(Xtrain, Ytrain)\r\n","print(\"Classification rate for AdaBoost:\", model.score(Xtest, Ytest))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Classification rate for AdaBoost: 0.9125\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RHcTWH8wdawL"},"source":["也可試試其他的<br>\r\n","https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"]},{"cell_type":"code","metadata":{"id":"a9y_QbkbcIFc","executionInfo":{"status":"ok","timestamp":1608557104700,"user_tz":-480,"elapsed":2076,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["from sklearn.neighbors import KNeighborsClassifier\r\n","from sklearn.svm import SVC\r\n","from sklearn.gaussian_process import GaussianProcessClassifier\r\n","from sklearn.gaussian_process.kernels import RBF\r\n","from sklearn.tree import DecisionTreeClassifier\r\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\r\n","from sklearn.neural_network import MLPClassifier\r\n","from sklearn.naive_bayes import GaussianNB\r\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqVARIwrcJfl","executionInfo":{"status":"ok","timestamp":1608557104700,"user_tz":-480,"elapsed":2074,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}}},"source":["names = [\r\n","    \"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\r\n","    \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\r\n","    \"Naive Bayes\", \"QDA\"\r\n","]\r\n","\r\n","classifiers = [\r\n","    KNeighborsClassifier(3),\r\n","    SVC(kernel=\"linear\", C=0.025),\r\n","    SVC(gamma=2, C=1),\r\n","    GaussianProcessClassifier(1.0 * RBF(1.0)),\r\n","    DecisionTreeClassifier(max_depth=5),\r\n","    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\r\n","    MLPClassifier(alpha=1, max_iter=1000),\r\n","    AdaBoostClassifier(),\r\n","    GaussianNB(),\r\n","    QuadraticDiscriminantAnalysis()\r\n","]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvhYTMlKcN01","executionInfo":{"status":"ok","timestamp":1608557519785,"user_tz":-480,"elapsed":417154,"user":{"displayName":"王俊煒","photoUrl":"","userId":"10865038187423164500"}},"outputId":"518879f8-504b-4555-b316-7b655b45f8bb"},"source":["# iterate over classifiers\r\n","for name, clf in zip(names, classifiers):\r\n","    clf.fit(Xtrain, Ytrain)\r\n","    score = clf.score(Xtest, Ytest)\r\n","    print(f\"Classification rate for {name}: {clf.score(Xtest, Ytest)}\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Classification rate for Nearest Neighbors: 0.8125\n","Classification rate for Linear SVM: 0.9375\n","Classification rate for RBF SVM: 0.7875\n","Classification rate for Gaussian Process: 0.9125\n","Classification rate for Decision Tree: 0.8875\n","Classification rate for Random Forest: 0.7875\n","Classification rate for Neural Net: 0.9375\n","Classification rate for AdaBoost: 0.9125\n","Classification rate for Naive Bayes: 0.8125\n","Classification rate for QDA: 0.8\n"],"name":"stdout"}]}]}