{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手刻基本Naive Bayes模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 學習重點：理解單純貝氏模型原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "\n",
    "def tokenize(message):\n",
    "    message = message.lower()\n",
    "    all_words = re.findall(\"[a-z0-9]+\", message)\n",
    "    return set(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀入資料並分割為 train/testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for root, dirs, files in os.walk(\"spam_data\"):\n",
    "    for name in files:\n",
    "        filename = os.path.join(root, name)\n",
    "        is_spam = False if 'ham' in filename else True\n",
    "        with open(filename, encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f.readlines():\n",
    "                if line.startswith('Subject:'):\n",
    "                    subject = re.sub(r'^Subject:', '', line).strip()\n",
    "                    X.append(subject)\n",
    "                    Y.append(is_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# random_state 是為了讓各為學員得到相同的結果，平時可以移除\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(x, y) for x, y in zip(X_train, y_train)]\n",
    "test_data = [(x, y) for x, y in zip(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defaultdict用法示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic : defaultdict(<function <lambda> at 0x7f88c12220e0>, {'you': [1, 0], 'hi': [1, 2], 'no': [8, 1]})\n",
      "you : [1, 0]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "counts = defaultdict(lambda: [0, 0])\n",
    "counts['you'][0] += 1\n",
    "counts['hi'][0] += 1\n",
    "counts['hi'][1] += 2\n",
    "counts['no'][1] += 1\n",
    "counts['no'][0] += 8\n",
    "print(f\"dic : {counts}\")\n",
    "print(f\"you : {counts['you']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 創造一個字典，裡面是{'hi': [1, 0]}，對應第一個數字是是垃圾郵件的次數，對應第二個數字是不是垃圾郵件的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(training_set):\n",
    "    counts = defaultdict(lambda: [0, 0])\n",
    "    for message, is_spam in training_set:\n",
    "        for word in tokenize(message):\n",
    "            counts[word][0 if is_spam else 1] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算 p(w|spam) / p(w|non_spam)\n",
    "* 其中K為超參數，為了確保分母/分子皆不為0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
    "    # 獲得三組數據，分別為w這個字，p(w|spam)，p(w|non_spam)\n",
    "    # counts[w][0]=spam, counts[w][1]=non_spam\n",
    "    return [(w, \n",
    "             (counts[w][0] + k) / (total_spams + 2 * k), \n",
    "             (counts[w][1] + k)/(total_non_spams + 2 * k)\n",
    "            ) for w in counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算貝氏結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_probability(word_probs, message, is_spam_probability, is_not_spam_probability):\n",
    "    # 先把這個mail的文字處理一下\n",
    "    message_words = tokenize(message)\n",
    "    #初始化值\n",
    "    log_prob_if_spam = log_prob_if_not_spam = 0.\n",
    "    # 將w這個字，p(w|spam)，p(w|non_spam)依序引入\n",
    "    for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
    "        if word in message_words:\n",
    "            # 假如這個字有在這個mail中出現\n",
    "            # 把他的p(w|spam)轉log值加上log_prob_if_spam\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            # 把他的p(w|non_spam)轉log值加上log_prob_if_not_spam\n",
    "            log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
    "        else:\n",
    "            # 如果沒出現log_prob_if_spam➕上得值就是1-p(w|spam)也就是這封信是垃圾郵件但是w這個字卻沒在裡面\n",
    "            log_prob_if_spam += math.log(1 - prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(1 - prob_if_not_spam)\n",
    "    log_prob_if_spam += math.log(is_spam_probability)\n",
    "    log_prob_if_not_spam += math.log(is_not_spam_probability)\n",
    "    \n",
    "    # 把+起來的值轉成exp再算NaiveBayes\n",
    "    prob_if_spam = math.exp(log_prob_if_spam)\n",
    "    prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
    "    #貝氏\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打包整個模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k=0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = []\n",
    "\n",
    "    def train(self, training_set):\n",
    "        # 訓練的資料格式為(message, is_spam)\n",
    "        # 所有垃圾郵件的數量\n",
    "        num_spams = len([is_spam for _, is_spam in training_set if is_spam])\n",
    "        #所有不是垃圾郵件的數量\n",
    "        num_non_spams = len(training_set) - num_spams\n",
    "        \n",
    "        self.is_spam_probability = num_spams / (num_spams + num_non_spams)\n",
    "        self.is_not_spam_probability = num_non_spams / (num_spams + num_non_spams)\n",
    "        # 把training_set裡面的所有字體轉成('Bad', num_is_spam, num_not_spam)\n",
    "        word_counts = count_words(training_set)\n",
    "        self.word_probs = word_probabilities(word_counts, num_spams, num_non_spams, self.k)\n",
    "\n",
    "    def classify(self, message):\n",
    "        return spam_probability(self.word_probs, message, self.is_spam_probability, self.is_not_spam_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit 訓練集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=NaiveBayesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 88.24%\n",
      "recall : 59.41%\n",
      "accuracy : 92.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "y_true = [is_spam for _, is_spam in test_data]\n",
    "y_pred = [classifier.classify(subject) > 0.5 for subject, _ in test_data]\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"precision : {precision * 100:.2f}%\")\n",
    "print(f\"recall : {recall * 100:.2f}%\")\n",
    "print(f\"accuracy : {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_true = pd.Series(y_true).map({True: 'spam', False: 'ham'})\n",
    "y_pred = pd.Series(y_pred).map({True: 'spam', False: 'ham'})\n",
    "confusion_matrix = pd.crosstab(y_true, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>576</td>\n",
       "      <td>8</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>41</td>\n",
       "      <td>60</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>617</td>\n",
       "      <td>68</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  ham  spam  All\n",
       "Actual                   \n",
       "ham        576     8  584\n",
       "spam        41    60  101\n",
       "All        617    68  685"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
